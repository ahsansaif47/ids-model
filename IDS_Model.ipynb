{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcCNAgviN6Ki"
      },
      "source": [
        "# Mounting Drive\n",
        "Mounting drive to fetch dataset and other resources from the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmchhkO9S-1R",
        "outputId": "30fd133e-6f6f-4613-fe2e-783f91953950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caLVJ7fVTETv"
      },
      "source": [
        "# Installing Spektral Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pbGlTrXTIl8",
        "outputId": "03fabeb3-b09d-4d0a-83de-8b35d9cb149f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/danielegrattarola/spektral\n",
            "  Cloning https://github.com/danielegrattarola/spektral to /tmp/pip-req-build-a2p4bbyn\n",
            "  Running command git clone -q https://github.com/danielegrattarola/spektral /tmp/pip-req-build-a2p4bbyn\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (1.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (4.2.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (2.6.3)\n",
            "Requirement already satisfied: numpy<1.20 in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (1.4.1)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (2.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.8) (4.62.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.6.3)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.12.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (0.2.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (0.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (1.40.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.8) (0.37.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1.0->spektral==1.0.8) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (1.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.8) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.8) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.8) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.8) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->spektral==1.0.8) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral==1.0.8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral==1.0.8) (2018.9)\n",
            "Building wheels for collected packages: spektral\n",
            "  Building wheel for spektral (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spektral: filename=spektral-1.0.8-py3-none-any.whl size=123417 sha256=1c0e6e389d600bba6468ebce740e3848d6360c910f5377f624328f0d73fb6b1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xnaqvw1y/wheels/af/7c/1f/e06aba9c0f493bb708968b8b396fe7523fdfb1c1c0818730be\n",
            "Successfully built spektral\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/danielegrattarola/spektral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVDhozDN0Nd"
      },
      "source": [
        "# Loading Label Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm6klvIIN0Nk",
        "outputId": "73f65bae-f5f1-4f8a-eab9-e48a4311a93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Label files are:  129\n"
          ]
        }
      ],
      "source": [
        "# Dataset loading\n",
        "import os\n",
        "\n",
        "dataset = \"/content/drive/MyDrive/Project GCN Dataset/Dataset (Labelled Images)/\"\n",
        "lab_files_path = dataset+\"Labels/\"\n",
        "\n",
        "files = os.listdir(lab_files_path)\n",
        "print(\"Total Label files are: \", len(files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEkBSTLnN0No"
      },
      "source": [
        "# Sparse Matrix Creation\n",
        "\n",
        "Iterate all the csv files and do the following three steps:\n",
        "1. Make a graph of CSV file.\n",
        "2. Turn the graph into adjacency matrix.\n",
        "3. Append that adjacency matrix into sparce matrix(i.e. bigger matrix)\n",
        "\n",
        "# DON'T RUN THIS TAKES A HELL LOT OF TIME\n",
        "# SPARCE MATRIX IS ALREADY CREATED AND SAVED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJwo6iIWN0Np"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import Mat_Package.Grapher as GMaker\n",
        "import Mat_Package.MatricesOverDiagonal as DiagPlacer\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from numpy.core.fromnumeric import shape\n",
        "\n",
        "\n",
        "Z_file = lab_files_path + files[0]\n",
        "df = pd.read_csv(Z_file)\n",
        "G = GMaker.makeGraph(df)\n",
        "M = nx.to_numpy_array(G, dtype=np.int32)\n",
        "\n",
        "\n",
        "for i in range(1, len(files)):\n",
        "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
        "    print(\"Iteration No.: \", i)\n",
        "    # Getting file\n",
        "    f = lab_files_path + files[i]\n",
        "    # Making dataframe of file\n",
        "    df = pd.read_csv(f)\n",
        "    # Making graph of the dataframe. \n",
        "    G = GMaker.makeGraph(df)\n",
        "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
        "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
        "    # Now resizing the original sparce matrix with the new incident matrix\n",
        "    M = DiagPlacer.resizeMatrix(M, I)\n",
        "    \n",
        "print(\"Final Matix Done\")\n",
        "print(\"Dimentions of sparce matrix are: \", np.shape(M))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMEFmXdpDs-f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from numpy.core.fromnumeric import shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nomU0PgWZLqu"
      },
      "source": [
        "# Geometric Algorithms for converting dataframes to Graphs\n",
        "It connects a node with its neighbouring nodes  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTxAf2dxkJ_8"
      },
      "outputs": [],
      "source": [
        "from PIL.Image import Image\n",
        "import networkx as nx\n",
        "from networkx.algorithms.shortest_paths.weighted import single_source_dijkstra\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.core.frame import DataFrame\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# csv = './A-10.csv'\n",
        "# df = pd.read_csv(csv)\n",
        "df = 0\n",
        "xMIN, xMAX = [], []\n",
        "yMIN, yMAX = [], []\n",
        "Text = []\n",
        "\n",
        "\n",
        "def findRight(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
        "    S_list = []\n",
        "    xmax = xMAX[df_ind]\n",
        "    ymin = yMIN[df_ind]\n",
        "    ymax = yMAX[df_ind]\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if(xMIN[i] > xmax):\n",
        "            if not (yMIN[i] > ymax or yMAX[i] < ymin):\n",
        "                if(yMIN[i] <= ymin and yMAX[i] <= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] <= ymin and yMAX[i] >= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] >= ymin and yMAX[i] <= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] >= ymin and yMAX[i] >= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] == ymin and yMAX[i] == ymax):\n",
        "                    S_list.append(i)\n",
        "\n",
        "    # print(S_list)\n",
        "    if S_list:\n",
        "        consec = S_list[0]\n",
        "        for j in S_list:\n",
        "            if(xMIN[consec] > xMIN[j]):\n",
        "                consec = j\n",
        "        return consec\n",
        "\n",
        "    return -1\n",
        "\n",
        "\n",
        "def findLeft(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
        "    S_list = []\n",
        "    xmin = xMIN[df_ind]\n",
        "    ymin = yMIN[df_ind]\n",
        "    ymax = yMAX[df_ind]\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if(xMAX[i] < xmin):\n",
        "            if not (yMIN[i] > ymax or yMAX[i] < ymin):\n",
        "                if(yMIN[i] <= ymin and yMAX[i] <= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] <= ymin and yMAX[i] >= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] >= ymin and yMAX[i] <= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] >= ymin and yMAX[i] >= ymax):\n",
        "                    S_list.append(i)\n",
        "                elif (yMIN[i] == ymin and yMAX[i] == ymax):\n",
        "                    S_list.append(i)\n",
        "    # print(S_list)\n",
        "    if S_list:\n",
        "        consec = S_list[0]\n",
        "        for j in S_list:\n",
        "            if(xMAX[j] > xMAX[consec]):\n",
        "                consec = j\n",
        "        return consec\n",
        "    return -1\n",
        "\n",
        "\n",
        "def findUp(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
        "    S_list = []\n",
        "    xmin = xMIN[df_ind]\n",
        "    xmax = xMAX[df_ind]\n",
        "    ymin = yMIN[df_ind]\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if(yMAX[i] < ymin):\n",
        "            if not (xMAX[i] < xmin or xMIN[i] > xmax):\n",
        "                if(xMIN[i] <= xmin and xMAX[i] <= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] <= xmin and xMAX[i] >= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] >= xmin and xMAX[i] <= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] >= xmin and xMAX[i] >= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] == xmin and xMAX[i] == xmax):\n",
        "                    S_list.append(i)\n",
        "    # print(S_list)\n",
        "\n",
        "    if S_list:\n",
        "        consec = S_list[0]\n",
        "        for j in S_list:\n",
        "            if(yMAX[j] > yMAX[consec]):\n",
        "                consec = j\n",
        "        return consec\n",
        "\n",
        "    return -1\n",
        "\n",
        "\n",
        "def findDown(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
        "    S_list = []\n",
        "    xmin = xMIN[df_ind]\n",
        "    xmax = xMAX[df_ind]\n",
        "    ymax = yMAX[df_ind]\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if(yMIN[i] > ymax):\n",
        "            if not (xMAX[i] < xmin or xMIN[i] > xmax):\n",
        "                if(xMIN[i] <= xmin and xMAX[i] <= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] <= xmin and xMAX[i] >= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] >= xmin and xMAX[i] <= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] >= xmin and xMAX[i] >= xmax):\n",
        "                    S_list.append(i)\n",
        "                elif (xMIN[i] == xmin and xMAX[i] == xmax):\n",
        "                    S_list.append(i)\n",
        "    # print(S_list)\n",
        "    if S_list:\n",
        "        consec = S_list[0]\n",
        "        for j in S_list:\n",
        "            if(yMIN[j] < yMIN[consec]):\n",
        "                consec = j\n",
        "        return consec\n",
        "\n",
        "    return -1\n",
        "\n",
        "\n",
        "def makeGraph(df):\n",
        "    G = nx.Graph()\n",
        "    xMIN = df['xmin']\n",
        "    xMAX = df['xmax']\n",
        "    yMIN = df['ymin']\n",
        "    yMAX = df['ymax']\n",
        "    Text = df['Object']\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if findUp(df, i, xMIN, xMAX, yMIN, yMAX):\n",
        "            l = findUp(df, i, xMIN, xMAX, yMIN, yMAX)\n",
        "            if(l != -1):\n",
        "                text = Text[l]\n",
        "                G.add_edge(Text[i], text)\n",
        "        if findRight(df, i, xMIN, xMAX, yMIN, yMAX):\n",
        "            l = findRight(df, i, xMIN, xMAX, yMIN, yMAX)\n",
        "            if (l != -1):\n",
        "                text = Text[l]\n",
        "                G.add_edge(Text[i], text)\n",
        "        if findDown(df, i, xMIN, xMAX, yMIN, yMAX):\n",
        "            l = findDown(df, i, xMIN, xMAX, yMIN, yMAX)\n",
        "            if (l != -1):\n",
        "                text = Text[l]\n",
        "                G.add_edge(Text[i], text)\n",
        "        if findLeft(df, i, xMIN, xMAX, yMIN, yMAX):\n",
        "            l = findLeft(df, i, xMIN, xMAX, yMIN, yMAX)\n",
        "            if (l != -1):\n",
        "                text = Text[l]\n",
        "                G.add_edge(Text[i], text)\n",
        "    return G\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln7Fs0dRkoIf"
      },
      "source": [
        "# Matrices Over Diagonal\n",
        "Place an incident Matrix over diagonal with existing matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRjN1IPHk_bO"
      },
      "outputs": [],
      "source": [
        "from typing import SupportsAbs\n",
        "import numpy as np\n",
        "from numpy.core.fromnumeric import shape\n",
        "\n",
        "# Test Matrices\n",
        "# mat1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "# mat2 = np.array([[3, 2, 1, 7], [6, 5, 4, 9], [9, 8, 7, 4], [1, 5, 7, 2]])\n",
        "\n",
        "\n",
        "def alignDiagonally(M1, M2, prev_Len):\n",
        "    for i in range(prev_Len, np.shape(M1)[0]):\n",
        "        for j in range(prev_Len, np.shape(M1)[0]):\n",
        "            x = i - prev_Len\n",
        "            y = j - prev_Len\n",
        "            M1[i][j] = M2[x][y]\n",
        "    return M1\n",
        "\n",
        "\n",
        "def resizeMatrix(M, I):\n",
        "    oldMat_Len = np.shape(M)[0]\n",
        "    z = np.zeros((oldMat_Len, np.shape(I)[0]), dtype=np.int64)\n",
        "    newArray = np.append(M, z, axis=1)\n",
        "    M = newArray\n",
        "\n",
        "    # Appending 1D arrays of zeros in the original Matrix\n",
        "    # (i.e. the matrix in which we want to align othe rmatrices diagonally)\n",
        "    # for i in range(appZero):\n",
        "    #     M = np.vstack((M, L))\n",
        "    appZero = np.shape(I)[0]\n",
        "    x = oldMat_Len + appZero\n",
        "    L = np.zeros((np.shape(I)[0], x), dtype=np.int64)\n",
        "    newArray = np.append(M, L, axis=0)\n",
        "    M = newArray\n",
        "\n",
        "    M = alignDiagonally(M, I, oldMat_Len)\n",
        "    return M\n",
        "\n",
        "\n",
        "# print(resizeMatrix(mat1, mat2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4migFjSpUxCP"
      },
      "source": [
        "# Dividing Dataset into smaller datasets\n",
        "Creating a total of four sparse matrices and saving it to drive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kuu2G9BAY_O"
      },
      "source": [
        "# Dataset Batch 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StRWr_C0U8uj",
        "outputId": "216662d6-e578-4872-c20c-5518f28dff7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  1\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  2\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  3\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  4\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  5\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  6\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  7\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  8\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  9\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  10\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  11\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  12\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  13\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  14\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  15\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  16\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  17\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  18\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  19\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  20\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  21\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  22\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  23\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  24\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  25\n",
            "Dimentions of Batch 1 matrix is:  (5762, 5762)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from numpy.core.fromnumeric import shape\n",
        "\n",
        "Z_file = lab_files_path + files[0]\n",
        "df = pd.read_csv(Z_file)\n",
        "G = makeGraph(df)\n",
        "M1 = nx.to_numpy_array(G, dtype=np.int32)\n",
        "\n",
        "for i in range(1, 26):\n",
        "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
        "    print(\"Iteration No.: \", i)\n",
        "    # Getting file\n",
        "    f = lab_files_path + files[i]\n",
        "    # Making dataframe of file\n",
        "    df = pd.read_csv(f)\n",
        "    # Making graph of the dataframe. \n",
        "    G = makeGraph(df)\n",
        "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
        "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
        "    # Now resizing the original sparce matrix with the new incident matrix\n",
        "    M1 = resizeMatrix(M1, I)\n",
        "\n",
        "print(\"Dimentions of Batch 1 matrix is: \", np.shape(M1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14pae4cQAmoa"
      },
      "source": [
        "# Dataset Batch 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuO0iRx_Aphl",
        "outputId": "8ba57aaa-6f10-49ef-f6c0-6d514f5b8d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  27\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  28\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  29\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  30\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  31\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  32\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  33\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  34\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  35\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  36\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  37\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  38\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  39\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  40\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  41\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  42\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  43\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  44\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  45\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  46\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  47\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  48\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  49\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  50\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  51\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  52\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  53\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  54\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  55\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  56\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  57\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  58\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  59\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  60\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  61\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  62\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  63\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  64\n",
            "Dimentions of Batch 2 matrix is:  (5410, 5410)\n"
          ]
        }
      ],
      "source": [
        "Z1_file = lab_files_path + files[26]\n",
        "df = pd.read_csv(Z1_file)\n",
        "G = makeGraph(df)\n",
        "M2 = nx.to_numpy_array(G, dtype=np.int32)\n",
        "\n",
        "for i in range(27, 65):\n",
        "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
        "    print(\"Iteration No.: \", i)\n",
        "    # Getting file\n",
        "    f = lab_files_path + files[i]\n",
        "    # Making dataframe of file\n",
        "    df = pd.read_csv(f)\n",
        "    # Making graph of the dataframe. \n",
        "    G = makeGraph(df)\n",
        "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
        "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
        "    # Now resizing the original sparce matrix with the new incident matrix\n",
        "    M2 = resizeMatrix(M2, I)\n",
        "\n",
        "print(\"Dimentions of Batch 2 matrix is: \", np.shape(M2))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2GlwRWArD1"
      },
      "source": [
        "# Dataset Batch 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3ucBbqAt8Z",
        "outputId": "ee7891f7-d6b0-4f1b-aa47-784f184acbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  66\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  67\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  68\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  69\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  70\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  71\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  72\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  73\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  74\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  75\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  76\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  77\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  78\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  79\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  80\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  81\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  82\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  83\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  84\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  85\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  86\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  87\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  88\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  89\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  90\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  91\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  92\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  93\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  94\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  95\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  96\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  97\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  98\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  99\n",
            "Dimentions of Batch 3 matrix is:  (7432, 7432)\n"
          ]
        }
      ],
      "source": [
        "Z2_file = lab_files_path + files[65]\n",
        "df = pd.read_csv(Z2_file)\n",
        "G = makeGraph(df)\n",
        "M3 = nx.to_numpy_array(G, dtype=np.int32)\n",
        "    \n",
        "for i in range(66, 100):\n",
        "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
        "    print(\"Iteration No.: \", i)\n",
        "    # Getting file\n",
        "    f = lab_files_path + files[i]\n",
        "    # Making dataframe of file\n",
        "    df = pd.read_csv(f)\n",
        "    # Making graph of the dataframe. \n",
        "    G = makeGraph(df)\n",
        "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
        "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
        "    # Now resizing the original sparce matrix with the new incident matrix\n",
        "    M3 = resizeMatrix(M3, I)\n",
        "\n",
        "print(\"Dimentions of Batch 3 matrix is: \", np.shape(M3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfGcavncA3Iu"
      },
      "source": [
        "# Dataset Batch 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA9wfeuLA5Kv",
        "outputId": "4ff4e9b6-270a-4482-80a5-2654918df8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  101\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  102\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  103\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  104\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  105\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  106\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  107\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  108\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  109\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  110\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  111\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  112\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  113\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  114\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  115\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  116\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  117\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  118\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  119\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  120\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  121\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  122\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  123\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  124\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  125\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  126\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  127\n",
            "\n",
            "= = = = = = = = = = = = = = = =\n",
            "Iteration No.:  128\n",
            "Dimentions of Batch 4 matrix is:  (2493, 2493)\n"
          ]
        }
      ],
      "source": [
        "Z3_file = lab_files_path + files[100]\n",
        "df = pd.read_csv(Z3_file)\n",
        "G = makeGraph(df)\n",
        "M4 = nx.to_numpy_array(G, dtype=np.int32)\n",
        "\n",
        "for i in range(101, len(files)):\n",
        "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
        "    print(\"Iteration No.: \", i)\n",
        "    # Getting file\n",
        "    f = lab_files_path + files[i]\n",
        "    # Making dataframe of file\n",
        "    df = pd.read_csv(f)\n",
        "    # Making graph of the dataframe. \n",
        "    G = makeGraph(df)\n",
        "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
        "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
        "    # Now resizing the original sparce matrix with the new incident matrix\n",
        "    M4 = resizeMatrix(M4, I)\n",
        "\n",
        "print(\"Dimentions of Batch 4 matrix is: \", np.shape(M4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FWHWx2nGk6K"
      },
      "source": [
        "# Verifying dataset batches size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAMbTr8WGrrc",
        "outputId": "a799c8e3-2c17-4be7-a61b-e40295997d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall dimention is:  21097\n"
          ]
        }
      ],
      "source": [
        "t_size = np.shape(M1)[0] + np.shape(M2)[0]  + np.shape(M3)[0] + np.shape(M4)[0] \n",
        "print(\"Overall dimention is: \", t_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrbU0aV1lX75"
      },
      "source": [
        "# Saving the four Matrices\n",
        "Saving the matrices named Mat_batch(no.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfifTHr6lowY"
      },
      "outputs": [],
      "source": [
        "np.save(\"drive/MyDrive/Project GCN Dataset/Mat_b1.npy\", M1)\n",
        "np.save(\"drive/MyDrive/Project GCN Dataset/Mat_b2.npy\", M2)\n",
        "np.save(\"drive/MyDrive/Project GCN Dataset/Mat_b3.npy\", M3)\n",
        "np.save(\"drive/MyDrive/Project GCN Dataset/Mat_b4.npy\", M4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNtE4-hmN0Nq"
      },
      "source": [
        "# Saving Matrix\n",
        "\n",
        "# MATRIX ALREADY SAVED\n",
        "# PLEASE DONOT RUN THIS CELL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XdyNtrDN0Nr"
      },
      "outputs": [],
      "source": [
        "print(\"Saving Matrix\")\n",
        "np.save(\"drive/MyDrive/Project GCN Dataset/Matrix.npy\", M)\n",
        "\n",
        "print(\"Saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDBgT62fN0Ns"
      },
      "source": [
        "# Loading Matrix\n",
        "Loading the sparce matrix in a variable A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Popt5iN0Nt",
        "outputId": "cb643646-a49c-445f-9c29-9d7e2c1a5bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing Sparse Matrix..\n",
            "[[0 1 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 1 0]]\n",
            "[[1 1 0 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 1 0 1]\n",
            " [0 0 0 ... 0 1 0]]\n",
            "[[0 1 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[0 1 1 ... 0 0 0]\n",
            " [1 0 1 ... 0 0 0]\n",
            " [1 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 1 0 1]\n",
            " [0 0 0 ... 0 1 0]]\n",
            "(5762, 5762)\n",
            "(5410, 5410)\n",
            "(7432, 7432)\n",
            "(2493, 2493)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# loading matrix\n",
        "A1 = np.load(\"/content/drive/MyDrive/Project GCN Dataset/Mat_b1.npy\")\n",
        "A2 = np.load(\"/content/drive/MyDrive/Project GCN Dataset/Mat_b2.npy\")\n",
        "A3 = np.load(\"/content/drive/MyDrive/Project GCN Dataset/Mat_b3.npy\")\n",
        "A4 = np.load(\"/content/drive/MyDrive/Project GCN Dataset/Mat_b4.npy\")\n",
        "print(\"Printing Sparse Matrix..\")\n",
        "print(A1)\n",
        "print(A2)\n",
        "print(A3)\n",
        "print(A4)\n",
        "print(np.shape(A1))\n",
        "print(np.shape(A2))\n",
        "print(np.shape(A3))\n",
        "print(np.shape(A4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oWMhfx0o5n8"
      },
      "source": [
        "# Checking Sparse Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uadt4RY4o800",
        "outputId": "2cdcd949-0d0d-4b4c-f92b-132d4aa82581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5762, 5762)\n",
            "(5410, 5410)\n",
            "(7432, 7432)\n",
            "(2493, 2493)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(A1)\n",
        "plt.matshow(A2)\n",
        "plt.matshow(A3)\n",
        "\n",
        "print(np.shape(A1))\n",
        "print(np.shape(A2))\n",
        "print(np.shape(A3))\n",
        "print(np.shape(A4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br5DRJSKn2ha"
      },
      "source": [
        "# Generating Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfSeOkKon5mi"
      },
      "outputs": [],
      "source": [
        "from numpy import nan\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def returnLabels(direc, files):\n",
        "    labels = []\n",
        "    for f in range(len(files)):\n",
        "        seenList = []\n",
        "        df = pd.read_csv(direc + files[f])\n",
        "        text = df['Object'].to_list()\n",
        "        T_labels = df['labels'].to_list()\n",
        "\n",
        "        for i in range(len(text)):\n",
        "            if(text[i] not in seenList):\n",
        "                labels.append(T_labels[i])\n",
        "            seenList.append(text[i])\n",
        "\n",
        "    return labels\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcOYerByN0Nv"
      },
      "source": [
        "# Encoding Labels\n",
        "1. Get a list of labels from CSV files.\n",
        "2. Catagorically encode the labels "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6o6X8zRN0Nx",
        "outputId": "bc388ca6-c2c8-40bc-cc9a-d05f8715074b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total labels are:  21097\n",
            "Encoding list..\n",
            "Total Encodings are:  21097\n",
            "Unique Encodings are:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
            "Size of batch1 matrix is:  5762\n",
            "Total encodings for batch1 matrix are:  5762\n",
            "Size of batch1 matrix is:  5762\n",
            "Total encodings for batch2 matrix are:  5410\n",
            "Size of batch1 matrix is:  5762\n",
            "Total encodings for batch3 matrix are:  7432\n",
            "Size of batch1 matrix is:  5762\n",
            "Total encodings for batch4 matrix are:  2493\n",
            "Total length 21097\n",
            "Encodings for Batch 1 Matrix is:  {2, 3, 5, 6, 8, 9, 10, 11}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labels = returnLabels(lab_files_path, files)\n",
        "print(\"Total labels are: \", len(labels))\n",
        "\n",
        "print(\"Encoding list..\")\n",
        "lab_encoder = LabelEncoder()\n",
        "encodings = lab_encoder.fit_transform(labels)\n",
        "print(\"Total Encodings are: \", len(encodings))\n",
        "\n",
        "\n",
        "# t_file = open(\"Encodings.txt\", \"w\")\n",
        "# for element in encodings:\n",
        "#     t_file.write(\"%i\\n\" % element)\n",
        "\n",
        "# t_file.close()\n",
        "\n",
        "\n",
        "uni_enc = set(encodings)\n",
        "print(\"Unique Encodings are: \", uni_enc)\n",
        "encodings = np.transpose(encodings)  \n",
        "\n",
        "# Encodings for Mat_b1 are\n",
        "e1_encodings_size = np.shape(A1)[0]\n",
        "print(\"Size of batch1 matrix is: \", e1_encodings_size)\n",
        "e1 = encodings[0:e1_encodings_size]\n",
        "print(\"Total encodings for batch1 matrix are: \", len(e1))\n",
        "\n",
        "# Encodings for Mat_b2 are\n",
        "e2_encodings_size = np.shape(A2)[0]\n",
        "print(\"Size of batch1 matrix is: \", e1_encodings_size)\n",
        "e2 = encodings[e1_encodings_size:e2_encodings_size+e1_encodings_size]\n",
        "print(\"Total encodings for batch2 matrix are: \", len(e2))\n",
        "\n",
        "# Encodings for Mat_b3 are\n",
        "e3_encodings_size = np.shape(A3)[0]\n",
        "start = e2_encodings_size+e1_encodings_size \n",
        "print(\"Size of batch1 matrix is: \", e1_encodings_size)\n",
        "e3 = encodings[start:start+e3_encodings_size]\n",
        "print(\"Total encodings for batch3 matrix are: \", len(e3))\n",
        "\n",
        "# Encodings for Mat_b4 are\n",
        "e4_encodings_size = np.shape(A4)[0]\n",
        "start += e3_encodings_size\n",
        "print(\"Size of batch1 matrix is: \", e1_encodings_size)\n",
        "e4 = encodings[start:start+e4_encodings_size]\n",
        "print(\"Total encodings for batch4 matrix are: \", len(e4))\n",
        "\n",
        "print(\"Total length\", (len(e1) + len(e2) + len(e3) +len(e4)))\n",
        "\n",
        "print(\"Encodings for Batch 1 Matrix is: \", set(e1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhFDji2YN0Ny"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iejwmS9VN0Nz",
        "outputId": "6a3aa4d9-063f-4549-b532-c4069376c026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries Imported..\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, MaxPool2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
        "from spektral.layers import GCNConv\n",
        "from sklearn.metrics import classification_report\n",
        "from spektral.utils import normalized_laplacian\n",
        "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"Libraries Imported..\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTQOoH9xN0N0"
      },
      "source": [
        "# Model Hyper-parameters\n",
        "Adding model hyper-parameters:\n",
        "1. Learning rate(At whar pace should the model be learning)\n",
        "2. Channels(Neurons)\n",
        "3. Dropout rate(Now many neurons should be active at a time)\n",
        "4. Epochs(How many times a data is passed through the model)\n",
        "5. Batch size(How much data should be fed to the model at a time)\n",
        "etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVOMWygNN0N0"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "\n",
        "channels = 32\n",
        "dropout = 0.5\n",
        "# learning_rate = 5e-4\n",
        "l2_reg = 0.001\n",
        "learning_rate = 0.005\n",
        "epochs = 200\n",
        "batch_size = 5762\n",
        "es_patience = 10\n",
        "\n",
        "out_classes = 12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UNUsu-PzHLh"
      },
      "source": [
        "# Getting Node Features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJWoN1DDzOU6",
        "outputId": "92a4898c-1462-43f3-e290-18aebc8e6758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing Feature Matrix..\n",
            "[[ 0.000e+00  0.000e+00]\n",
            " [ 1.000e+00 -1.000e+00]\n",
            " [ 2.000e+00 -2.000e+00]\n",
            " ...\n",
            " [ 5.407e+03 -5.407e+03]\n",
            " [ 5.408e+03 -5.408e+03]\n",
            " [ 5.409e+03 -5.409e+03]]\n",
            "Output feature representation..\n",
            "Prining features in an array [[7.81826347e-01 7.45754333e-01 6.21740461e-01 ... 1.34043824e-01\n",
            "  5.78167018e-01 0.00000000e+00]\n",
            " [9.37306322e-01 8.94060750e-01 7.45384530e-01 ... 1.60700806e-01\n",
            "  6.93145738e-01 0.00000000e+00]\n",
            " [9.12960703e-02 8.70838393e-02 7.26023892e-02 ... 1.56526759e-02\n",
            "  6.75141953e-02 0.00000000e+00]\n",
            " ...\n",
            " [8.97149884e+01 8.55757055e+01 7.13450479e+01 ... 1.53816000e+01\n",
            "  6.63449722e+01 0.00000000e+00]\n",
            " [8.97398873e+01 8.55994557e+01 7.13648485e+01 ... 1.53858689e+01\n",
            "  6.63633851e+01 0.00000000e+00]\n",
            " [8.97772357e+01 8.56350809e+01 7.13945495e+01 ... 1.53922723e+01\n",
            "  6.63910046e+01 0.00000000e+00]]\n",
            "Shape of vals is:  (5410, 8)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "def nodeFeatures(A):\n",
        "    # X = Features Matrix\n",
        "    X = np.matrix([[i, -i] for i in range(A.shape[0])], dtype=float)\n",
        "    print(\"Printing Feature Matrix..\")\n",
        "    print(X)\n",
        "\n",
        "    # Identity matrix of the same shape as adjacency matrix\n",
        "    I = np.matrix(np.eye(A.shape[0]))\n",
        "\n",
        "    # Self looping making node connections with themselves\n",
        "    # i.e. multiply the adjacency matrix with identity matrix\n",
        "    A_new = A + I\n",
        "\n",
        "    # Multiplying the self-looped graph with the feature matrix\n",
        "\n",
        "    # Stores the sum of array(Row wise) in a new array called D\n",
        "    D = np.array(np.sum(A, axis=0))[0]\n",
        "\n",
        "    # Making the diagonal matrix named D containing the elements of 1D array D\n",
        "    # D = np.matrix(np.diag(D))\n",
        "    # print(\"Printing the 2D array named D containing the elemnets of 1D D in diagonal\")\n",
        "    # print(D)\n",
        "\n",
        "    # Stores the degree of the graph in a 1D array called D\n",
        "    D = np.array(np.sum(A_new, axis=0))[0]\n",
        "    # Transforming that 1D array to a degree matrix\n",
        "    D = np.matrix(np.diag(D))\n",
        "    # print(\"Degree matrix of A_new multiplied by A_new..\")\n",
        "    D_new = D * A_new\n",
        "    # print(D_new)\n",
        "\n",
        "    # Weight Matrix\n",
        "    W0 = np.random.randn(X.shape[1], 8) * 0.01\n",
        "\n",
        "    print(\"Printing Weights\")\n",
        "    print(W0)\n",
        "\n",
        "    # Reducing feature of output feature representation..\n",
        "    print(\"Output feature representation..\")\n",
        "    final = D_new**-1 * A_new * X * W0\n",
        "\n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    H_1 = relu(final)\n",
        "    # print(\"After applying relu function..\")\n",
        "    # print(H_1)\n",
        "\n",
        "    output = H_1\n",
        "\n",
        "    # print(\"Printing A_new matrix..\")\n",
        "    # print(A_new)\n",
        "\n",
        "    G = nx.from_numpy_matrix(np.array(A_new))\n",
        "    # nx.draw_networkx_edges(G, pos=nx.spring_layout(\n",
        "    #     G), arrowstyle=\"<|-\", style=\"dashed\")\n",
        "    # plt.show()\n",
        "    # nx.draw(G)\n",
        "    # plt.savefig(\"/content/Sample Graph.png\")\n",
        "    feature_representations = {\n",
        "        node: np.array(output)[node]\n",
        "        for node in G.nodes()\n",
        "    }\n",
        "\n",
        "    features = np.array(feature_representations.values())\n",
        "\n",
        "    # print(\"Printing feature representation..\")\n",
        "    # print(features)\n",
        "\n",
        "    vals = []\n",
        "\n",
        "    for v in feature_representations.values():\n",
        "        vals.append(v)\n",
        "\n",
        "    vals = np.array(vals)\n",
        "\n",
        "    # print(\"Prining features in an array\", vals)\n",
        "\n",
        "    # print(\"Shape of vals is: \", np.shape(vals))\n",
        "\n",
        "    return vals\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U87KGv4sN0N1"
      },
      "source": [
        "# Model Definition\n",
        "3 GCN-Conv Layers & 2 Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "NZwuo9T0N0N1",
        "outputId": "a02465c2-5c33-4532-dd35-0b3bfc4261da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node has  8  features\n",
            "Total Nodes are:  7432\n",
            "Shape of X-in is:  (7432, 8)\n",
            "Shape of A-in is:  (7432, 7432)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(7432, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(7432, 7432)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_2 (GCNConv)            (None, 32)           288         input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_3 (GCNConv)            (None, 32)           1056        gcn_conv_2[0][0]                 \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32)           0           gcn_conv_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 512)          16896       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           16416       dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 12)           396         dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 35,052\n",
            "Trainable params: 35,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def Model(A):\n",
        "    N = A.shape[0]\n",
        "    F = nodeFeatures(A).shape[1]\n",
        "\n",
        "    # print(\"Node has \", F, \" features\")\n",
        "    # print(\"Total Nodes are: \", N)\n",
        "\n",
        "    fltr = normalized_laplacian(A)\n",
        "    X_in = Input(batch_size = N, shape=(F))\n",
        "    # print(\"Shape of X-in is: \", np.shape(X_in))\n",
        "\n",
        "    A_in = Input(tensor=sp_matrix_to_sp_tensor(fltr))\n",
        "    # print(\"Shape of A-in is: \", np.shape(A_in))\n",
        "\n",
        "    G1 = GCNConv(channels, activation='LeakyReLU', kernel_regularizer=l2(l2_reg), use_bias=True)([X_in, A_in])\n",
        "\n",
        "    G2 = GCNConv(channels, activation='LeakyReLU', kernel_regularizer=l2(l2_reg), use_bias=True)([G1, A_in])\n",
        "\n",
        "    flatten = Flatten()(G2)\n",
        "\n",
        "    D1 = Dense(512, activation='LeakyReLU')(flatten)\n",
        "\n",
        "    D2 = Dense(32, activation='LeakyReLU')(D1)\n",
        "\n",
        "\n",
        "    D2_out = Dense(out_classes, activation='softmax')(D2)\n",
        "\n",
        "    model = Model(inputs = [X_in, A_in], outputs=D2_out)\n",
        "    model.compile(optimizer = 'Adagrad', loss = 'sparse_categorical_crossentropy', weighted_metrics=['acc'])\n",
        "\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQcuJa7N0N2"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSKbBOwt7Cyd",
        "outputId": "315bdb51-3ef7-464c-f46e-a0dbe37d8336"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15208/2358056970.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb1_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodeFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb1_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodeFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb1_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodeFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "b1_features = nodeFeatures(A1)\n",
        "b2_features = nodeFeatures(A2)\n",
        "b3_features = nodeFeatures(A3)\n",
        "b4_features = nodeFeatures(A4)\n",
        "\n",
        "def trainModel(A, F, L):\n",
        "    # {2, 3, 5, 6, 8, 9, 10, 11}\n",
        "    W = {\n",
        "        0:np.random.rand(),\n",
        "        1:np.random.rand(),\n",
        "        2:np.random.rand(),\n",
        "        3:np.random.rand(),\n",
        "        4:np.random.rand(),\n",
        "        5:np.random.rand(),\n",
        "        6:np.random.rand(),\n",
        "        7:np.random.rand(),\n",
        "        8:np.random.rand(),\n",
        "        9:np.random.rand(),\n",
        "        10:np.random.rand(),\n",
        "        11:np.random.rand(),\n",
        "    }\n",
        "    model.fit([F, A],\n",
        "            L,\n",
        "            epochs = 200,\n",
        "            batch_size = np.shape(A),\n",
        "            class_weight=W,\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Batches\n",
        "We have a total of 4 dataset batches on which we will be training our model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training batch 1\n",
        "model = Model(A1)\n",
        "trainModel(A1, b1_features)\n",
        "\n",
        "# Training batch 2\n",
        "model = Model(A2)\n",
        "trainModel(A2, b2_features)\n",
        "\n",
        "# Training batch 3\n",
        "model = Model(A3)\n",
        "trainModel(A3, b3_features)\n",
        "\n",
        "# Training batch 1\n",
        "# model = Model(A1)\n",
        "# trainModel(A1, b1_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oF0YahQPIH9"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3MIIgQBPJ85"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Project GCN Dataset/IDS_Batch1_0.9267.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IDS_Model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "35146d2ce121e8e653791712ad16cca408ea08bd1c84e92938f653a743d84e6c"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('Graphs': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
