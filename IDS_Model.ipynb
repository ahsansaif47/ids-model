{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Label files are:  110\n",
      "Training Batch-1 files are:  45\n",
      "Training Batch-2 files are:  15\n",
      "Validation files are:  5\n",
      "Testing files are:  5\n"
     ]
    }
   ],
   "source": [
    "# Dataset loading\n",
    "import os\n",
    "\n",
    "dataset = \"./New-Dataset/\"\n",
    "# dataset = \"./Dataset (Labelled Images)/\"\n",
    "lab_files_path = dataset+\"labels/\"\n",
    "# lab_files_path = dataset+\"label/\"\n",
    "\n",
    "# total invoice files\n",
    "files = os.listdir(lab_files_path)\n",
    "\n",
    "\n",
    "# training set\n",
    "Batch_1 = files[:45]\n",
    "\n",
    "Batch_2 = files[45:60]\n",
    "\n",
    "# validation set\n",
    "valid_set = files[60:65]\n",
    "\n",
    "# test set\n",
    "test = files[95:100]\n",
    "\n",
    "print(\"Total Label files are: \", len(files))\n",
    "print(\"Training Batch-1 files are: \", len(Batch_1))\n",
    "print(\"Training Batch-2 files are: \", len(Batch_2))\n",
    "print(\"Validation files are: \", len(valid_set))\n",
    "print(\"Testing files are: \", len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.Image import Image\n",
    "from networkx.algorithms.shortest_paths.weighted import single_source_dijkstra\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.frame import DataFrame\n",
    "from PIL import Image\n",
    "import networkx as nx\n",
    "\n",
    "df = 0\n",
    "xMIN, xMAX = [], []\n",
    "yMIN, yMAX = [], []\n",
    "Text = []\n",
    "\n",
    "\n",
    "def findRight(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
    "    S_list = []\n",
    "    xmax = xMAX[df_ind]\n",
    "    ymin = yMIN[df_ind]\n",
    "    ymax = yMAX[df_ind]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if(xMIN[i] > xmax):\n",
    "            if not (yMIN[i] > ymax or yMAX[i] < ymin):\n",
    "                if(yMIN[i] <= ymin and yMAX[i] <= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] <= ymin and yMAX[i] >= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] >= ymin and yMAX[i] <= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] >= ymin and yMAX[i] >= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] == ymin and yMAX[i] == ymax):\n",
    "                    S_list.append(i)\n",
    "\n",
    "    if S_list:\n",
    "        consec = S_list[0]\n",
    "        for j in S_list:\n",
    "            if(xMIN[consec] > xMIN[j]):\n",
    "                consec = j\n",
    "        return consec\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "def findLeft(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
    "    S_list = []\n",
    "    xmin = xMIN[df_ind]\n",
    "    ymin = yMIN[df_ind]\n",
    "    ymax = yMAX[df_ind]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if(xMAX[i] < xmin):\n",
    "            if not (yMIN[i] > ymax or yMAX[i] < ymin):\n",
    "                if(yMIN[i] <= ymin and yMAX[i] <= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] <= ymin and yMAX[i] >= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] >= ymin and yMAX[i] <= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] >= ymin and yMAX[i] >= ymax):\n",
    "                    S_list.append(i)\n",
    "                elif (yMIN[i] == ymin and yMAX[i] == ymax):\n",
    "                    S_list.append(i)\n",
    "\n",
    "    if S_list:\n",
    "        consec = S_list[0]\n",
    "        for j in S_list:\n",
    "            if(xMAX[j] > xMAX[consec]):\n",
    "                consec = j\n",
    "        return consec\n",
    "    return -1\n",
    "\n",
    "\n",
    "def findUp(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
    "    S_list = []\n",
    "    xmin = xMIN[df_ind]\n",
    "    xmax = xMAX[df_ind]\n",
    "    ymin = yMIN[df_ind]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if(yMAX[i] < ymin):\n",
    "            if not (xMAX[i] < xmin or xMIN[i] > xmax):\n",
    "                if(xMIN[i] <= xmin and xMAX[i] <= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] <= xmin and xMAX[i] >= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] >= xmin and xMAX[i] <= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] >= xmin and xMAX[i] >= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] == xmin and xMAX[i] == xmax):\n",
    "                    S_list.append(i)\n",
    "\n",
    "    if S_list:\n",
    "        consec = S_list[0]\n",
    "        for j in S_list:\n",
    "            if(yMAX[j] > yMAX[consec]):\n",
    "                consec = j\n",
    "        return consec\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "def findDown(df, df_ind, xMIN, xMAX, yMIN, yMAX):\n",
    "    S_list = []\n",
    "    xmin = xMIN[df_ind]\n",
    "    xmax = xMAX[df_ind]\n",
    "    ymax = yMAX[df_ind]\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if(yMIN[i] > ymax):\n",
    "            if not (xMAX[i] < xmin or xMIN[i] > xmax):\n",
    "                if(xMIN[i] <= xmin and xMAX[i] <= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] <= xmin and xMAX[i] >= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] >= xmin and xMAX[i] <= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] >= xmin and xMAX[i] >= xmax):\n",
    "                    S_list.append(i)\n",
    "                elif (xMIN[i] == xmin and xMAX[i] == xmax):\n",
    "                    S_list.append(i)\n",
    "\n",
    "    if S_list:\n",
    "        consec = S_list[0]\n",
    "        for j in S_list:\n",
    "            if(yMIN[j] < yMIN[consec]):\n",
    "                consec = j\n",
    "        return consec\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "def makeGraph(df):\n",
    "    G = nx.Graph()\n",
    "    xMIN = df['xmin']\n",
    "    xMAX = df['xmax']\n",
    "    yMIN = df['ymin']\n",
    "    yMAX = df['ymax']\n",
    "    Text = df['Object']\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if findUp(df, i, xMIN, xMAX, yMIN, yMAX):\n",
    "            l = findUp(df, i, xMIN, xMAX, yMIN, yMAX)\n",
    "            if(l != -1):\n",
    "                text = Text[l]\n",
    "                G.add_edge(Text[i], text)\n",
    "        if findRight(df, i, xMIN, xMAX, yMIN, yMAX):\n",
    "            l = findRight(df, i, xMIN, xMAX, yMIN, yMAX)\n",
    "            if (l != -1):\n",
    "                text = Text[l]\n",
    "                G.add_edge(Text[i], text)\n",
    "        if findDown(df, i, xMIN, xMAX, yMIN, yMAX):\n",
    "            l = findDown(df, i, xMIN, xMAX, yMIN, yMAX)\n",
    "            if (l != -1):\n",
    "                text = Text[l]\n",
    "                G.add_edge(Text[i], text)\n",
    "        if findLeft(df, i, xMIN, xMAX, yMIN, yMAX):\n",
    "            l = findLeft(df, i, xMIN, xMAX, yMIN, yMAX)\n",
    "            if (l != -1):\n",
    "                text = Text[l]\n",
    "                G.add_edge(Text[i], text)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices Over Diagonal\n",
    "Place an incident Matrix over diagonal with existing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import SupportsAbs\n",
    "from numpy.core.fromnumeric import shape\n",
    "import numpy as np\n",
    "\n",
    "# Test Matrices\n",
    "# mat1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "# mat2 = np.array([[3, 2, 1, 7], [6, 5, 4, 9], [9, 8, 7, 4], [1, 5, 7, 2]])\n",
    "\n",
    "\n",
    "def alignDiagonally(M1, M2, prev_Len):\n",
    "    for i in range(prev_Len, np.shape(M1)[0]):\n",
    "        for j in range(prev_Len, np.shape(M1)[0]):\n",
    "            x = i - prev_Len\n",
    "            y = j - prev_Len\n",
    "            M1[i][j] = M2[x][y]\n",
    "\n",
    "    return M1\n",
    "\n",
    "\n",
    "def resizeMatrix(M, I):\n",
    "    oldMat_Len = np.shape(M)[0]\n",
    "    z = np.zeros((oldMat_Len, np.shape(I)[0]), dtype=np.int64)\n",
    "    newArray = np.append(M, z, axis=1)\n",
    "    M = newArray\n",
    "\n",
    "    # Appending 1D arrays of zeros in the original Matrix\n",
    "    # (i.e. the matrix in which we want to align othe rmatrices diagonally)\n",
    "    appZero = np.shape(I)[0]\n",
    "    x = oldMat_Len + appZero\n",
    "    L = np.zeros((np.shape(I)[0], x), dtype=np.int64)\n",
    "    newArray = np.append(M, L, axis=0)\n",
    "    M = newArray\n",
    "\n",
    "    M = alignDiagonally(M, I, oldMat_Len)\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Batch-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  1\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  2\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  3\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  4\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  5\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  6\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  7\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  8\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  9\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  10\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  11\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  12\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  13\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  14\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  15\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  16\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  17\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  18\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  19\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  20\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  21\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  22\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  23\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  24\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  25\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  26\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  27\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  28\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  29\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  30\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  31\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  32\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  33\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  34\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  35\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  36\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  37\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  38\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  39\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  40\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  41\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  42\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  43\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  44\n",
      "Dimentions of Batch 1 matrix is:  (4938, 4938)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import shape\n",
    "\n",
    "Z_file = lab_files_path + Batch_1[0]\n",
    "df = pd.read_csv(Z_file)\n",
    "G = makeGraph(df)\n",
    "M1 = nx.to_numpy_array(G, dtype=np.int32)\n",
    "\n",
    "for i in range(1, len(Batch_1)):\n",
    "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
    "    print(\"Iteration No.: \", i)\n",
    "    # Getting file\n",
    "    f = lab_files_path + Batch_1[i]\n",
    "    # Making dataframe of file\n",
    "    df = pd.read_csv(f)\n",
    "    # Making graph of the dataframe.\n",
    "    G = makeGraph(df)\n",
    "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
    "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
    "    # Now resizing the original sparce matrix with the new incident matrix\n",
    "    M1 = resizeMatrix(M1, I)\n",
    "\n",
    "print(\"Dimentions of Batch 1 matrix is: \", np.shape(M1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Batch-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  1\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  2\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  3\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  4\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  5\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  6\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  7\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  8\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  9\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  10\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  11\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  12\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  13\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  14\n",
      "Dimentions of Batch 2 matrix is:  (2460, 2460)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import shape\n",
    "\n",
    "Z1_file = lab_files_path + Batch_2[0]\n",
    "df = pd.read_csv(Z1_file)\n",
    "G = makeGraph(df)\n",
    "M2 = nx.to_numpy_array(G, dtype=np.int32)\n",
    "\n",
    "for i in range(1, len(Batch_2)):\n",
    "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
    "    print(\"Iteration No.: \", i)\n",
    "    # Getting file\n",
    "    f = lab_files_path + Batch_2[i]\n",
    "    # Making dataframe of file\n",
    "    df = pd.read_csv(f)\n",
    "    # Making graph of the dataframe.\n",
    "    G = makeGraph(df)\n",
    "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
    "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
    "    # Now resizing the original sparce matrix with the new incident matrix\n",
    "    M2 = resizeMatrix(M2, I)\n",
    "\n",
    "print(\"Dimentions of Batch 2 matrix is: \", np.shape(M2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  1\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  2\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  3\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  4\n",
      "Dimentions of Validation matrix is:  (427, 427)\n"
     ]
    }
   ],
   "source": [
    "Z3_file = lab_files_path + valid_set[0]\n",
    "df = pd.read_csv(Z3_file)\n",
    "G = makeGraph(df)\n",
    "M4 = nx.to_numpy_array(G, dtype=np.int32)\n",
    "\n",
    "for i in range(1, len(valid_set)):\n",
    "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
    "    print(\"Iteration No.: \", i)\n",
    "    # Getting file\n",
    "    f = lab_files_path + valid_set[i]\n",
    "    # Making dataframe of file\n",
    "    df = pd.read_csv(f)\n",
    "    # Making graph of the dataframe.\n",
    "    G = makeGraph(df)\n",
    "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
    "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
    "    # Now resizing the original sparce matrix with the new incident matrix\n",
    "    M4 = resizeMatrix(M4, I)\n",
    "\n",
    "print(\"Dimentions of Validation matrix is: \", np.shape(M4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  1\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  2\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  3\n",
      "\n",
      "= = = = = = = = = = = = = = = =\n",
      "Iteration No.:  4\n",
      "Dimentions of Batch 3 matrix is:  (1012, 1012)\n"
     ]
    }
   ],
   "source": [
    "Z4_file = lab_files_path + test[0]\n",
    "df = pd.read_csv(Z4_file)\n",
    "G = makeGraph(df)\n",
    "M5 = nx.to_numpy_array(G, dtype=np.int32)\n",
    "\n",
    "for i in range(1, len(test)):\n",
    "    print(\"\\n= = = = = = = = = = = = = = = =\")\n",
    "    print(\"Iteration No.: \", i)\n",
    "    # Getting file\n",
    "    f = lab_files_path + test[i]\n",
    "    # Making dataframe of file\n",
    "    df = pd.read_csv(f)\n",
    "    # Making graph of the dataframe.\n",
    "    G = makeGraph(df)\n",
    "    # Storing the graph as an incident matrix(an adjacency matrix)\n",
    "    I = nx.to_numpy_array(G, dtype=np.int32)\n",
    "    # Now resizing the original sparce matrix with the new incident matrix\n",
    "    M5 = resizeMatrix(M5, I)\n",
    "\n",
    "print(\"Dimentions of Batch 3 matrix is: \", np.shape(M5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Matrix\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Matrix\")\n",
    "# np.save(\"./Matrices/Matrix_b1.npy\", M1)\n",
    "np.save(\"./IDS Model File Matrices/Train_B1.npy\", M1)\n",
    "np.save(\"./IDS Model File Matrices/Train_B2.npy\", M2)\n",
    "np.save(\"./IDS Model File Matrices/Validation.npy\", M4)\n",
    "np.save(\"./IDS Model File Matrices/Test.npy\", M5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Training Batch_1\n",
      "[[1 1 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(4938, 4938)\n",
      "Printing Training Batch_2\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(2460, 2460)\n",
      "Printing Validation Batch\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(427, 427)\n",
      "Printing Test Batch\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]]\n",
      "(1012, 1012)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A1 = np.load(\"./IDS Model File Matrices/Train_B1.npy\")\n",
    "A2 = np.load(\"./IDS Model File Matrices/Train_B2.npy\")\n",
    "A4 = np.load(\"./IDS Model File Matrices/Validation.npy\")\n",
    "A5 = np.load(\"./IDS Model File Matrices/Test.npy\")\n",
    "\n",
    "print(\"Printing Training Batch_1\")\n",
    "print(A1)\n",
    "print(np.shape(A1))\n",
    "print(\"Printing Training Batch_2\")\n",
    "print(A2)\n",
    "print(np.shape(A2))\n",
    "print(\"Printing Validation Batch\")\n",
    "print(A4)\n",
    "print(np.shape(A4))\n",
    "print(\"Printing Test Batch\")\n",
    "print(A5)\n",
    "print(np.shape(A5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Train Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4938, 4938)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(A1)\n",
    "print(np.shape(A1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "\n",
    "\n",
    "def returnLabels(direc, files):\n",
    "    train_text = []\n",
    "    labels = []\n",
    "    for f in range(len(files)):\n",
    "        seenList = []\n",
    "        df = pd.read_csv(direc + files[f])\n",
    "        text = df['Object'].to_list()\n",
    "        T_labels = df['labels'].to_list()\n",
    "\n",
    "        for i in range(len(text)):\n",
    "            if(text[i] not in seenList):\n",
    "                labels.append(T_labels[i])\n",
    "                train_text.append(text[i])\n",
    "            seenList.append(text[i])\n",
    "\n",
    "    return labels, train_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Labels\n",
    "1. Get a list of labels from CSV files.\n",
    "2. Catagorically encode the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train labels are:  4938\n",
      "Total train text is:  4938\n",
      "Total train encodings are:  4938\n",
      "Unique train encodings are:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "=============================================\n",
      "Total train labels are:  2460\n",
      "Total train text is:  2460\n",
      "Total train encodings are:  2460\n",
      "Unique train encodings are:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "=============================================\n",
      "Total validation labels are:  427\n",
      "Total train encodings are:  427\n",
      "Unique validation encodings are:  {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "b1_labels, b1_text = returnLabels(lab_files_path, Batch_1)\n",
    "print(\"Total train labels are: \", len(b1_labels))\n",
    "print(\"Total train text is: \", len(b1_text))\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "b1_encodings = lab_encoder.fit_transform(b1_labels)\n",
    "print(\"Total train encodings are: \", len(b1_encodings))\n",
    "\n",
    "\n",
    "uni_b1_enc = set(b1_encodings)\n",
    "print(\"Unique train encodings are: \", uni_b1_enc)\n",
    "print(\"=============================================\")\n",
    "\n",
    "b2_labels, b2_text = returnLabels(lab_files_path, Batch_2)\n",
    "print(\"Total train labels are: \", len(b2_labels))\n",
    "print(\"Total train text is: \", len(b2_text))\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "b2_encodings = lab_encoder.fit_transform(b2_labels)\n",
    "print(\"Total train encodings are: \", len(b2_encodings))\n",
    "\n",
    "\n",
    "uni_b2_enc = set(b2_encodings)\n",
    "print(\"Unique train encodings are: \", uni_b2_enc)\n",
    "print(\"=============================================\")\n",
    "\n",
    "valid_labels, valid_text = returnLabels(lab_files_path, valid_set)\n",
    "print(\"Total validation labels are: \", len(valid_labels))\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "valid_encodings = lab_encoder.fit_transform(valid_labels)\n",
    "print(\"Total train encodings are: \", len(valid_encodings))\n",
    "\n",
    "\n",
    "uni_valid_enc = set(valid_encodings)\n",
    "print(\"Unique validation encodings are: \", uni_valid_enc)\n",
    "print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported..\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "from spektral.layers import GCNConv\n",
    "from sklearn.metrics import classification_report\n",
    "from spektral.utils import normalized_laplacian\n",
    "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Libraries Imported..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "dropout = 0.5\n",
    "learning_rate = 5e-4\n",
    "l2_reg = 0.001\n",
    "batch_size = 16\n",
    "es_patience = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings for train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4938\n",
      "Total train test is:  4938\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "Emb_Model = \"./Model/Word2Vec_Model.bin\"\n",
    "Loaded_model = Word2Vec.load(Emb_Model)\n",
    "\n",
    "train_embeddings = []\n",
    "for t in b1_text:\n",
    "    train_embeddings.append(Loaded_model.wv[t])\n",
    "    \n",
    "print(len(train_embeddings))\n",
    "    \n",
    "print(\"Total train test is: \", len(b1_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Total classes are:  10\n",
      "Shape of X-in is:  (None, 100)\n",
      "Shape of A-in is:  (None, None)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_6 (GCNConv)           (None, 32)           3232        ['input_7[0][0]',                \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " gcn_conv_7 (GCNConv)           (None, 32)           1056        ['gcn_conv_6[0][0]',             \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 32)           0           ['gcn_conv_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          4224        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 32)           4128        ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 10)           330         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,970\n",
      "Trainable params: 12,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N = A1.shape[0]\n",
    "F = np.shape(train_embeddings)[1]\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "print(F)\n",
    "\n",
    "classes = len(set(b1_labels))\n",
    "print(\"Total classes are: \", classes)\n",
    "\n",
    "# X_in = Input(batch_size=N, shape=(F))\n",
    "X_in = Input(batch_size=None, shape=(F,))\n",
    "print(\"Shape of X-in is: \", np.shape(X_in))\n",
    "\n",
    "# A_in = Input(tensor=sp_matrix_to_sp_tensor(fltr), sparse=True)\n",
    "# A_in = Input(shape=(None,), sparse=True)\n",
    "A_in = Input(shape=(None,))\n",
    "print(\"Shape of A-in is: \", np.shape(A_in))\n",
    "\n",
    "# D1 = Dropout(dropout)(X_in)\n",
    "# G1 = GCNConv(channels, activation='LeakyReLU',\n",
    "            #  kernel_regularizer=l2(l2_reg), use_bias=True)([X_in, A_in])\n",
    "G1 = GCNConv(32, activation='LeakyReLU', use_bias=True)([X_in, A_in])\n",
    "# D2 = Dropout(dropout)(G1)\n",
    "# G2 = GCNConv(channels, activation='LeakyReLU',\n",
    "#              kernel_regularizer=l2(l2_reg), use_bias=True)([G1, A_in])\n",
    "G2 = GCNConv(32, activation='LeakyReLU', use_bias=True)([G1, A_in])\n",
    "\n",
    "# # BN = BatchNormalization()(G2)\n",
    "flatten = Flatten()(G2)\n",
    "\n",
    "D1 = Dense(128, activation='relu')(flatten)\n",
    "# Dr1 = Dropout(dropout)(D1)\n",
    "D2 = Dense(32, activation='relu')(D1)\n",
    "# Dr2 = Dropout(dropout)(D2)\n",
    "# D3 = Dense(16, activation='LeakyReLU')(D2)\n",
    "\n",
    "D2_out = Dense(classes, activation='softmax')(D2)\n",
    "\n",
    "model = Model(inputs=[X_in, A_in], outputs=D2_out)\n",
    "# other loss = sparse_categorical_crossentropy\n",
    "# model.compile(optimizer='Adagrad',loss='sparse_categorical_crossentropy', weighted_metrics=['acc'])\n",
    "opt = tf.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy', weighted_metrics=['acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 3.4138 - acc: 0.1079 - val_loss: 3.5571 - val_acc: 0.1639\n",
      "Epoch 2/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.8965 - acc: 0.1130 - val_loss: 3.5372 - val_acc: 0.1429\n",
      "Epoch 3/1500\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.5699 - acc: 0.1262 - val_loss: 3.5975 - val_acc: 0.0984\n",
      "Epoch 4/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.4735 - acc: 0.1430 - val_loss: 3.6582 - val_acc: 0.0749\n",
      "Epoch 5/1500\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.4578 - acc: 0.1486 - val_loss: 3.6836 - val_acc: 0.0679\n",
      "Epoch 6/1500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.4508 - acc: 0.1600 - val_loss: 3.6644 - val_acc: 0.0609\n",
      "Epoch 7/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.4088 - acc: 0.1614 - val_loss: 3.6053 - val_acc: 0.0539\n",
      "Epoch 8/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.4170 - acc: 0.1691 - val_loss: 3.5172 - val_acc: 0.0492\n",
      "Epoch 9/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.3883 - acc: 0.1596 - val_loss: 3.4112 - val_acc: 0.0422\n",
      "Epoch 10/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.3437 - acc: 0.1659 - val_loss: 3.3035 - val_acc: 0.0375\n",
      "Epoch 11/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.3636 - acc: 0.1614 - val_loss: 3.2008 - val_acc: 0.0328\n",
      "Epoch 12/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.3127 - acc: 0.1624 - val_loss: 3.1116 - val_acc: 0.0234\n",
      "Epoch 13/1500\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.2804 - acc: 0.1638 - val_loss: 3.0386 - val_acc: 0.0328\n",
      "Epoch 14/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.2985 - acc: 0.1663 - val_loss: 2.9831 - val_acc: 0.0281\n",
      "Epoch 15/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.3199 - acc: 0.1495 - val_loss: 2.9459 - val_acc: 0.0351\n",
      "Epoch 16/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.2774 - acc: 0.1657 - val_loss: 2.9210 - val_acc: 0.0351\n",
      "Epoch 17/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.2963 - acc: 0.1507 - val_loss: 2.9071 - val_acc: 0.0351\n",
      "Epoch 18/1500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.2764 - acc: 0.1612 - val_loss: 2.9024 - val_acc: 0.0398\n",
      "Epoch 19/1500\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.2533 - acc: 0.1618 - val_loss: 2.9066 - val_acc: 0.0445\n",
      "Epoch 20/1500\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.2617 - acc: 0.1515 - val_loss: 2.9185 - val_acc: 0.0422\n",
      "Epoch 21/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.2328 - acc: 0.1618 - val_loss: 2.9374 - val_acc: 0.0422\n",
      "Epoch 22/1500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.2351 - acc: 0.1634 - val_loss: 2.9568 - val_acc: 0.0562\n",
      "Epoch 23/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.1975 - acc: 0.1802 - val_loss: 2.9765 - val_acc: 0.0562\n",
      "Epoch 24/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.1978 - acc: 0.1855 - val_loss: 2.9949 - val_acc: 0.0539\n",
      "Epoch 25/1500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.2062 - acc: 0.1754 - val_loss: 3.0093 - val_acc: 0.0539\n",
      "Epoch 26/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.2178 - acc: 0.1679 - val_loss: 3.0209 - val_acc: 0.0492\n",
      "Epoch 27/1500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.2073 - acc: 0.1802 - val_loss: 3.0294 - val_acc: 0.0562\n",
      "Epoch 28/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1904 - acc: 0.1760 - val_loss: 3.0344 - val_acc: 0.0539\n",
      "Epoch 29/1500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.2056 - acc: 0.1746 - val_loss: 3.0358 - val_acc: 0.0539\n",
      "Epoch 30/1500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.2058 - acc: 0.1713 - val_loss: 3.0346 - val_acc: 0.0562\n",
      "Epoch 31/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.1682 - acc: 0.1861 - val_loss: 3.0330 - val_acc: 0.0562\n",
      "Epoch 32/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.1699 - acc: 0.1812 - val_loss: 3.0319 - val_acc: 0.0492\n",
      "Epoch 33/1500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.1590 - acc: 0.1810 - val_loss: 3.0323 - val_acc: 0.0539\n",
      "Epoch 34/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.1565 - acc: 0.1857 - val_loss: 3.0347 - val_acc: 0.0562\n",
      "Epoch 35/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.1796 - acc: 0.1618 - val_loss: 3.0398 - val_acc: 0.0492\n",
      "Epoch 36/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.1605 - acc: 0.1819 - val_loss: 3.0469 - val_acc: 0.0492\n",
      "Epoch 37/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.1791 - acc: 0.1644 - val_loss: 3.0549 - val_acc: 0.0445\n",
      "Epoch 38/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.1509 - acc: 0.1825 - val_loss: 3.0636 - val_acc: 0.0515\n",
      "Epoch 39/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.1424 - acc: 0.1972 - val_loss: 3.0730 - val_acc: 0.0468\n",
      "Epoch 40/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.1422 - acc: 0.1841 - val_loss: 3.0853 - val_acc: 0.0539\n",
      "Epoch 41/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.1435 - acc: 0.1825 - val_loss: 3.0976 - val_acc: 0.0515\n",
      "Epoch 42/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.1509 - acc: 0.1750 - val_loss: 3.1073 - val_acc: 0.0515\n",
      "Epoch 43/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.1533 - acc: 0.1685 - val_loss: 3.1144 - val_acc: 0.0515\n",
      "Epoch 44/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.1398 - acc: 0.1766 - val_loss: 3.1183 - val_acc: 0.0539\n",
      "Epoch 45/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.1238 - acc: 0.1855 - val_loss: 3.1184 - val_acc: 0.0539\n",
      "Epoch 46/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.1384 - acc: 0.1796 - val_loss: 3.1175 - val_acc: 0.0539\n",
      "Epoch 47/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.1379 - acc: 0.1833 - val_loss: 3.1174 - val_acc: 0.0632\n",
      "Epoch 48/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1364 - acc: 0.1845 - val_loss: 3.1194 - val_acc: 0.0632\n",
      "Epoch 49/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1314 - acc: 0.1770 - val_loss: 3.1243 - val_acc: 0.0656\n",
      "Epoch 50/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.1197 - acc: 0.1819 - val_loss: 3.1327 - val_acc: 0.0679\n",
      "Epoch 51/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.1298 - acc: 0.1812 - val_loss: 3.1423 - val_acc: 0.0679\n",
      "Epoch 52/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.1176 - acc: 0.1885 - val_loss: 3.1548 - val_acc: 0.0679\n",
      "Epoch 53/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.1230 - acc: 0.1896 - val_loss: 3.1715 - val_acc: 0.0679\n",
      "Epoch 54/1500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 2.1276 - acc: 0.1896 - val_loss: 3.1886 - val_acc: 0.0679\n",
      "Epoch 55/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.1087 - acc: 0.1863 - val_loss: 3.2111 - val_acc: 0.0585\n",
      "Epoch 56/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.1284 - acc: 0.1879 - val_loss: 3.2308 - val_acc: 0.0539\n",
      "Epoch 57/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.1181 - acc: 0.1936 - val_loss: 3.2480 - val_acc: 0.0539\n",
      "Epoch 58/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.1145 - acc: 0.1857 - val_loss: 3.2627 - val_acc: 0.0515\n",
      "Epoch 59/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.1215 - acc: 0.1869 - val_loss: 3.2751 - val_acc: 0.0515\n",
      "Epoch 60/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.1229 - acc: 0.1796 - val_loss: 3.2805 - val_acc: 0.0492\n",
      "Epoch 61/1500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.1098 - acc: 0.2027 - val_loss: 3.2814 - val_acc: 0.0492\n",
      "Epoch 62/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.1140 - acc: 0.1934 - val_loss: 3.2796 - val_acc: 0.0515\n",
      "Epoch 63/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.1152 - acc: 0.1819 - val_loss: 3.2745 - val_acc: 0.0539\n",
      "Epoch 64/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1046 - acc: 0.1926 - val_loss: 3.2714 - val_acc: 0.0539\n",
      "Epoch 65/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.1100 - acc: 0.1962 - val_loss: 3.2744 - val_acc: 0.0515\n",
      "Epoch 66/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.1098 - acc: 0.1869 - val_loss: 3.2744 - val_acc: 0.0515\n",
      "Epoch 67/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1119 - acc: 0.1954 - val_loss: 3.2747 - val_acc: 0.0515\n",
      "Epoch 68/1500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.1041 - acc: 0.1898 - val_loss: 3.2771 - val_acc: 0.0539\n",
      "Epoch 69/1500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.1015 - acc: 0.1851 - val_loss: 3.2839 - val_acc: 0.0539\n",
      "Epoch 70/1500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.1100 - acc: 0.1983 - val_loss: 3.2899 - val_acc: 0.0515\n",
      "Epoch 71/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1031 - acc: 0.2009 - val_loss: 3.2973 - val_acc: 0.0515\n",
      "Epoch 72/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0938 - acc: 0.1924 - val_loss: 3.3039 - val_acc: 0.0515\n",
      "Epoch 73/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.1051 - acc: 0.1881 - val_loss: 3.3093 - val_acc: 0.0562\n",
      "Epoch 74/1500\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.1012 - acc: 0.2053 - val_loss: 3.3089 - val_acc: 0.0562\n",
      "Epoch 75/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.1027 - acc: 0.1930 - val_loss: 3.3054 - val_acc: 0.0562\n",
      "Epoch 76/1500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.0976 - acc: 0.1942 - val_loss: 3.3001 - val_acc: 0.0562\n",
      "Epoch 77/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1012 - acc: 0.1944 - val_loss: 3.2931 - val_acc: 0.0562\n",
      "Epoch 78/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0962 - acc: 0.1989 - val_loss: 3.2865 - val_acc: 0.0562\n",
      "Epoch 79/1500\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0951 - acc: 0.2041 - val_loss: 3.2826 - val_acc: 0.0562\n",
      "Epoch 80/1500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.1014 - acc: 0.1950 - val_loss: 3.2810 - val_acc: 0.0609\n",
      "Epoch 81/1500\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.1063 - acc: 0.1891 - val_loss: 3.2816 - val_acc: 0.0609\n",
      "Epoch 82/1500\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.0934 - acc: 0.2027 - val_loss: 3.2824 - val_acc: 0.0632\n",
      "Epoch 83/1500\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.0979 - acc: 0.1995 - val_loss: 3.2849 - val_acc: 0.0656\n",
      "Epoch 84/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0964 - acc: 0.1989 - val_loss: 3.2873 - val_acc: 0.0656\n",
      "Epoch 85/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0962 - acc: 0.1974 - val_loss: 3.2893 - val_acc: 0.0632\n",
      "Epoch 86/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0910 - acc: 0.1995 - val_loss: 3.2921 - val_acc: 0.0656\n",
      "Epoch 87/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0968 - acc: 0.1960 - val_loss: 3.2946 - val_acc: 0.0609\n",
      "Epoch 88/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.1013 - acc: 0.1989 - val_loss: 3.2932 - val_acc: 0.0585\n",
      "Epoch 89/1500\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.0972 - acc: 0.1944 - val_loss: 3.2902 - val_acc: 0.0585\n",
      "Epoch 90/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0953 - acc: 0.1956 - val_loss: 3.2888 - val_acc: 0.0585\n",
      "Epoch 91/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0980 - acc: 0.2086 - val_loss: 3.2895 - val_acc: 0.0585\n",
      "Epoch 92/1500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.0945 - acc: 0.2003 - val_loss: 3.2914 - val_acc: 0.0585\n",
      "Epoch 93/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0970 - acc: 0.2064 - val_loss: 3.2963 - val_acc: 0.0585\n",
      "Epoch 94/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0886 - acc: 0.2015 - val_loss: 3.3017 - val_acc: 0.0632\n",
      "Epoch 95/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0954 - acc: 0.2080 - val_loss: 3.3029 - val_acc: 0.0632\n",
      "Epoch 96/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0963 - acc: 0.1991 - val_loss: 3.3058 - val_acc: 0.0585\n",
      "Epoch 97/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0882 - acc: 0.1999 - val_loss: 3.3120 - val_acc: 0.0585\n",
      "Epoch 98/1500\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2.0949 - acc: 0.1908 - val_loss: 3.3232 - val_acc: 0.0585\n",
      "Epoch 99/1500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 2.0950 - acc: 0.2070 - val_loss: 3.3386 - val_acc: 0.0562\n",
      "Epoch 100/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0834 - acc: 0.2039 - val_loss: 3.3527 - val_acc: 0.0562\n",
      "Epoch 101/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0959 - acc: 0.2039 - val_loss: 3.3664 - val_acc: 0.0515\n",
      "Epoch 102/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0964 - acc: 0.1962 - val_loss: 3.3798 - val_acc: 0.0539\n",
      "Epoch 103/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0887 - acc: 0.2060 - val_loss: 3.3922 - val_acc: 0.0539\n",
      "Epoch 104/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0893 - acc: 0.2045 - val_loss: 3.3992 - val_acc: 0.0539\n",
      "Epoch 105/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0969 - acc: 0.1985 - val_loss: 3.3943 - val_acc: 0.0539\n",
      "Epoch 106/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0853 - acc: 0.2134 - val_loss: 3.3867 - val_acc: 0.0539\n",
      "Epoch 107/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0887 - acc: 0.2005 - val_loss: 3.3788 - val_acc: 0.0539\n",
      "Epoch 108/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0975 - acc: 0.1966 - val_loss: 3.3683 - val_acc: 0.0515\n",
      "Epoch 109/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0833 - acc: 0.2070 - val_loss: 3.3615 - val_acc: 0.0515\n",
      "Epoch 110/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0878 - acc: 0.2070 - val_loss: 3.3598 - val_acc: 0.0515\n",
      "Epoch 111/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0955 - acc: 0.1956 - val_loss: 3.3605 - val_acc: 0.0515\n",
      "Epoch 112/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0864 - acc: 0.1989 - val_loss: 3.3628 - val_acc: 0.0515\n",
      "Epoch 113/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0855 - acc: 0.2114 - val_loss: 3.3677 - val_acc: 0.0515\n",
      "Epoch 114/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0892 - acc: 0.2122 - val_loss: 3.3722 - val_acc: 0.0515\n",
      "Epoch 115/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0859 - acc: 0.2066 - val_loss: 3.3769 - val_acc: 0.0515\n",
      "Epoch 116/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0898 - acc: 0.2088 - val_loss: 3.3751 - val_acc: 0.0515\n",
      "Epoch 117/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0879 - acc: 0.1987 - val_loss: 3.3703 - val_acc: 0.0515\n",
      "Epoch 118/1500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 2.0939 - acc: 0.2098 - val_loss: 3.3692 - val_acc: 0.0515\n",
      "Epoch 119/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0906 - acc: 0.2021 - val_loss: 3.3682 - val_acc: 0.0515\n",
      "Epoch 120/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0820 - acc: 0.2096 - val_loss: 3.3679 - val_acc: 0.0515\n",
      "Epoch 121/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0891 - acc: 0.2053 - val_loss: 3.3694 - val_acc: 0.0515\n",
      "Epoch 122/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0891 - acc: 0.1983 - val_loss: 3.3707 - val_acc: 0.0515\n",
      "Epoch 123/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0855 - acc: 0.2080 - val_loss: 3.3710 - val_acc: 0.0515\n",
      "Epoch 124/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0829 - acc: 0.2025 - val_loss: 3.3681 - val_acc: 0.0515\n",
      "Epoch 125/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0822 - acc: 0.2041 - val_loss: 3.3624 - val_acc: 0.0515\n",
      "Epoch 126/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0942 - acc: 0.2155 - val_loss: 3.3513 - val_acc: 0.0515\n",
      "Epoch 127/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0829 - acc: 0.2070 - val_loss: 3.3422 - val_acc: 0.0539\n",
      "Epoch 128/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0800 - acc: 0.2086 - val_loss: 3.3358 - val_acc: 0.0539\n",
      "Epoch 129/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0807 - acc: 0.2064 - val_loss: 3.3318 - val_acc: 0.0539\n",
      "Epoch 130/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0850 - acc: 0.2064 - val_loss: 3.3305 - val_acc: 0.0562\n",
      "Epoch 131/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0863 - acc: 0.2051 - val_loss: 3.3337 - val_acc: 0.0562\n",
      "Epoch 132/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0841 - acc: 0.2058 - val_loss: 3.3394 - val_acc: 0.0562\n",
      "Epoch 133/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0830 - acc: 0.2009 - val_loss: 3.3501 - val_acc: 0.0539\n",
      "Epoch 134/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0828 - acc: 0.2088 - val_loss: 3.3655 - val_acc: 0.0539\n",
      "Epoch 135/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0787 - acc: 0.2058 - val_loss: 3.3816 - val_acc: 0.0515\n",
      "Epoch 136/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0895 - acc: 0.2039 - val_loss: 3.3945 - val_acc: 0.0515\n",
      "Epoch 137/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0801 - acc: 0.2108 - val_loss: 3.4040 - val_acc: 0.0515\n",
      "Epoch 138/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0769 - acc: 0.2080 - val_loss: 3.4175 - val_acc: 0.0539\n",
      "Epoch 139/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0900 - acc: 0.1985 - val_loss: 3.4247 - val_acc: 0.0539\n",
      "Epoch 140/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0795 - acc: 0.2090 - val_loss: 3.4283 - val_acc: 0.0539\n",
      "Epoch 141/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0785 - acc: 0.2060 - val_loss: 3.4355 - val_acc: 0.0539\n",
      "Epoch 142/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0818 - acc: 0.2047 - val_loss: 3.4430 - val_acc: 0.0562\n",
      "Epoch 143/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0808 - acc: 0.2120 - val_loss: 3.4444 - val_acc: 0.0562\n",
      "Epoch 144/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0823 - acc: 0.2141 - val_loss: 3.4415 - val_acc: 0.0539\n",
      "Epoch 145/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0852 - acc: 0.2066 - val_loss: 3.4360 - val_acc: 0.0539\n",
      "Epoch 146/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0793 - acc: 0.2153 - val_loss: 3.4279 - val_acc: 0.0539\n",
      "Epoch 147/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0840 - acc: 0.2001 - val_loss: 3.4247 - val_acc: 0.0492\n",
      "Epoch 148/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0800 - acc: 0.2124 - val_loss: 3.4230 - val_acc: 0.0492\n",
      "Epoch 149/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0841 - acc: 0.2049 - val_loss: 3.4225 - val_acc: 0.0492\n",
      "Epoch 150/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0854 - acc: 0.2104 - val_loss: 3.4192 - val_acc: 0.0492\n",
      "Epoch 151/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0805 - acc: 0.2078 - val_loss: 3.4168 - val_acc: 0.0492\n",
      "Epoch 152/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0887 - acc: 0.2049 - val_loss: 3.4139 - val_acc: 0.0492\n",
      "Epoch 153/1500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.0870 - acc: 0.2076 - val_loss: 3.4113 - val_acc: 0.0492\n",
      "Epoch 154/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0828 - acc: 0.2169 - val_loss: 3.4085 - val_acc: 0.0492\n",
      "Epoch 155/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0838 - acc: 0.2066 - val_loss: 3.4082 - val_acc: 0.0492\n",
      "Epoch 156/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0773 - acc: 0.2074 - val_loss: 3.4094 - val_acc: 0.0468\n",
      "Epoch 157/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0853 - acc: 0.2055 - val_loss: 3.4110 - val_acc: 0.0468\n",
      "Epoch 158/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0792 - acc: 0.2100 - val_loss: 3.4141 - val_acc: 0.0468\n",
      "Epoch 159/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0820 - acc: 0.2045 - val_loss: 3.4148 - val_acc: 0.0468\n",
      "Epoch 160/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0824 - acc: 0.2092 - val_loss: 3.4179 - val_acc: 0.0468\n",
      "Epoch 161/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0841 - acc: 0.2132 - val_loss: 3.4210 - val_acc: 0.0468\n",
      "Epoch 162/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0893 - acc: 0.2027 - val_loss: 3.4264 - val_acc: 0.0468\n",
      "Epoch 163/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0783 - acc: 0.2139 - val_loss: 3.4364 - val_acc: 0.0468\n",
      "Epoch 164/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0813 - acc: 0.2092 - val_loss: 3.4487 - val_acc: 0.0468\n",
      "Epoch 165/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0891 - acc: 0.2055 - val_loss: 3.4616 - val_acc: 0.0468\n",
      "Epoch 166/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0814 - acc: 0.2147 - val_loss: 3.4721 - val_acc: 0.0468\n",
      "Epoch 167/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0811 - acc: 0.2106 - val_loss: 3.4734 - val_acc: 0.0468\n",
      "Epoch 168/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0814 - acc: 0.2130 - val_loss: 3.4653 - val_acc: 0.0468\n",
      "Epoch 169/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0889 - acc: 0.2110 - val_loss: 3.4540 - val_acc: 0.0468\n",
      "Epoch 170/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0776 - acc: 0.2055 - val_loss: 3.4444 - val_acc: 0.0468\n",
      "Epoch 171/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0755 - acc: 0.2019 - val_loss: 3.4437 - val_acc: 0.0468\n",
      "Epoch 172/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0807 - acc: 0.1987 - val_loss: 3.4438 - val_acc: 0.0492\n",
      "Epoch 173/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0794 - acc: 0.2132 - val_loss: 3.4481 - val_acc: 0.0492\n",
      "Epoch 174/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0755 - acc: 0.2066 - val_loss: 3.4501 - val_acc: 0.0492\n",
      "Epoch 175/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0793 - acc: 0.2066 - val_loss: 3.4582 - val_acc: 0.0468\n",
      "Epoch 176/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0812 - acc: 0.2128 - val_loss: 3.4664 - val_acc: 0.0468\n",
      "Epoch 177/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0789 - acc: 0.2124 - val_loss: 3.4720 - val_acc: 0.0468\n",
      "Epoch 178/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0806 - acc: 0.2074 - val_loss: 3.4710 - val_acc: 0.0468\n",
      "Epoch 179/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0757 - acc: 0.2159 - val_loss: 3.4659 - val_acc: 0.0492\n",
      "Epoch 180/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0772 - acc: 0.2118 - val_loss: 3.4623 - val_acc: 0.0492\n",
      "Epoch 181/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0773 - acc: 0.2041 - val_loss: 3.4677 - val_acc: 0.0492\n",
      "Epoch 182/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0785 - acc: 0.2112 - val_loss: 3.4678 - val_acc: 0.0492\n",
      "Epoch 183/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0724 - acc: 0.2035 - val_loss: 3.4709 - val_acc: 0.0492\n",
      "Epoch 184/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0714 - acc: 0.2169 - val_loss: 3.4741 - val_acc: 0.0492\n",
      "Epoch 185/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0828 - acc: 0.1983 - val_loss: 3.4839 - val_acc: 0.0468\n",
      "Epoch 186/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0803 - acc: 0.2116 - val_loss: 3.4994 - val_acc: 0.0468\n",
      "Epoch 187/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0720 - acc: 0.2217 - val_loss: 3.5156 - val_acc: 0.0468\n",
      "Epoch 188/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0782 - acc: 0.2086 - val_loss: 3.5289 - val_acc: 0.0468\n",
      "Epoch 189/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0747 - acc: 0.2151 - val_loss: 3.5362 - val_acc: 0.0468\n",
      "Epoch 190/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0755 - acc: 0.2088 - val_loss: 3.5382 - val_acc: 0.0468\n",
      "Epoch 191/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0791 - acc: 0.2130 - val_loss: 3.5408 - val_acc: 0.0468\n",
      "Epoch 192/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0748 - acc: 0.2112 - val_loss: 3.5491 - val_acc: 0.0468\n",
      "Epoch 193/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0755 - acc: 0.2100 - val_loss: 3.5606 - val_acc: 0.0468\n",
      "Epoch 194/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0720 - acc: 0.2086 - val_loss: 3.5725 - val_acc: 0.0468\n",
      "Epoch 195/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0775 - acc: 0.2114 - val_loss: 3.5797 - val_acc: 0.0468\n",
      "Epoch 196/1500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.0717 - acc: 0.2165 - val_loss: 3.5925 - val_acc: 0.0468\n",
      "Epoch 197/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0767 - acc: 0.2132 - val_loss: 3.6000 - val_acc: 0.0468\n",
      "Epoch 198/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0786 - acc: 0.2017 - val_loss: 3.6062 - val_acc: 0.0468\n",
      "Epoch 199/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0672 - acc: 0.2189 - val_loss: 3.6109 - val_acc: 0.0468\n",
      "Epoch 200/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0742 - acc: 0.2088 - val_loss: 3.6159 - val_acc: 0.0468\n",
      "Epoch 201/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0797 - acc: 0.2118 - val_loss: 3.6196 - val_acc: 0.0468\n",
      "Epoch 202/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0806 - acc: 0.2098 - val_loss: 3.6248 - val_acc: 0.0468\n",
      "Epoch 203/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0767 - acc: 0.2110 - val_loss: 3.6226 - val_acc: 0.0468\n",
      "Epoch 204/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0789 - acc: 0.2082 - val_loss: 3.6205 - val_acc: 0.0468\n",
      "Epoch 205/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0713 - acc: 0.2124 - val_loss: 3.6232 - val_acc: 0.0468\n",
      "Epoch 206/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0754 - acc: 0.2072 - val_loss: 3.6257 - val_acc: 0.0468\n",
      "Epoch 207/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0782 - acc: 0.2090 - val_loss: 3.6230 - val_acc: 0.0468\n",
      "Epoch 208/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0765 - acc: 0.2114 - val_loss: 3.6213 - val_acc: 0.0468\n",
      "Epoch 209/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0722 - acc: 0.2126 - val_loss: 3.6166 - val_acc: 0.0468\n",
      "Epoch 210/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0787 - acc: 0.2110 - val_loss: 3.6057 - val_acc: 0.0468\n",
      "Epoch 211/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0862 - acc: 0.2070 - val_loss: 3.5914 - val_acc: 0.0468\n",
      "Epoch 212/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0746 - acc: 0.2139 - val_loss: 3.5839 - val_acc: 0.0468\n",
      "Epoch 213/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0759 - acc: 0.2128 - val_loss: 3.5728 - val_acc: 0.0468\n",
      "Epoch 214/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0717 - acc: 0.2151 - val_loss: 3.5647 - val_acc: 0.0468\n",
      "Epoch 215/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0764 - acc: 0.2120 - val_loss: 3.5578 - val_acc: 0.0468\n",
      "Epoch 216/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0703 - acc: 0.2211 - val_loss: 3.5536 - val_acc: 0.0468\n",
      "Epoch 217/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0729 - acc: 0.2116 - val_loss: 3.5479 - val_acc: 0.0468\n",
      "Epoch 218/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0716 - acc: 0.2070 - val_loss: 3.5414 - val_acc: 0.0468\n",
      "Epoch 219/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0765 - acc: 0.2078 - val_loss: 3.5352 - val_acc: 0.0468\n",
      "Epoch 220/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0701 - acc: 0.2143 - val_loss: 3.5266 - val_acc: 0.0468\n",
      "Epoch 221/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0812 - acc: 0.2074 - val_loss: 3.5138 - val_acc: 0.0468\n",
      "Epoch 222/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0753 - acc: 0.2078 - val_loss: 3.4953 - val_acc: 0.0468\n",
      "Epoch 223/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0747 - acc: 0.2084 - val_loss: 3.4732 - val_acc: 0.0468\n",
      "Epoch 224/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0726 - acc: 0.2110 - val_loss: 3.4546 - val_acc: 0.0468\n",
      "Epoch 225/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0768 - acc: 0.2153 - val_loss: 3.4335 - val_acc: 0.0468\n",
      "Epoch 226/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0755 - acc: 0.2136 - val_loss: 3.4143 - val_acc: 0.0468\n",
      "Epoch 227/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0767 - acc: 0.2070 - val_loss: 3.4032 - val_acc: 0.0468\n",
      "Epoch 228/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0713 - acc: 0.2149 - val_loss: 3.4011 - val_acc: 0.0468\n",
      "Epoch 229/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0706 - acc: 0.2074 - val_loss: 3.4030 - val_acc: 0.0468\n",
      "Epoch 230/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0787 - acc: 0.2096 - val_loss: 3.4067 - val_acc: 0.0468\n",
      "Epoch 231/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0705 - acc: 0.2112 - val_loss: 3.4115 - val_acc: 0.0468\n",
      "Epoch 232/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0698 - acc: 0.2199 - val_loss: 3.4177 - val_acc: 0.0468\n",
      "Epoch 233/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0686 - acc: 0.2197 - val_loss: 3.4141 - val_acc: 0.0468\n",
      "Epoch 234/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0789 - acc: 0.2092 - val_loss: 3.4059 - val_acc: 0.0468\n",
      "Epoch 235/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0767 - acc: 0.2116 - val_loss: 3.3994 - val_acc: 0.0468\n",
      "Epoch 236/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0749 - acc: 0.2070 - val_loss: 3.3941 - val_acc: 0.0468\n",
      "Epoch 237/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0783 - acc: 0.2112 - val_loss: 3.3905 - val_acc: 0.0468\n",
      "Epoch 238/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0717 - acc: 0.2128 - val_loss: 3.3879 - val_acc: 0.0468\n",
      "Epoch 239/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0725 - acc: 0.2181 - val_loss: 3.3913 - val_acc: 0.0468\n",
      "Epoch 240/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0684 - acc: 0.2136 - val_loss: 3.3969 - val_acc: 0.0468\n",
      "Epoch 241/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0692 - acc: 0.2122 - val_loss: 3.4003 - val_acc: 0.0468\n",
      "Epoch 242/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0727 - acc: 0.2159 - val_loss: 3.4019 - val_acc: 0.0468\n",
      "Epoch 243/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0777 - acc: 0.2100 - val_loss: 3.4015 - val_acc: 0.0468\n",
      "Epoch 244/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0696 - acc: 0.2155 - val_loss: 3.3954 - val_acc: 0.0468\n",
      "Epoch 245/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0684 - acc: 0.2143 - val_loss: 3.3903 - val_acc: 0.0468\n",
      "Epoch 246/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0682 - acc: 0.2191 - val_loss: 3.3824 - val_acc: 0.0468\n",
      "Epoch 247/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0658 - acc: 0.2286 - val_loss: 3.3723 - val_acc: 0.0468\n",
      "Epoch 248/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0728 - acc: 0.2203 - val_loss: 3.3732 - val_acc: 0.0468\n",
      "Epoch 249/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0739 - acc: 0.2118 - val_loss: 3.3779 - val_acc: 0.0468\n",
      "Epoch 250/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0699 - acc: 0.2128 - val_loss: 3.3901 - val_acc: 0.0468\n",
      "Epoch 251/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0707 - acc: 0.2155 - val_loss: 3.3979 - val_acc: 0.0468\n",
      "Epoch 252/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0699 - acc: 0.2153 - val_loss: 3.4076 - val_acc: 0.0468\n",
      "Epoch 253/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0644 - acc: 0.2193 - val_loss: 3.4163 - val_acc: 0.0468\n",
      "Epoch 254/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0681 - acc: 0.2108 - val_loss: 3.4256 - val_acc: 0.0468\n",
      "Epoch 255/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0737 - acc: 0.2096 - val_loss: 3.4294 - val_acc: 0.0468\n",
      "Epoch 256/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0646 - acc: 0.2183 - val_loss: 3.4296 - val_acc: 0.0468\n",
      "Epoch 257/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0720 - acc: 0.2207 - val_loss: 3.4221 - val_acc: 0.0468\n",
      "Epoch 258/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0693 - acc: 0.2175 - val_loss: 3.4164 - val_acc: 0.0468\n",
      "Epoch 259/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0711 - acc: 0.2108 - val_loss: 3.4153 - val_acc: 0.0468\n",
      "Epoch 260/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0703 - acc: 0.2100 - val_loss: 3.4191 - val_acc: 0.0468\n",
      "Epoch 261/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0712 - acc: 0.2199 - val_loss: 3.4243 - val_acc: 0.0468\n",
      "Epoch 262/1500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 2.0677 - acc: 0.2114 - val_loss: 3.4277 - val_acc: 0.0468\n",
      "Epoch 263/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0664 - acc: 0.2211 - val_loss: 3.4318 - val_acc: 0.0468\n",
      "Epoch 264/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0646 - acc: 0.2114 - val_loss: 3.4328 - val_acc: 0.0468\n",
      "Epoch 265/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0667 - acc: 0.2213 - val_loss: 3.4393 - val_acc: 0.0468\n",
      "Epoch 266/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0607 - acc: 0.2209 - val_loss: 3.4474 - val_acc: 0.0468\n",
      "Epoch 267/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0676 - acc: 0.2116 - val_loss: 3.4562 - val_acc: 0.0468\n",
      "Epoch 268/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0679 - acc: 0.2191 - val_loss: 3.4729 - val_acc: 0.0468\n",
      "Epoch 269/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0745 - acc: 0.2100 - val_loss: 3.4873 - val_acc: 0.0468\n",
      "Epoch 270/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0664 - acc: 0.2260 - val_loss: 3.4920 - val_acc: 0.0468\n",
      "Epoch 271/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0678 - acc: 0.2175 - val_loss: 3.4849 - val_acc: 0.0468\n",
      "Epoch 272/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0704 - acc: 0.2191 - val_loss: 3.4741 - val_acc: 0.0468\n",
      "Epoch 273/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0666 - acc: 0.2145 - val_loss: 3.4609 - val_acc: 0.0468\n",
      "Epoch 274/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0723 - acc: 0.2185 - val_loss: 3.4446 - val_acc: 0.0468\n",
      "Epoch 275/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0696 - acc: 0.2106 - val_loss: 3.4342 - val_acc: 0.0468\n",
      "Epoch 276/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0618 - acc: 0.2211 - val_loss: 3.4319 - val_acc: 0.0468\n",
      "Epoch 277/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0659 - acc: 0.2114 - val_loss: 3.4311 - val_acc: 0.0468\n",
      "Epoch 278/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0683 - acc: 0.2199 - val_loss: 3.4316 - val_acc: 0.0468\n",
      "Epoch 279/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0647 - acc: 0.2189 - val_loss: 3.4429 - val_acc: 0.0468\n",
      "Epoch 280/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0615 - acc: 0.2139 - val_loss: 3.4517 - val_acc: 0.0468\n",
      "Epoch 281/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0693 - acc: 0.2108 - val_loss: 3.4643 - val_acc: 0.0468\n",
      "Epoch 282/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0749 - acc: 0.2074 - val_loss: 3.4781 - val_acc: 0.0468\n",
      "Epoch 283/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0685 - acc: 0.2173 - val_loss: 3.4881 - val_acc: 0.0468\n",
      "Epoch 284/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0637 - acc: 0.2240 - val_loss: 3.4931 - val_acc: 0.0468\n",
      "Epoch 285/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0697 - acc: 0.2096 - val_loss: 3.4982 - val_acc: 0.0468\n",
      "Epoch 286/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0689 - acc: 0.2191 - val_loss: 3.4963 - val_acc: 0.0468\n",
      "Epoch 287/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0699 - acc: 0.2120 - val_loss: 3.4943 - val_acc: 0.0468\n",
      "Epoch 288/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0664 - acc: 0.2086 - val_loss: 3.4953 - val_acc: 0.0468\n",
      "Epoch 289/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0696 - acc: 0.2124 - val_loss: 3.5004 - val_acc: 0.0468\n",
      "Epoch 290/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0675 - acc: 0.2209 - val_loss: 3.5078 - val_acc: 0.0468\n",
      "Epoch 291/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0627 - acc: 0.2236 - val_loss: 3.5122 - val_acc: 0.0468\n",
      "Epoch 292/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0641 - acc: 0.2228 - val_loss: 3.5057 - val_acc: 0.0468\n",
      "Epoch 293/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0710 - acc: 0.2098 - val_loss: 3.5041 - val_acc: 0.0468\n",
      "Epoch 294/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0656 - acc: 0.2211 - val_loss: 3.4979 - val_acc: 0.0468\n",
      "Epoch 295/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0660 - acc: 0.2179 - val_loss: 3.4979 - val_acc: 0.0468\n",
      "Epoch 296/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0682 - acc: 0.2070 - val_loss: 3.4946 - val_acc: 0.0468\n",
      "Epoch 297/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0697 - acc: 0.2187 - val_loss: 3.4942 - val_acc: 0.0468\n",
      "Epoch 298/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0717 - acc: 0.2157 - val_loss: 3.4932 - val_acc: 0.0468\n",
      "Epoch 299/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0706 - acc: 0.2086 - val_loss: 3.4910 - val_acc: 0.0468\n",
      "Epoch 300/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0676 - acc: 0.2074 - val_loss: 3.4920 - val_acc: 0.0468\n",
      "Epoch 301/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0706 - acc: 0.2151 - val_loss: 3.4900 - val_acc: 0.0468\n",
      "Epoch 302/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0625 - acc: 0.2136 - val_loss: 3.4870 - val_acc: 0.0468\n",
      "Epoch 303/1500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.0668 - acc: 0.2151 - val_loss: 3.4921 - val_acc: 0.0468\n",
      "Epoch 304/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0690 - acc: 0.2092 - val_loss: 3.4969 - val_acc: 0.0468\n",
      "Epoch 305/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0652 - acc: 0.2161 - val_loss: 3.5013 - val_acc: 0.0468\n",
      "Epoch 306/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0655 - acc: 0.2167 - val_loss: 3.5043 - val_acc: 0.0468\n",
      "Epoch 307/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0656 - acc: 0.2139 - val_loss: 3.5027 - val_acc: 0.0468\n",
      "Epoch 308/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0622 - acc: 0.2167 - val_loss: 3.4950 - val_acc: 0.0468\n",
      "Epoch 309/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0679 - acc: 0.2145 - val_loss: 3.4855 - val_acc: 0.0468\n",
      "Epoch 310/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0643 - acc: 0.2116 - val_loss: 3.4720 - val_acc: 0.0468\n",
      "Epoch 311/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0598 - acc: 0.2185 - val_loss: 3.4624 - val_acc: 0.0468\n",
      "Epoch 312/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0694 - acc: 0.2092 - val_loss: 3.4576 - val_acc: 0.0468\n",
      "Epoch 313/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0658 - acc: 0.2078 - val_loss: 3.4606 - val_acc: 0.0468\n",
      "Epoch 314/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0664 - acc: 0.2195 - val_loss: 3.4643 - val_acc: 0.0468\n",
      "Epoch 315/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0647 - acc: 0.2161 - val_loss: 3.4655 - val_acc: 0.0468\n",
      "Epoch 316/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0630 - acc: 0.2163 - val_loss: 3.4697 - val_acc: 0.0468\n",
      "Epoch 317/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0627 - acc: 0.2145 - val_loss: 3.4728 - val_acc: 0.0468\n",
      "Epoch 318/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0659 - acc: 0.2139 - val_loss: 3.4709 - val_acc: 0.0468\n",
      "Epoch 319/1500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.0673 - acc: 0.2189 - val_loss: 3.4615 - val_acc: 0.0468\n",
      "Epoch 320/1500\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.0623 - acc: 0.2151 - val_loss: 3.4561 - val_acc: 0.0468\n",
      "Epoch 321/1500\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0665 - acc: 0.2145 - val_loss: 3.4503 - val_acc: 0.0468\n",
      "Epoch 322/1500\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.0609 - acc: 0.2246 - val_loss: 3.4495 - val_acc: 0.0468\n",
      "Epoch 323/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0612 - acc: 0.2195 - val_loss: 3.4475 - val_acc: 0.0468\n",
      "Epoch 324/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0639 - acc: 0.2175 - val_loss: 3.4546 - val_acc: 0.0468\n",
      "Epoch 325/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0613 - acc: 0.2157 - val_loss: 3.4676 - val_acc: 0.0468\n",
      "Epoch 326/1500\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.0624 - acc: 0.2209 - val_loss: 3.4776 - val_acc: 0.0468\n",
      "Epoch 327/1500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.0678 - acc: 0.2090 - val_loss: 3.4760 - val_acc: 0.0468\n",
      "Epoch 328/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0647 - acc: 0.2126 - val_loss: 3.4672 - val_acc: 0.0468\n",
      "Epoch 329/1500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.0662 - acc: 0.2183 - val_loss: 3.4568 - val_acc: 0.0468\n",
      "Epoch 330/1500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.0612 - acc: 0.2155 - val_loss: 3.4499 - val_acc: 0.0468\n",
      "Epoch 331/1500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.0671 - acc: 0.2122 - val_loss: 3.4445 - val_acc: 0.0468\n",
      "Epoch 332/1500\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.0655 - acc: 0.2224 - val_loss: 3.4410 - val_acc: 0.0468\n",
      "Epoch 333/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0660 - acc: 0.2211 - val_loss: 3.4393 - val_acc: 0.0468\n",
      "Epoch 334/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0648 - acc: 0.2217 - val_loss: 3.4437 - val_acc: 0.0468\n",
      "Epoch 335/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0624 - acc: 0.2175 - val_loss: 3.4556 - val_acc: 0.0468\n",
      "Epoch 336/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0665 - acc: 0.2171 - val_loss: 3.4644 - val_acc: 0.0468\n",
      "Epoch 337/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0582 - acc: 0.2220 - val_loss: 3.4758 - val_acc: 0.0468\n",
      "Epoch 338/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0602 - acc: 0.2126 - val_loss: 3.4842 - val_acc: 0.0468\n",
      "Epoch 339/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0657 - acc: 0.2120 - val_loss: 3.4812 - val_acc: 0.0468\n",
      "Epoch 340/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0638 - acc: 0.2114 - val_loss: 3.4741 - val_acc: 0.0468\n",
      "Epoch 341/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0652 - acc: 0.2122 - val_loss: 3.4692 - val_acc: 0.0468\n",
      "Epoch 342/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0690 - acc: 0.2086 - val_loss: 3.4698 - val_acc: 0.0468\n",
      "Epoch 343/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0596 - acc: 0.2189 - val_loss: 3.4658 - val_acc: 0.0468\n",
      "Epoch 344/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0651 - acc: 0.2161 - val_loss: 3.4598 - val_acc: 0.0468\n",
      "Epoch 345/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0623 - acc: 0.2108 - val_loss: 3.4551 - val_acc: 0.0468\n",
      "Epoch 346/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0601 - acc: 0.2159 - val_loss: 3.4495 - val_acc: 0.0468\n",
      "Epoch 347/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0615 - acc: 0.2203 - val_loss: 3.4539 - val_acc: 0.0468\n",
      "Epoch 348/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0624 - acc: 0.2124 - val_loss: 3.4580 - val_acc: 0.0468\n",
      "Epoch 349/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0546 - acc: 0.2232 - val_loss: 3.4597 - val_acc: 0.0468\n",
      "Epoch 350/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0585 - acc: 0.2197 - val_loss: 3.4613 - val_acc: 0.0468\n",
      "Epoch 351/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0565 - acc: 0.2244 - val_loss: 3.4584 - val_acc: 0.0468\n",
      "Epoch 352/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0622 - acc: 0.2175 - val_loss: 3.4539 - val_acc: 0.0468\n",
      "Epoch 353/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0530 - acc: 0.2215 - val_loss: 3.4495 - val_acc: 0.0468\n",
      "Epoch 354/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0556 - acc: 0.2153 - val_loss: 3.4473 - val_acc: 0.0468\n",
      "Epoch 355/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0596 - acc: 0.2136 - val_loss: 3.4491 - val_acc: 0.0468\n",
      "Epoch 356/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0587 - acc: 0.2234 - val_loss: 3.4471 - val_acc: 0.0468\n",
      "Epoch 357/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0652 - acc: 0.2191 - val_loss: 3.4458 - val_acc: 0.0468\n",
      "Epoch 358/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0576 - acc: 0.2213 - val_loss: 3.4456 - val_acc: 0.0468\n",
      "Epoch 359/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0615 - acc: 0.2163 - val_loss: 3.4458 - val_acc: 0.0468\n",
      "Epoch 360/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0579 - acc: 0.2197 - val_loss: 3.4428 - val_acc: 0.0468\n",
      "Epoch 361/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0578 - acc: 0.2183 - val_loss: 3.4409 - val_acc: 0.0468\n",
      "Epoch 362/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0626 - acc: 0.2159 - val_loss: 3.4391 - val_acc: 0.0468\n",
      "Epoch 363/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0569 - acc: 0.2193 - val_loss: 3.4318 - val_acc: 0.0468\n",
      "Epoch 364/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0639 - acc: 0.2147 - val_loss: 3.4210 - val_acc: 0.0468\n",
      "Epoch 365/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0684 - acc: 0.2082 - val_loss: 3.4101 - val_acc: 0.0468\n",
      "Epoch 366/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0653 - acc: 0.2120 - val_loss: 3.4072 - val_acc: 0.0468\n",
      "Epoch 367/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0622 - acc: 0.2141 - val_loss: 3.4106 - val_acc: 0.0468\n",
      "Epoch 368/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0626 - acc: 0.2236 - val_loss: 3.4211 - val_acc: 0.0468\n",
      "Epoch 369/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0607 - acc: 0.2169 - val_loss: 3.4314 - val_acc: 0.0468\n",
      "Epoch 370/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0644 - acc: 0.2179 - val_loss: 3.4390 - val_acc: 0.0468\n",
      "Epoch 371/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0639 - acc: 0.2169 - val_loss: 3.4366 - val_acc: 0.0468\n",
      "Epoch 372/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0652 - acc: 0.2136 - val_loss: 3.4296 - val_acc: 0.0468\n",
      "Epoch 373/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0629 - acc: 0.2120 - val_loss: 3.4195 - val_acc: 0.0468\n",
      "Epoch 374/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0648 - acc: 0.2179 - val_loss: 3.4140 - val_acc: 0.0468\n",
      "Epoch 375/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0618 - acc: 0.2222 - val_loss: 3.4134 - val_acc: 0.0468\n",
      "Epoch 376/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0584 - acc: 0.2183 - val_loss: 3.4137 - val_acc: 0.0468\n",
      "Epoch 377/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0633 - acc: 0.2141 - val_loss: 3.4179 - val_acc: 0.0468\n",
      "Epoch 378/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0605 - acc: 0.2136 - val_loss: 3.4196 - val_acc: 0.0468\n",
      "Epoch 379/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0625 - acc: 0.2163 - val_loss: 3.4218 - val_acc: 0.0468\n",
      "Epoch 380/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0574 - acc: 0.2217 - val_loss: 3.4180 - val_acc: 0.0468\n",
      "Epoch 381/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0634 - acc: 0.2066 - val_loss: 3.4121 - val_acc: 0.0468\n",
      "Epoch 382/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0586 - acc: 0.2234 - val_loss: 3.4034 - val_acc: 0.0468\n",
      "Epoch 383/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0582 - acc: 0.2207 - val_loss: 3.3927 - val_acc: 0.0468\n",
      "Epoch 384/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0560 - acc: 0.2254 - val_loss: 3.3810 - val_acc: 0.0468\n",
      "Epoch 385/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0576 - acc: 0.2226 - val_loss: 3.3731 - val_acc: 0.0468\n",
      "Epoch 386/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0545 - acc: 0.2217 - val_loss: 3.3713 - val_acc: 0.0468\n",
      "Epoch 387/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0563 - acc: 0.2171 - val_loss: 3.3811 - val_acc: 0.0468\n",
      "Epoch 388/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0633 - acc: 0.2151 - val_loss: 3.3974 - val_acc: 0.0468\n",
      "Epoch 389/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0585 - acc: 0.2213 - val_loss: 3.4113 - val_acc: 0.0468\n",
      "Epoch 390/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0600 - acc: 0.2234 - val_loss: 3.4209 - val_acc: 0.0468\n",
      "Epoch 391/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0608 - acc: 0.2260 - val_loss: 3.4189 - val_acc: 0.0468\n",
      "Epoch 392/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0633 - acc: 0.2120 - val_loss: 3.4070 - val_acc: 0.0468\n",
      "Epoch 393/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0581 - acc: 0.2220 - val_loss: 3.3964 - val_acc: 0.0468\n",
      "Epoch 394/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0614 - acc: 0.2108 - val_loss: 3.3921 - val_acc: 0.0468\n",
      "Epoch 395/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0658 - acc: 0.2114 - val_loss: 3.3964 - val_acc: 0.0468\n",
      "Epoch 396/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0584 - acc: 0.2167 - val_loss: 3.4091 - val_acc: 0.0468\n",
      "Epoch 397/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0615 - acc: 0.2236 - val_loss: 3.4229 - val_acc: 0.0468\n",
      "Epoch 398/1500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.0598 - acc: 0.2159 - val_loss: 3.4294 - val_acc: 0.0468\n",
      "Epoch 399/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0569 - acc: 0.2217 - val_loss: 3.4271 - val_acc: 0.0468\n",
      "Epoch 400/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0545 - acc: 0.2155 - val_loss: 3.4319 - val_acc: 0.0468\n",
      "Epoch 401/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0567 - acc: 0.2187 - val_loss: 3.4326 - val_acc: 0.0468\n",
      "Epoch 402/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0560 - acc: 0.2191 - val_loss: 3.4320 - val_acc: 0.0468\n",
      "Epoch 403/1500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0537 - acc: 0.222 - 0s 204ms/step - loss: 2.0537 - acc: 0.2224 - val_loss: 3.4263 - val_acc: 0.0492\n",
      "Epoch 404/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0569 - acc: 0.2163 - val_loss: 3.4223 - val_acc: 0.0492\n",
      "Epoch 405/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0575 - acc: 0.2234 - val_loss: 3.4219 - val_acc: 0.0492\n",
      "Epoch 406/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0610 - acc: 0.2118 - val_loss: 3.4188 - val_acc: 0.0492\n",
      "Epoch 407/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0600 - acc: 0.2161 - val_loss: 3.4122 - val_acc: 0.0468\n",
      "Epoch 408/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0564 - acc: 0.2207 - val_loss: 3.4033 - val_acc: 0.0468\n",
      "Epoch 409/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0607 - acc: 0.2171 - val_loss: 3.3939 - val_acc: 0.0468\n",
      "Epoch 410/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0575 - acc: 0.2209 - val_loss: 3.3862 - val_acc: 0.0468\n",
      "Epoch 411/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0638 - acc: 0.2157 - val_loss: 3.3745 - val_acc: 0.0468\n",
      "Epoch 412/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0608 - acc: 0.2232 - val_loss: 3.3557 - val_acc: 0.0468\n",
      "Epoch 413/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0536 - acc: 0.2234 - val_loss: 3.3422 - val_acc: 0.0468\n",
      "Epoch 414/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0572 - acc: 0.2215 - val_loss: 3.3325 - val_acc: 0.0468\n",
      "Epoch 415/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0565 - acc: 0.2191 - val_loss: 3.3296 - val_acc: 0.0468\n",
      "Epoch 416/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0575 - acc: 0.2155 - val_loss: 3.3336 - val_acc: 0.0468\n",
      "Epoch 417/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0576 - acc: 0.2177 - val_loss: 3.3450 - val_acc: 0.0468\n",
      "Epoch 418/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0605 - acc: 0.2167 - val_loss: 3.3596 - val_acc: 0.0468\n",
      "Epoch 419/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0590 - acc: 0.2141 - val_loss: 3.3693 - val_acc: 0.0468\n",
      "Epoch 420/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0588 - acc: 0.2171 - val_loss: 3.3713 - val_acc: 0.0468\n",
      "Epoch 421/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0606 - acc: 0.2102 - val_loss: 3.3703 - val_acc: 0.0468\n",
      "Epoch 422/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0584 - acc: 0.2187 - val_loss: 3.3648 - val_acc: 0.0468\n",
      "Epoch 423/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0562 - acc: 0.2171 - val_loss: 3.3658 - val_acc: 0.0468\n",
      "Epoch 424/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0538 - acc: 0.2228 - val_loss: 3.3681 - val_acc: 0.0468\n",
      "Epoch 425/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0563 - acc: 0.2197 - val_loss: 3.3670 - val_acc: 0.0468\n",
      "Epoch 426/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0600 - acc: 0.2222 - val_loss: 3.3709 - val_acc: 0.0468\n",
      "Epoch 427/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0566 - acc: 0.2167 - val_loss: 3.3768 - val_acc: 0.0468\n",
      "Epoch 428/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0548 - acc: 0.2199 - val_loss: 3.3863 - val_acc: 0.0468\n",
      "Epoch 429/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0556 - acc: 0.2167 - val_loss: 3.3964 - val_acc: 0.0468\n",
      "Epoch 430/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0512 - acc: 0.2250 - val_loss: 3.4037 - val_acc: 0.0468\n",
      "Epoch 431/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0595 - acc: 0.2130 - val_loss: 3.4065 - val_acc: 0.0468\n",
      "Epoch 432/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0526 - acc: 0.2222 - val_loss: 3.4049 - val_acc: 0.0468\n",
      "Epoch 433/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0605 - acc: 0.2181 - val_loss: 3.4072 - val_acc: 0.0468\n",
      "Epoch 434/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0527 - acc: 0.2173 - val_loss: 3.4097 - val_acc: 0.0468\n",
      "Epoch 435/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0573 - acc: 0.2195 - val_loss: 3.4121 - val_acc: 0.0468\n",
      "Epoch 436/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0521 - acc: 0.2199 - val_loss: 3.4195 - val_acc: 0.0468\n",
      "Epoch 437/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0623 - acc: 0.2161 - val_loss: 3.4306 - val_acc: 0.0468\n",
      "Epoch 438/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0564 - acc: 0.2193 - val_loss: 3.4283 - val_acc: 0.0468\n",
      "Epoch 439/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0581 - acc: 0.2238 - val_loss: 3.4300 - val_acc: 0.0468\n",
      "Epoch 440/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0494 - acc: 0.2252 - val_loss: 3.4282 - val_acc: 0.0468\n",
      "Epoch 441/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0607 - acc: 0.2149 - val_loss: 3.4272 - val_acc: 0.0468\n",
      "Epoch 442/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0587 - acc: 0.2153 - val_loss: 3.4303 - val_acc: 0.0468\n",
      "Epoch 443/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0568 - acc: 0.2171 - val_loss: 3.4329 - val_acc: 0.0468\n",
      "Epoch 444/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0554 - acc: 0.2181 - val_loss: 3.4453 - val_acc: 0.0468\n",
      "Epoch 445/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0620 - acc: 0.2130 - val_loss: 3.4486 - val_acc: 0.0468\n",
      "Epoch 446/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0588 - acc: 0.2147 - val_loss: 3.4454 - val_acc: 0.0468\n",
      "Epoch 447/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0579 - acc: 0.2177 - val_loss: 3.4350 - val_acc: 0.0468\n",
      "Epoch 448/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0564 - acc: 0.2155 - val_loss: 3.4197 - val_acc: 0.0468\n",
      "Epoch 449/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0586 - acc: 0.2084 - val_loss: 3.4053 - val_acc: 0.0468\n",
      "Epoch 450/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0536 - acc: 0.2211 - val_loss: 3.3931 - val_acc: 0.0468\n",
      "Epoch 451/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0529 - acc: 0.2165 - val_loss: 3.3868 - val_acc: 0.0468\n",
      "Epoch 452/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0546 - acc: 0.2234 - val_loss: 3.3891 - val_acc: 0.0468\n",
      "Epoch 453/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0542 - acc: 0.2224 - val_loss: 3.3967 - val_acc: 0.0468\n",
      "Epoch 454/1500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.0511 - acc: 0.2203 - val_loss: 3.4024 - val_acc: 0.0468\n",
      "Epoch 455/1500\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 2.0493 - acc: 0.2236 - val_loss: 3.3992 - val_acc: 0.0468\n",
      "Epoch 456/1500\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.0568 - acc: 0.2151 - val_loss: 3.3924 - val_acc: 0.0468\n",
      "Epoch 457/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0566 - acc: 0.2185 - val_loss: 3.3852 - val_acc: 0.0468\n",
      "Epoch 458/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0495 - acc: 0.2252 - val_loss: 3.3773 - val_acc: 0.0468\n",
      "Epoch 459/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0589 - acc: 0.2128 - val_loss: 3.3767 - val_acc: 0.0468\n",
      "Epoch 460/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0594 - acc: 0.2149 - val_loss: 3.3833 - val_acc: 0.0468\n",
      "Epoch 461/1500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 2.0555 - acc: 0.2130 - val_loss: 3.3919 - val_acc: 0.0468\n",
      "Epoch 462/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0502 - acc: 0.2272 - val_loss: 3.3971 - val_acc: 0.0468\n",
      "Epoch 463/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0525 - acc: 0.2167 - val_loss: 3.3965 - val_acc: 0.0468\n",
      "Epoch 464/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0545 - acc: 0.2203 - val_loss: 3.3912 - val_acc: 0.0468\n",
      "Epoch 465/1500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.0596 - acc: 0.2118 - val_loss: 3.3973 - val_acc: 0.0468\n",
      "Epoch 466/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0587 - acc: 0.2151 - val_loss: 3.4022 - val_acc: 0.0468\n",
      "Epoch 467/1500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.0534 - acc: 0.2226 - val_loss: 3.4054 - val_acc: 0.0468\n",
      "Epoch 468/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0562 - acc: 0.2177 - val_loss: 3.4009 - val_acc: 0.0468\n",
      "Epoch 469/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0528 - acc: 0.2246 - val_loss: 3.3925 - val_acc: 0.0468\n",
      "Epoch 470/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0556 - acc: 0.2171 - val_loss: 3.3836 - val_acc: 0.0468\n",
      "Epoch 471/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0543 - acc: 0.2220 - val_loss: 3.3756 - val_acc: 0.0468\n",
      "Epoch 472/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0441 - acc: 0.2232 - val_loss: 3.3662 - val_acc: 0.0468\n",
      "Epoch 473/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0609 - acc: 0.2128 - val_loss: 3.3683 - val_acc: 0.0468\n",
      "Epoch 474/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0552 - acc: 0.2165 - val_loss: 3.3668 - val_acc: 0.0468\n",
      "Epoch 475/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0519 - acc: 0.2171 - val_loss: 3.3684 - val_acc: 0.0468\n",
      "Epoch 476/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0526 - acc: 0.2189 - val_loss: 3.3680 - val_acc: 0.0468\n",
      "Epoch 477/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0518 - acc: 0.2254 - val_loss: 3.3678 - val_acc: 0.0468\n",
      "Epoch 478/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0492 - acc: 0.2234 - val_loss: 3.3646 - val_acc: 0.0468\n",
      "Epoch 479/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0532 - acc: 0.2191 - val_loss: 3.3585 - val_acc: 0.0468\n",
      "Epoch 480/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0521 - acc: 0.2238 - val_loss: 3.3579 - val_acc: 0.0468\n",
      "Epoch 481/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0526 - acc: 0.2201 - val_loss: 3.3589 - val_acc: 0.0468\n",
      "Epoch 482/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0543 - acc: 0.2155 - val_loss: 3.3607 - val_acc: 0.0468\n",
      "Epoch 483/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0533 - acc: 0.2254 - val_loss: 3.3617 - val_acc: 0.0468\n",
      "Epoch 484/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0541 - acc: 0.2104 - val_loss: 3.3694 - val_acc: 0.0468\n",
      "Epoch 485/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0555 - acc: 0.2173 - val_loss: 3.3759 - val_acc: 0.0468\n",
      "Epoch 486/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0477 - acc: 0.2260 - val_loss: 3.3730 - val_acc: 0.0468\n",
      "Epoch 487/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0605 - acc: 0.2112 - val_loss: 3.3759 - val_acc: 0.0468\n",
      "Epoch 488/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0582 - acc: 0.2136 - val_loss: 3.3816 - val_acc: 0.0468\n",
      "Epoch 489/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0514 - acc: 0.2292 - val_loss: 3.3939 - val_acc: 0.0468\n",
      "Epoch 490/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0565 - acc: 0.2143 - val_loss: 3.4038 - val_acc: 0.0468\n",
      "Epoch 491/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0523 - acc: 0.2246 - val_loss: 3.4105 - val_acc: 0.0468\n",
      "Epoch 492/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0504 - acc: 0.2230 - val_loss: 3.4098 - val_acc: 0.0468\n",
      "Epoch 493/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0527 - acc: 0.2153 - val_loss: 3.4060 - val_acc: 0.0468\n",
      "Epoch 494/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0554 - acc: 0.2165 - val_loss: 3.4073 - val_acc: 0.0468\n",
      "Epoch 495/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0558 - acc: 0.2161 - val_loss: 3.4153 - val_acc: 0.0468\n",
      "Epoch 496/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0500 - acc: 0.2238 - val_loss: 3.4246 - val_acc: 0.0468\n",
      "Epoch 497/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0567 - acc: 0.2118 - val_loss: 3.4345 - val_acc: 0.0468\n",
      "Epoch 498/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0502 - acc: 0.2199 - val_loss: 3.4424 - val_acc: 0.0468\n",
      "Epoch 499/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0528 - acc: 0.2199 - val_loss: 3.4503 - val_acc: 0.0468\n",
      "Epoch 500/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0496 - acc: 0.2272 - val_loss: 3.4502 - val_acc: 0.0468\n",
      "Epoch 501/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0508 - acc: 0.2244 - val_loss: 3.4414 - val_acc: 0.0468\n",
      "Epoch 502/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0530 - acc: 0.2177 - val_loss: 3.4325 - val_acc: 0.0468\n",
      "Epoch 503/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0555 - acc: 0.2181 - val_loss: 3.4352 - val_acc: 0.0468\n",
      "Epoch 504/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0558 - acc: 0.2163 - val_loss: 3.4443 - val_acc: 0.0468\n",
      "Epoch 505/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0554 - acc: 0.2171 - val_loss: 3.4576 - val_acc: 0.0468\n",
      "Epoch 506/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0518 - acc: 0.2276 - val_loss: 3.4609 - val_acc: 0.0468\n",
      "Epoch 507/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0528 - acc: 0.2246 - val_loss: 3.4563 - val_acc: 0.0468\n",
      "Epoch 508/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0504 - acc: 0.2171 - val_loss: 3.4434 - val_acc: 0.0468\n",
      "Epoch 509/1500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.0550 - acc: 0.2159 - val_loss: 3.4230 - val_acc: 0.0468\n",
      "Epoch 510/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0494 - acc: 0.2215 - val_loss: 3.4067 - val_acc: 0.0468\n",
      "Epoch 511/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0543 - acc: 0.2173 - val_loss: 3.3995 - val_acc: 0.0492\n",
      "Epoch 512/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0547 - acc: 0.2220 - val_loss: 3.3913 - val_acc: 0.0468\n",
      "Epoch 513/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0508 - acc: 0.2268 - val_loss: 3.3871 - val_acc: 0.0468\n",
      "Epoch 514/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0545 - acc: 0.2153 - val_loss: 3.3856 - val_acc: 0.0468\n",
      "Epoch 515/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0493 - acc: 0.2252 - val_loss: 3.3762 - val_acc: 0.0468\n",
      "Epoch 516/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0563 - acc: 0.2171 - val_loss: 3.3623 - val_acc: 0.0468\n",
      "Epoch 517/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0508 - acc: 0.2187 - val_loss: 3.3514 - val_acc: 0.0468\n",
      "Epoch 518/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0576 - acc: 0.2100 - val_loss: 3.3441 - val_acc: 0.0468\n",
      "Epoch 519/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0509 - acc: 0.2234 - val_loss: 3.3370 - val_acc: 0.0468\n",
      "Epoch 520/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0519 - acc: 0.2114 - val_loss: 3.3323 - val_acc: 0.0468\n",
      "Epoch 521/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0534 - acc: 0.2118 - val_loss: 3.3234 - val_acc: 0.0468\n",
      "Epoch 522/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0515 - acc: 0.2159 - val_loss: 3.3102 - val_acc: 0.0468\n",
      "Epoch 523/1500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 2.0528 - acc: 0.2175 - val_loss: 3.2998 - val_acc: 0.0468\n",
      "Epoch 524/1500\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.0558 - acc: 0.2139 - val_loss: 3.2915 - val_acc: 0.0468\n",
      "Epoch 525/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0503 - acc: 0.2234 - val_loss: 3.2834 - val_acc: 0.0468\n",
      "Epoch 526/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0570 - acc: 0.2136 - val_loss: 3.2787 - val_acc: 0.0468\n",
      "Epoch 527/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0543 - acc: 0.2183 - val_loss: 3.2783 - val_acc: 0.0468\n",
      "Epoch 528/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0518 - acc: 0.2207 - val_loss: 3.2763 - val_acc: 0.0445\n",
      "Epoch 529/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0518 - acc: 0.2181 - val_loss: 3.2835 - val_acc: 0.0468\n",
      "Epoch 530/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0519 - acc: 0.2213 - val_loss: 3.2873 - val_acc: 0.0468\n",
      "Epoch 531/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0563 - acc: 0.2149 - val_loss: 3.2840 - val_acc: 0.0468\n",
      "Epoch 532/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0537 - acc: 0.2181 - val_loss: 3.2764 - val_acc: 0.0445\n",
      "Epoch 533/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0501 - acc: 0.2203 - val_loss: 3.2674 - val_acc: 0.0468\n",
      "Epoch 534/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0544 - acc: 0.2228 - val_loss: 3.2611 - val_acc: 0.0468\n",
      "Epoch 535/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0557 - acc: 0.2153 - val_loss: 3.2625 - val_acc: 0.0468\n",
      "Epoch 536/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0509 - acc: 0.2195 - val_loss: 3.2659 - val_acc: 0.0445\n",
      "Epoch 537/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0513 - acc: 0.2171 - val_loss: 3.2780 - val_acc: 0.0468\n",
      "Epoch 538/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0469 - acc: 0.2264 - val_loss: 3.2957 - val_acc: 0.0468\n",
      "Epoch 539/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0529 - acc: 0.2179 - val_loss: 3.3081 - val_acc: 0.0468\n",
      "Epoch 540/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0575 - acc: 0.2151 - val_loss: 3.3119 - val_acc: 0.0468\n",
      "Epoch 541/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0543 - acc: 0.2217 - val_loss: 3.3074 - val_acc: 0.0468\n",
      "Epoch 542/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0504 - acc: 0.2191 - val_loss: 3.3022 - val_acc: 0.0468\n",
      "Epoch 543/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0497 - acc: 0.2195 - val_loss: 3.2932 - val_acc: 0.0492\n",
      "Epoch 544/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0546 - acc: 0.2175 - val_loss: 3.2938 - val_acc: 0.0468\n",
      "Epoch 545/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0505 - acc: 0.2161 - val_loss: 3.3102 - val_acc: 0.0468\n",
      "Epoch 546/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0463 - acc: 0.2207 - val_loss: 3.3313 - val_acc: 0.0468\n",
      "Epoch 547/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0531 - acc: 0.2114 - val_loss: 3.3482 - val_acc: 0.0468\n",
      "Epoch 548/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0511 - acc: 0.2161 - val_loss: 3.3617 - val_acc: 0.0468\n",
      "Epoch 549/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0514 - acc: 0.2213 - val_loss: 3.3637 - val_acc: 0.0468\n",
      "Epoch 550/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0517 - acc: 0.2151 - val_loss: 3.3608 - val_acc: 0.0468\n",
      "Epoch 551/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0485 - acc: 0.2236 - val_loss: 3.3505 - val_acc: 0.0468\n",
      "Epoch 552/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0543 - acc: 0.2215 - val_loss: 3.3481 - val_acc: 0.0468\n",
      "Epoch 553/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0506 - acc: 0.2211 - val_loss: 3.3466 - val_acc: 0.0468\n",
      "Epoch 554/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0522 - acc: 0.2171 - val_loss: 3.3499 - val_acc: 0.0468\n",
      "Epoch 555/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0504 - acc: 0.2228 - val_loss: 3.3554 - val_acc: 0.0468\n",
      "Epoch 556/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0554 - acc: 0.2185 - val_loss: 3.3639 - val_acc: 0.0468\n",
      "Epoch 557/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0516 - acc: 0.2149 - val_loss: 3.3683 - val_acc: 0.0468\n",
      "Epoch 558/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0500 - acc: 0.2282 - val_loss: 3.3593 - val_acc: 0.0468\n",
      "Epoch 559/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0496 - acc: 0.2217 - val_loss: 3.3478 - val_acc: 0.0468\n",
      "Epoch 560/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0479 - acc: 0.2209 - val_loss: 3.3280 - val_acc: 0.0492\n",
      "Epoch 561/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0512 - acc: 0.2177 - val_loss: 3.3107 - val_acc: 0.0492\n",
      "Epoch 562/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0487 - acc: 0.2181 - val_loss: 3.3009 - val_acc: 0.0492\n",
      "Epoch 563/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0517 - acc: 0.2191 - val_loss: 3.2938 - val_acc: 0.0468\n",
      "Epoch 564/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0518 - acc: 0.2122 - val_loss: 3.2909 - val_acc: 0.0468\n",
      "Epoch 565/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0516 - acc: 0.2195 - val_loss: 3.2912 - val_acc: 0.0468\n",
      "Epoch 566/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0492 - acc: 0.2240 - val_loss: 3.2873 - val_acc: 0.0468\n",
      "Epoch 567/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0510 - acc: 0.2163 - val_loss: 3.2727 - val_acc: 0.0468\n",
      "Epoch 568/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0502 - acc: 0.2222 - val_loss: 3.2597 - val_acc: 0.0468\n",
      "Epoch 569/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0531 - acc: 0.2171 - val_loss: 3.2491 - val_acc: 0.0468\n",
      "Epoch 570/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0493 - acc: 0.2234 - val_loss: 3.2434 - val_acc: 0.0468\n",
      "Epoch 571/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0514 - acc: 0.2116 - val_loss: 3.2515 - val_acc: 0.0468\n",
      "Epoch 572/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0522 - acc: 0.2199 - val_loss: 3.2642 - val_acc: 0.0468\n",
      "Epoch 573/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0510 - acc: 0.2207 - val_loss: 3.2751 - val_acc: 0.0468\n",
      "Epoch 574/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0510 - acc: 0.2147 - val_loss: 3.2776 - val_acc: 0.0468\n",
      "Epoch 575/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0518 - acc: 0.2193 - val_loss: 3.2733 - val_acc: 0.0468\n",
      "Epoch 576/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0500 - acc: 0.2272 - val_loss: 3.2617 - val_acc: 0.0492\n",
      "Epoch 577/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0529 - acc: 0.2211 - val_loss: 3.2520 - val_acc: 0.0492\n",
      "Epoch 578/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0543 - acc: 0.2183 - val_loss: 3.2416 - val_acc: 0.0492\n",
      "Epoch 579/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0493 - acc: 0.2165 - val_loss: 3.2395 - val_acc: 0.0492\n",
      "Epoch 580/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0506 - acc: 0.2167 - val_loss: 3.2393 - val_acc: 0.0492\n",
      "Epoch 581/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0516 - acc: 0.2234 - val_loss: 3.2373 - val_acc: 0.0468\n",
      "Epoch 582/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0493 - acc: 0.2262 - val_loss: 3.2359 - val_acc: 0.0468\n",
      "Epoch 583/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0499 - acc: 0.2240 - val_loss: 3.2307 - val_acc: 0.0468\n",
      "Epoch 584/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0501 - acc: 0.2226 - val_loss: 3.2241 - val_acc: 0.0468\n",
      "Epoch 585/1500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.0506 - acc: 0.2234 - val_loss: 3.2095 - val_acc: 0.0468\n",
      "Epoch 586/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0527 - acc: 0.2305 - val_loss: 3.1979 - val_acc: 0.0468\n",
      "Epoch 587/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0476 - acc: 0.2161 - val_loss: 3.1981 - val_acc: 0.0468\n",
      "Epoch 588/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0495 - acc: 0.2226 - val_loss: 3.2063 - val_acc: 0.0468\n",
      "Epoch 589/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0496 - acc: 0.2254 - val_loss: 3.2125 - val_acc: 0.0468\n",
      "Epoch 590/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0506 - acc: 0.2228 - val_loss: 3.2162 - val_acc: 0.0468\n",
      "Epoch 591/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0499 - acc: 0.2205 - val_loss: 3.2151 - val_acc: 0.0468\n",
      "Epoch 592/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0526 - acc: 0.2183 - val_loss: 3.2197 - val_acc: 0.0468\n",
      "Epoch 593/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0500 - acc: 0.2207 - val_loss: 3.2197 - val_acc: 0.0468\n",
      "Epoch 594/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0477 - acc: 0.2242 - val_loss: 3.2145 - val_acc: 0.0468\n",
      "Epoch 595/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0489 - acc: 0.2209 - val_loss: 3.2085 - val_acc: 0.0468\n",
      "Epoch 596/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0548 - acc: 0.2230 - val_loss: 3.2053 - val_acc: 0.0468\n",
      "Epoch 597/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0537 - acc: 0.2114 - val_loss: 3.2101 - val_acc: 0.0468\n",
      "Epoch 598/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0465 - acc: 0.2266 - val_loss: 3.2126 - val_acc: 0.0468\n",
      "Epoch 599/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0492 - acc: 0.2209 - val_loss: 3.2082 - val_acc: 0.0468\n",
      "Epoch 600/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0463 - acc: 0.2205 - val_loss: 3.1994 - val_acc: 0.0468\n",
      "Epoch 601/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0489 - acc: 0.2244 - val_loss: 3.1885 - val_acc: 0.0468\n",
      "Epoch 602/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0510 - acc: 0.2284 - val_loss: 3.1767 - val_acc: 0.0468\n",
      "Epoch 603/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0532 - acc: 0.2195 - val_loss: 3.1756 - val_acc: 0.0468\n",
      "Epoch 604/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0517 - acc: 0.2252 - val_loss: 3.1758 - val_acc: 0.0468\n",
      "Epoch 605/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0510 - acc: 0.2199 - val_loss: 3.1835 - val_acc: 0.0468\n",
      "Epoch 606/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0480 - acc: 0.2242 - val_loss: 3.1797 - val_acc: 0.0468\n",
      "Epoch 607/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0503 - acc: 0.2236 - val_loss: 3.1685 - val_acc: 0.0468\n",
      "Epoch 608/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0492 - acc: 0.2199 - val_loss: 3.1517 - val_acc: 0.0468\n",
      "Epoch 609/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0506 - acc: 0.2274 - val_loss: 3.1421 - val_acc: 0.0468\n",
      "Epoch 610/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0472 - acc: 0.2234 - val_loss: 3.1382 - val_acc: 0.0468\n",
      "Epoch 611/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0504 - acc: 0.2224 - val_loss: 3.1381 - val_acc: 0.0468\n",
      "Epoch 612/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0483 - acc: 0.2209 - val_loss: 3.1468 - val_acc: 0.0468\n",
      "Epoch 613/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0514 - acc: 0.2193 - val_loss: 3.1571 - val_acc: 0.0468\n",
      "Epoch 614/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0531 - acc: 0.2193 - val_loss: 3.1655 - val_acc: 0.0468\n",
      "Epoch 615/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0469 - acc: 0.2242 - val_loss: 3.1717 - val_acc: 0.0468\n",
      "Epoch 616/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0504 - acc: 0.2191 - val_loss: 3.1709 - val_acc: 0.0468\n",
      "Epoch 617/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0497 - acc: 0.2236 - val_loss: 3.1647 - val_acc: 0.0468\n",
      "Epoch 618/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0457 - acc: 0.2205 - val_loss: 3.1579 - val_acc: 0.0445\n",
      "Epoch 619/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0500 - acc: 0.2197 - val_loss: 3.1623 - val_acc: 0.0445\n",
      "Epoch 620/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0515 - acc: 0.2185 - val_loss: 3.1735 - val_acc: 0.0468\n",
      "Epoch 621/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0496 - acc: 0.2244 - val_loss: 3.1913 - val_acc: 0.0468\n",
      "Epoch 622/1500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.0543 - acc: 0.2211 - val_loss: 3.2033 - val_acc: 0.0468\n",
      "Epoch 623/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0479 - acc: 0.2189 - val_loss: 3.1988 - val_acc: 0.0468\n",
      "Epoch 624/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0493 - acc: 0.2276 - val_loss: 3.1900 - val_acc: 0.0468\n",
      "Epoch 625/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0509 - acc: 0.2234 - val_loss: 3.1873 - val_acc: 0.0468\n",
      "Epoch 626/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0478 - acc: 0.2240 - val_loss: 3.1923 - val_acc: 0.0468\n",
      "Epoch 627/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0488 - acc: 0.2213 - val_loss: 3.2035 - val_acc: 0.0468\n",
      "Epoch 628/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0536 - acc: 0.2149 - val_loss: 3.2162 - val_acc: 0.0468\n",
      "Epoch 629/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0528 - acc: 0.2199 - val_loss: 3.2191 - val_acc: 0.0468\n",
      "Epoch 630/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0506 - acc: 0.2199 - val_loss: 3.2180 - val_acc: 0.0468\n",
      "Epoch 631/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0481 - acc: 0.2220 - val_loss: 3.1995 - val_acc: 0.0468\n",
      "Epoch 632/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0450 - acc: 0.2262 - val_loss: 3.1729 - val_acc: 0.0468\n",
      "Epoch 633/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0470 - acc: 0.2211 - val_loss: 3.1553 - val_acc: 0.0468\n",
      "Epoch 634/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0477 - acc: 0.2246 - val_loss: 3.1470 - val_acc: 0.0468\n",
      "Epoch 635/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0471 - acc: 0.2226 - val_loss: 3.1549 - val_acc: 0.0468\n",
      "Epoch 636/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0478 - acc: 0.2256 - val_loss: 3.1705 - val_acc: 0.0468\n",
      "Epoch 637/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0459 - acc: 0.2220 - val_loss: 3.1830 - val_acc: 0.0468\n",
      "Epoch 638/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0486 - acc: 0.2197 - val_loss: 3.1801 - val_acc: 0.0468\n",
      "Epoch 639/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0446 - acc: 0.2305 - val_loss: 3.1664 - val_acc: 0.0468\n",
      "Epoch 640/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0452 - acc: 0.2282 - val_loss: 3.1466 - val_acc: 0.0468\n",
      "Epoch 641/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0502 - acc: 0.2193 - val_loss: 3.1354 - val_acc: 0.0445\n",
      "Epoch 642/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0466 - acc: 0.2248 - val_loss: 3.1296 - val_acc: 0.0445\n",
      "Epoch 643/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0492 - acc: 0.2260 - val_loss: 3.1312 - val_acc: 0.0445\n",
      "Epoch 644/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0479 - acc: 0.2203 - val_loss: 3.1409 - val_acc: 0.0445\n",
      "Epoch 645/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0476 - acc: 0.2236 - val_loss: 3.1426 - val_acc: 0.0445\n",
      "Epoch 646/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0521 - acc: 0.2197 - val_loss: 3.1406 - val_acc: 0.0445\n",
      "Epoch 647/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0456 - acc: 0.2209 - val_loss: 3.1310 - val_acc: 0.0445\n",
      "Epoch 648/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0528 - acc: 0.2187 - val_loss: 3.1233 - val_acc: 0.0375\n",
      "Epoch 649/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0461 - acc: 0.2242 - val_loss: 3.1177 - val_acc: 0.0328\n",
      "Epoch 650/1500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.0533 - acc: 0.2122 - val_loss: 3.1168 - val_acc: 0.0328\n",
      "Epoch 651/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0464 - acc: 0.2222 - val_loss: 3.1164 - val_acc: 0.0328\n",
      "Epoch 652/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0477 - acc: 0.2183 - val_loss: 3.1201 - val_acc: 0.0328\n",
      "Epoch 653/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0453 - acc: 0.2199 - val_loss: 3.1258 - val_acc: 0.0328\n",
      "Epoch 654/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0500 - acc: 0.2222 - val_loss: 3.1425 - val_acc: 0.0351\n",
      "Epoch 655/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0486 - acc: 0.2201 - val_loss: 3.1535 - val_acc: 0.0351\n",
      "Epoch 656/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0479 - acc: 0.2236 - val_loss: 3.1563 - val_acc: 0.0375\n",
      "Epoch 657/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0436 - acc: 0.2270 - val_loss: 3.1517 - val_acc: 0.0422\n",
      "Epoch 658/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0479 - acc: 0.2165 - val_loss: 3.1453 - val_acc: 0.0492\n",
      "Epoch 659/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0468 - acc: 0.2224 - val_loss: 3.1377 - val_acc: 0.0585\n",
      "Epoch 660/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0485 - acc: 0.2191 - val_loss: 3.1327 - val_acc: 0.0679\n",
      "Epoch 661/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0442 - acc: 0.2234 - val_loss: 3.1423 - val_acc: 0.0679\n",
      "Epoch 662/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0484 - acc: 0.2234 - val_loss: 3.1625 - val_acc: 0.0679\n",
      "Epoch 663/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0524 - acc: 0.2193 - val_loss: 3.1733 - val_acc: 0.0632\n",
      "Epoch 664/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0493 - acc: 0.2215 - val_loss: 3.1666 - val_acc: 0.0585\n",
      "Epoch 665/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0492 - acc: 0.2217 - val_loss: 3.1503 - val_acc: 0.0679\n",
      "Epoch 666/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0533 - acc: 0.2175 - val_loss: 3.1343 - val_acc: 0.0679\n",
      "Epoch 667/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0475 - acc: 0.2217 - val_loss: 3.1196 - val_acc: 0.0679\n",
      "Epoch 668/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0469 - acc: 0.2175 - val_loss: 3.1127 - val_acc: 0.0562\n",
      "Epoch 669/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0475 - acc: 0.2313 - val_loss: 3.1160 - val_acc: 0.0585\n",
      "Epoch 670/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0477 - acc: 0.2234 - val_loss: 3.1278 - val_acc: 0.0539\n",
      "Epoch 671/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0489 - acc: 0.2153 - val_loss: 3.1383 - val_acc: 0.0562\n",
      "Epoch 672/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0502 - acc: 0.2211 - val_loss: 3.1381 - val_acc: 0.0539\n",
      "Epoch 673/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0516 - acc: 0.2187 - val_loss: 3.1351 - val_acc: 0.0539\n",
      "Epoch 674/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0468 - acc: 0.2199 - val_loss: 3.1305 - val_acc: 0.0539\n",
      "Epoch 675/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0492 - acc: 0.2215 - val_loss: 3.1206 - val_acc: 0.0539\n",
      "Epoch 676/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0455 - acc: 0.2256 - val_loss: 3.1109 - val_acc: 0.0539\n",
      "Epoch 677/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0469 - acc: 0.2226 - val_loss: 3.1137 - val_acc: 0.0539\n",
      "Epoch 678/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0447 - acc: 0.2191 - val_loss: 3.1218 - val_acc: 0.0539\n",
      "Epoch 679/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0443 - acc: 0.2232 - val_loss: 3.1330 - val_acc: 0.0539\n",
      "Epoch 680/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0469 - acc: 0.2248 - val_loss: 3.1422 - val_acc: 0.0539\n",
      "Epoch 681/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0454 - acc: 0.2276 - val_loss: 3.1404 - val_acc: 0.0539\n",
      "Epoch 682/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0438 - acc: 0.2280 - val_loss: 3.1329 - val_acc: 0.0539\n",
      "Epoch 683/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0481 - acc: 0.2189 - val_loss: 3.1250 - val_acc: 0.0539\n",
      "Epoch 684/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0441 - acc: 0.2177 - val_loss: 3.1244 - val_acc: 0.0539\n",
      "Epoch 685/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0485 - acc: 0.2232 - val_loss: 3.1306 - val_acc: 0.0492\n",
      "Epoch 686/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0460 - acc: 0.2278 - val_loss: 3.1413 - val_acc: 0.0492\n",
      "Epoch 687/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0521 - acc: 0.2149 - val_loss: 3.1490 - val_acc: 0.0468\n",
      "Epoch 688/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0481 - acc: 0.2296 - val_loss: 3.1494 - val_acc: 0.0468\n",
      "Epoch 689/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0481 - acc: 0.2211 - val_loss: 3.1381 - val_acc: 0.0468\n",
      "Epoch 690/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0462 - acc: 0.2189 - val_loss: 3.1157 - val_acc: 0.0492\n",
      "Epoch 691/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0470 - acc: 0.2193 - val_loss: 3.1025 - val_acc: 0.0468\n",
      "Epoch 692/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0472 - acc: 0.2201 - val_loss: 3.1087 - val_acc: 0.0468\n",
      "Epoch 693/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0491 - acc: 0.2215 - val_loss: 3.1261 - val_acc: 0.0468\n",
      "Epoch 694/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0488 - acc: 0.2118 - val_loss: 3.1420 - val_acc: 0.0445\n",
      "Epoch 695/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0480 - acc: 0.2226 - val_loss: 3.1527 - val_acc: 0.0445\n",
      "Epoch 696/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0478 - acc: 0.2116 - val_loss: 3.1485 - val_acc: 0.0468\n",
      "Epoch 697/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0460 - acc: 0.2177 - val_loss: 3.1342 - val_acc: 0.0468\n",
      "Epoch 698/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0446 - acc: 0.2226 - val_loss: 3.1210 - val_acc: 0.0515\n",
      "Epoch 699/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0471 - acc: 0.2163 - val_loss: 3.1175 - val_acc: 0.0539\n",
      "Epoch 700/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0483 - acc: 0.2159 - val_loss: 3.1345 - val_acc: 0.0539\n",
      "Epoch 701/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.0532 - acc: 0.2215 - val_loss: 3.1627 - val_acc: 0.0515\n",
      "Epoch 702/1500\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.0476 - acc: 0.2203 - val_loss: 3.1894 - val_acc: 0.0515\n",
      "Epoch 703/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0449 - acc: 0.2203 - val_loss: 3.2020 - val_acc: 0.0515\n",
      "Epoch 704/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0430 - acc: 0.2246 - val_loss: 3.1886 - val_acc: 0.0679\n",
      "Epoch 705/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0479 - acc: 0.2266 - val_loss: 3.1661 - val_acc: 0.0796\n",
      "Epoch 706/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0481 - acc: 0.2217 - val_loss: 3.1467 - val_acc: 0.0867\n",
      "Epoch 707/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0472 - acc: 0.2187 - val_loss: 3.1409 - val_acc: 0.0867\n",
      "Epoch 708/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0436 - acc: 0.2288 - val_loss: 3.1483 - val_acc: 0.0796\n",
      "Epoch 709/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0502 - acc: 0.2189 - val_loss: 3.1661 - val_acc: 0.0749\n",
      "Epoch 710/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0487 - acc: 0.2226 - val_loss: 3.1822 - val_acc: 0.0632\n",
      "Epoch 711/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0477 - acc: 0.2230 - val_loss: 3.1876 - val_acc: 0.0609\n",
      "Epoch 712/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0489 - acc: 0.2242 - val_loss: 3.1725 - val_acc: 0.0703\n",
      "Epoch 713/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0446 - acc: 0.2226 - val_loss: 3.1503 - val_acc: 0.0796\n",
      "Epoch 714/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0444 - acc: 0.2252 - val_loss: 3.1306 - val_acc: 0.0913\n",
      "Epoch 715/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0499 - acc: 0.2205 - val_loss: 3.1256 - val_acc: 0.0913\n",
      "Epoch 716/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0448 - acc: 0.2209 - val_loss: 3.1311 - val_acc: 0.0843\n",
      "Epoch 717/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0481 - acc: 0.2232 - val_loss: 3.1456 - val_acc: 0.0703\n",
      "Epoch 718/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0478 - acc: 0.2232 - val_loss: 3.1559 - val_acc: 0.0726\n",
      "Epoch 719/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0443 - acc: 0.2242 - val_loss: 3.1561 - val_acc: 0.0703\n",
      "Epoch 720/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0495 - acc: 0.2228 - val_loss: 3.1468 - val_acc: 0.0726\n",
      "Epoch 721/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0494 - acc: 0.2130 - val_loss: 3.1297 - val_acc: 0.0726\n",
      "Epoch 722/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0433 - acc: 0.2213 - val_loss: 3.1142 - val_acc: 0.0726\n",
      "Epoch 723/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0487 - acc: 0.2165 - val_loss: 3.1021 - val_acc: 0.0726\n",
      "Epoch 724/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0460 - acc: 0.2222 - val_loss: 3.1003 - val_acc: 0.0703\n",
      "Epoch 725/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0467 - acc: 0.2232 - val_loss: 3.1039 - val_acc: 0.0609\n",
      "Epoch 726/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0456 - acc: 0.2240 - val_loss: 3.1132 - val_acc: 0.0562\n",
      "Epoch 727/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0464 - acc: 0.2258 - val_loss: 3.1250 - val_acc: 0.0492\n",
      "Epoch 728/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0503 - acc: 0.2205 - val_loss: 3.1355 - val_acc: 0.0562\n",
      "Epoch 729/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0484 - acc: 0.2224 - val_loss: 3.1251 - val_acc: 0.0585\n",
      "Epoch 730/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0482 - acc: 0.2284 - val_loss: 3.1060 - val_acc: 0.0585\n",
      "Epoch 731/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0465 - acc: 0.2236 - val_loss: 3.0880 - val_acc: 0.0609\n",
      "Epoch 732/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0495 - acc: 0.2175 - val_loss: 3.0814 - val_acc: 0.0609\n",
      "Epoch 733/1500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0479 - acc: 0.2242 - val_loss: 3.0856 - val_acc: 0.0515\n",
      "Epoch 734/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0458 - acc: 0.2270 - val_loss: 3.0965 - val_acc: 0.0515\n",
      "Epoch 735/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0452 - acc: 0.2252 - val_loss: 3.0992 - val_acc: 0.0515\n",
      "Epoch 736/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0508 - acc: 0.2177 - val_loss: 3.1006 - val_acc: 0.0515\n",
      "Epoch 737/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0479 - acc: 0.2185 - val_loss: 3.1052 - val_acc: 0.0515\n",
      "Epoch 738/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0451 - acc: 0.2213 - val_loss: 3.0987 - val_acc: 0.0492\n",
      "Epoch 739/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0431 - acc: 0.2187 - val_loss: 3.0945 - val_acc: 0.0468\n",
      "Epoch 740/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0482 - acc: 0.2230 - val_loss: 3.0907 - val_acc: 0.0468\n",
      "Epoch 741/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0463 - acc: 0.2191 - val_loss: 3.0927 - val_acc: 0.0515\n",
      "Epoch 742/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0449 - acc: 0.2232 - val_loss: 3.0982 - val_acc: 0.0515\n",
      "Epoch 743/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0479 - acc: 0.2199 - val_loss: 3.1072 - val_acc: 0.0515\n",
      "Epoch 744/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0418 - acc: 0.2288 - val_loss: 3.1122 - val_acc: 0.0515\n",
      "Epoch 745/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0493 - acc: 0.2226 - val_loss: 3.1144 - val_acc: 0.0539\n",
      "Epoch 746/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0456 - acc: 0.2248 - val_loss: 3.1053 - val_acc: 0.0539\n",
      "Epoch 747/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0456 - acc: 0.2224 - val_loss: 3.0955 - val_acc: 0.0539\n",
      "Epoch 748/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0491 - acc: 0.2159 - val_loss: 3.0882 - val_acc: 0.0562\n",
      "Epoch 749/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0438 - acc: 0.2226 - val_loss: 3.0854 - val_acc: 0.0468\n",
      "Epoch 750/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0456 - acc: 0.2228 - val_loss: 3.0796 - val_acc: 0.0422\n",
      "Epoch 751/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0475 - acc: 0.2185 - val_loss: 3.0735 - val_acc: 0.0445\n",
      "Epoch 752/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0470 - acc: 0.2238 - val_loss: 3.0779 - val_acc: 0.0422\n",
      "Epoch 753/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0434 - acc: 0.2343 - val_loss: 3.0799 - val_acc: 0.0422\n",
      "Epoch 754/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0483 - acc: 0.2213 - val_loss: 3.0856 - val_acc: 0.0422\n",
      "Epoch 755/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0469 - acc: 0.2211 - val_loss: 3.0886 - val_acc: 0.0468\n",
      "Epoch 756/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0443 - acc: 0.2215 - val_loss: 3.0809 - val_acc: 0.0539\n",
      "Epoch 757/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0473 - acc: 0.2207 - val_loss: 3.0729 - val_acc: 0.0585\n",
      "Epoch 758/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0468 - acc: 0.2197 - val_loss: 3.0594 - val_acc: 0.0585\n",
      "Epoch 759/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0413 - acc: 0.2305 - val_loss: 3.0451 - val_acc: 0.0515\n",
      "Epoch 760/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0439 - acc: 0.2244 - val_loss: 3.0313 - val_acc: 0.0515\n",
      "Epoch 761/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0467 - acc: 0.2232 - val_loss: 3.0172 - val_acc: 0.0492\n",
      "Epoch 762/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0494 - acc: 0.2260 - val_loss: 3.0157 - val_acc: 0.0445\n",
      "Epoch 763/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0423 - acc: 0.2195 - val_loss: 3.0151 - val_acc: 0.0398\n",
      "Epoch 764/1500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 2.0475 - acc: 0.2234 - val_loss: 3.0136 - val_acc: 0.0351\n",
      "Epoch 765/1500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.0470 - acc: 0.2256 - val_loss: 3.0169 - val_acc: 0.0351\n",
      "Epoch 766/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0452 - acc: 0.2195 - val_loss: 3.0156 - val_acc: 0.0328\n",
      "Epoch 767/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0409 - acc: 0.2274 - val_loss: 3.0198 - val_acc: 0.0328\n",
      "Epoch 768/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0423 - acc: 0.2282 - val_loss: 3.0253 - val_acc: 0.0375\n",
      "Epoch 769/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0493 - acc: 0.2177 - val_loss: 3.0311 - val_acc: 0.0422\n",
      "Epoch 770/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0473 - acc: 0.2167 - val_loss: 3.0371 - val_acc: 0.0422\n",
      "Epoch 771/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0474 - acc: 0.2240 - val_loss: 3.0343 - val_acc: 0.0445\n",
      "Epoch 772/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0454 - acc: 0.2201 - val_loss: 3.0282 - val_acc: 0.0445\n",
      "Epoch 773/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0445 - acc: 0.2252 - val_loss: 3.0195 - val_acc: 0.0445\n",
      "Epoch 774/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0439 - acc: 0.2232 - val_loss: 3.0119 - val_acc: 0.0515\n",
      "Epoch 775/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0458 - acc: 0.2112 - val_loss: 3.0189 - val_acc: 0.0539\n",
      "Epoch 776/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0430 - acc: 0.2220 - val_loss: 3.0311 - val_acc: 0.0539\n",
      "Epoch 777/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0466 - acc: 0.2250 - val_loss: 3.0389 - val_acc: 0.0539\n",
      "Epoch 778/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0446 - acc: 0.2238 - val_loss: 3.0443 - val_acc: 0.0539\n",
      "Epoch 779/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0472 - acc: 0.2222 - val_loss: 3.0428 - val_acc: 0.0539\n",
      "Epoch 780/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0430 - acc: 0.2264 - val_loss: 3.0328 - val_acc: 0.0585\n",
      "Epoch 781/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0485 - acc: 0.2197 - val_loss: 3.0223 - val_acc: 0.0632\n",
      "Epoch 782/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0491 - acc: 0.2128 - val_loss: 3.0207 - val_acc: 0.0585\n",
      "Epoch 783/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0491 - acc: 0.2157 - val_loss: 3.0205 - val_acc: 0.0562\n",
      "Epoch 784/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0475 - acc: 0.2232 - val_loss: 3.0190 - val_acc: 0.0515\n",
      "Epoch 785/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0449 - acc: 0.2246 - val_loss: 3.0231 - val_acc: 0.0515\n",
      "Epoch 786/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0448 - acc: 0.2207 - val_loss: 3.0264 - val_acc: 0.0515\n",
      "Epoch 787/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0481 - acc: 0.2175 - val_loss: 3.0300 - val_acc: 0.0562\n",
      "Epoch 788/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0451 - acc: 0.2246 - val_loss: 3.0325 - val_acc: 0.0585\n",
      "Epoch 789/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0467 - acc: 0.2120 - val_loss: 3.0345 - val_acc: 0.0656\n",
      "Epoch 790/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0459 - acc: 0.2175 - val_loss: 3.0314 - val_acc: 0.0703\n",
      "Epoch 791/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0474 - acc: 0.2126 - val_loss: 3.0327 - val_acc: 0.0749\n",
      "Epoch 792/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0459 - acc: 0.2238 - val_loss: 3.0325 - val_acc: 0.0796\n",
      "Epoch 793/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0439 - acc: 0.2207 - val_loss: 3.0320 - val_acc: 0.0796\n",
      "Epoch 794/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0475 - acc: 0.2280 - val_loss: 3.0295 - val_acc: 0.0867\n",
      "Epoch 795/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0457 - acc: 0.2215 - val_loss: 3.0304 - val_acc: 0.0820\n",
      "Epoch 796/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0453 - acc: 0.2268 - val_loss: 3.0339 - val_acc: 0.0796\n",
      "Epoch 797/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0457 - acc: 0.2234 - val_loss: 3.0430 - val_acc: 0.0796\n",
      "Epoch 798/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0421 - acc: 0.2303 - val_loss: 3.0484 - val_acc: 0.0796\n",
      "Epoch 799/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0447 - acc: 0.2284 - val_loss: 3.0496 - val_acc: 0.0820\n",
      "Epoch 800/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0468 - acc: 0.2246 - val_loss: 3.0426 - val_acc: 0.0820\n",
      "Epoch 801/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0463 - acc: 0.2228 - val_loss: 3.0367 - val_acc: 0.0796\n",
      "Epoch 802/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0445 - acc: 0.2262 - val_loss: 3.0339 - val_acc: 0.0796\n",
      "Epoch 803/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0479 - acc: 0.2165 - val_loss: 3.0363 - val_acc: 0.0773\n",
      "Epoch 804/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0475 - acc: 0.2232 - val_loss: 3.0384 - val_acc: 0.0703\n",
      "Epoch 805/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0453 - acc: 0.2248 - val_loss: 3.0438 - val_acc: 0.0773\n",
      "Epoch 806/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0446 - acc: 0.2224 - val_loss: 3.0462 - val_acc: 0.0749\n",
      "Epoch 807/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0491 - acc: 0.2238 - val_loss: 3.0375 - val_acc: 0.0703\n",
      "Epoch 808/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0468 - acc: 0.2193 - val_loss: 3.0245 - val_acc: 0.0609\n",
      "Epoch 809/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0443 - acc: 0.2262 - val_loss: 3.0082 - val_acc: 0.0609\n",
      "Epoch 810/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0446 - acc: 0.2270 - val_loss: 2.9944 - val_acc: 0.0562\n",
      "Epoch 811/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0428 - acc: 0.2242 - val_loss: 2.9900 - val_acc: 0.0562\n",
      "Epoch 812/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0464 - acc: 0.2220 - val_loss: 2.9898 - val_acc: 0.0562\n",
      "Epoch 813/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0446 - acc: 0.2203 - val_loss: 2.9882 - val_acc: 0.0539\n",
      "Epoch 814/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0467 - acc: 0.2236 - val_loss: 2.9882 - val_acc: 0.0515\n",
      "Epoch 815/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0446 - acc: 0.2161 - val_loss: 2.9917 - val_acc: 0.0515\n",
      "Epoch 816/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0459 - acc: 0.2179 - val_loss: 2.9930 - val_acc: 0.0492\n",
      "Epoch 817/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0432 - acc: 0.2294 - val_loss: 2.9920 - val_acc: 0.0492\n",
      "Epoch 818/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0446 - acc: 0.2203 - val_loss: 2.9843 - val_acc: 0.0398\n",
      "Epoch 819/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0446 - acc: 0.2230 - val_loss: 2.9750 - val_acc: 0.0422\n",
      "Epoch 820/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0448 - acc: 0.2185 - val_loss: 2.9722 - val_acc: 0.0422\n",
      "Epoch 821/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0461 - acc: 0.2201 - val_loss: 2.9799 - val_acc: 0.0375\n",
      "Epoch 822/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0436 - acc: 0.2288 - val_loss: 2.9981 - val_acc: 0.0375\n",
      "Epoch 823/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0480 - acc: 0.2169 - val_loss: 3.0134 - val_acc: 0.0422\n",
      "Epoch 824/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0461 - acc: 0.2280 - val_loss: 3.0185 - val_acc: 0.0422\n",
      "Epoch 825/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0462 - acc: 0.2197 - val_loss: 3.0148 - val_acc: 0.0375\n",
      "Epoch 826/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0439 - acc: 0.2258 - val_loss: 2.9948 - val_acc: 0.0539\n",
      "Epoch 827/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0433 - acc: 0.2299 - val_loss: 2.9847 - val_acc: 0.0539\n",
      "Epoch 828/1500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.0391 - acc: 0.2284 - val_loss: 2.9828 - val_acc: 0.0585\n",
      "Epoch 829/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0461 - acc: 0.2173 - val_loss: 2.9969 - val_acc: 0.0562\n",
      "Epoch 830/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0487 - acc: 0.2116 - val_loss: 3.0174 - val_acc: 0.0539\n",
      "Epoch 831/1500\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.0450 - acc: 0.2278 - val_loss: 3.0308 - val_acc: 0.0656\n",
      "Epoch 832/1500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 2.0457 - acc: 0.2299 - val_loss: 3.0267 - val_acc: 0.0656\n",
      "Epoch 833/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0486 - acc: 0.2211 - val_loss: 3.0095 - val_acc: 0.0656\n",
      "Epoch 834/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0480 - acc: 0.2234 - val_loss: 2.9962 - val_acc: 0.0656\n",
      "Epoch 835/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0424 - acc: 0.2238 - val_loss: 2.9870 - val_acc: 0.0632\n",
      "Epoch 836/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0476 - acc: 0.2114 - val_loss: 2.9959 - val_acc: 0.0609\n",
      "Epoch 837/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0426 - acc: 0.2224 - val_loss: 3.0033 - val_acc: 0.0539\n",
      "Epoch 838/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0483 - acc: 0.2224 - val_loss: 3.0125 - val_acc: 0.0609\n",
      "Epoch 839/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0445 - acc: 0.2246 - val_loss: 3.0170 - val_acc: 0.0609\n",
      "Epoch 840/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0461 - acc: 0.2264 - val_loss: 3.0141 - val_acc: 0.0609\n",
      "Epoch 841/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0421 - acc: 0.2258 - val_loss: 3.0032 - val_acc: 0.0609\n",
      "Epoch 842/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0474 - acc: 0.2197 - val_loss: 2.9944 - val_acc: 0.0609\n",
      "Epoch 843/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0429 - acc: 0.2209 - val_loss: 2.9913 - val_acc: 0.0539\n",
      "Epoch 844/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0431 - acc: 0.2209 - val_loss: 2.9898 - val_acc: 0.0468\n",
      "Epoch 845/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0479 - acc: 0.2238 - val_loss: 2.9874 - val_acc: 0.0468\n",
      "Epoch 846/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0427 - acc: 0.2246 - val_loss: 2.9790 - val_acc: 0.0468\n",
      "Epoch 847/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0418 - acc: 0.2299 - val_loss: 2.9693 - val_acc: 0.0468\n",
      "Epoch 848/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0443 - acc: 0.2278 - val_loss: 2.9723 - val_acc: 0.0468\n",
      "Epoch 849/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0432 - acc: 0.2256 - val_loss: 2.9814 - val_acc: 0.0468\n",
      "Epoch 850/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0420 - acc: 0.2240 - val_loss: 2.9880 - val_acc: 0.0468\n",
      "Epoch 851/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0430 - acc: 0.2209 - val_loss: 2.9871 - val_acc: 0.0445\n",
      "Epoch 852/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0467 - acc: 0.2248 - val_loss: 2.9831 - val_acc: 0.0492\n",
      "Epoch 853/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0453 - acc: 0.2303 - val_loss: 2.9758 - val_acc: 0.0539\n",
      "Epoch 854/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0467 - acc: 0.2187 - val_loss: 2.9675 - val_acc: 0.0539\n",
      "Epoch 855/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0469 - acc: 0.2191 - val_loss: 2.9564 - val_acc: 0.0492\n",
      "Epoch 856/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0459 - acc: 0.2284 - val_loss: 2.9529 - val_acc: 0.0539\n",
      "Epoch 857/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0457 - acc: 0.2215 - val_loss: 2.9621 - val_acc: 0.0492\n",
      "Epoch 858/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0431 - acc: 0.2207 - val_loss: 2.9702 - val_acc: 0.0492\n",
      "Epoch 859/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0466 - acc: 0.2222 - val_loss: 2.9743 - val_acc: 0.0539\n",
      "Epoch 860/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0417 - acc: 0.2246 - val_loss: 2.9698 - val_acc: 0.0492\n",
      "Epoch 861/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0474 - acc: 0.2078 - val_loss: 2.9673 - val_acc: 0.0609\n",
      "Epoch 862/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0408 - acc: 0.2266 - val_loss: 2.9634 - val_acc: 0.0562\n",
      "Epoch 863/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0421 - acc: 0.2280 - val_loss: 2.9550 - val_acc: 0.0585\n",
      "Epoch 864/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0465 - acc: 0.2177 - val_loss: 2.9540 - val_acc: 0.0562\n",
      "Epoch 865/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0482 - acc: 0.2175 - val_loss: 2.9576 - val_acc: 0.0562\n",
      "Epoch 866/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0401 - acc: 0.2309 - val_loss: 2.9509 - val_acc: 0.0492\n",
      "Epoch 867/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0413 - acc: 0.2238 - val_loss: 2.9442 - val_acc: 0.0445\n",
      "Epoch 868/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0414 - acc: 0.2292 - val_loss: 2.9367 - val_acc: 0.0492\n",
      "Epoch 869/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0474 - acc: 0.2183 - val_loss: 2.9314 - val_acc: 0.0492\n",
      "Epoch 870/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0432 - acc: 0.2236 - val_loss: 2.9233 - val_acc: 0.0492\n",
      "Epoch 871/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0436 - acc: 0.2292 - val_loss: 2.9241 - val_acc: 0.0492\n",
      "Epoch 872/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0413 - acc: 0.2187 - val_loss: 2.9307 - val_acc: 0.0468\n",
      "Epoch 873/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0426 - acc: 0.2248 - val_loss: 2.9335 - val_acc: 0.0468\n",
      "Epoch 874/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0464 - acc: 0.2179 - val_loss: 2.9353 - val_acc: 0.0468\n",
      "Epoch 875/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0450 - acc: 0.2244 - val_loss: 2.9379 - val_acc: 0.0515\n",
      "Epoch 876/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0425 - acc: 0.2307 - val_loss: 2.9452 - val_acc: 0.0515\n",
      "Epoch 877/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0434 - acc: 0.2292 - val_loss: 2.9512 - val_acc: 0.0515\n",
      "Epoch 878/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0431 - acc: 0.2256 - val_loss: 2.9576 - val_acc: 0.0515\n",
      "Epoch 879/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0437 - acc: 0.2284 - val_loss: 2.9546 - val_acc: 0.0515\n",
      "Epoch 880/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0452 - acc: 0.2167 - val_loss: 2.9586 - val_acc: 0.0468\n",
      "Epoch 881/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0439 - acc: 0.2217 - val_loss: 2.9626 - val_acc: 0.0422\n",
      "Epoch 882/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0441 - acc: 0.2256 - val_loss: 2.9686 - val_acc: 0.0468\n",
      "Epoch 883/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0419 - acc: 0.2240 - val_loss: 2.9703 - val_acc: 0.0492\n",
      "Epoch 884/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0431 - acc: 0.2252 - val_loss: 2.9634 - val_acc: 0.0492\n",
      "Epoch 885/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0413 - acc: 0.2272 - val_loss: 2.9496 - val_acc: 0.0492\n",
      "Epoch 886/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0443 - acc: 0.2191 - val_loss: 2.9314 - val_acc: 0.0492\n",
      "Epoch 887/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0420 - acc: 0.2256 - val_loss: 2.9196 - val_acc: 0.0492\n",
      "Epoch 888/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0462 - acc: 0.2185 - val_loss: 2.9179 - val_acc: 0.0492\n",
      "Epoch 889/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0432 - acc: 0.2252 - val_loss: 2.9226 - val_acc: 0.0492\n",
      "Epoch 890/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0447 - acc: 0.2226 - val_loss: 2.9320 - val_acc: 0.0515\n",
      "Epoch 891/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0436 - acc: 0.2244 - val_loss: 2.9421 - val_acc: 0.0492\n",
      "Epoch 892/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0423 - acc: 0.2278 - val_loss: 2.9389 - val_acc: 0.0492\n",
      "Epoch 893/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0447 - acc: 0.2264 - val_loss: 2.9249 - val_acc: 0.0515\n",
      "Epoch 894/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0447 - acc: 0.2274 - val_loss: 2.9094 - val_acc: 0.0515\n",
      "Epoch 895/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0429 - acc: 0.2242 - val_loss: 2.8971 - val_acc: 0.0492\n",
      "Epoch 896/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0468 - acc: 0.2250 - val_loss: 2.8959 - val_acc: 0.0492\n",
      "Epoch 897/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0410 - acc: 0.2244 - val_loss: 2.9072 - val_acc: 0.0492\n",
      "Epoch 898/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0493 - acc: 0.2179 - val_loss: 2.9201 - val_acc: 0.0492\n",
      "Epoch 899/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0454 - acc: 0.2195 - val_loss: 2.9215 - val_acc: 0.0492\n",
      "Epoch 900/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0430 - acc: 0.2274 - val_loss: 2.9132 - val_acc: 0.0445\n",
      "Epoch 901/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0490 - acc: 0.2197 - val_loss: 2.8960 - val_acc: 0.0375\n",
      "Epoch 902/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0415 - acc: 0.2244 - val_loss: 2.8789 - val_acc: 0.0375\n",
      "Epoch 903/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0437 - acc: 0.2234 - val_loss: 2.8781 - val_acc: 0.0375\n",
      "Epoch 904/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0416 - acc: 0.2234 - val_loss: 2.8881 - val_acc: 0.0375\n",
      "Epoch 905/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0468 - acc: 0.2211 - val_loss: 2.9034 - val_acc: 0.0375\n",
      "Epoch 906/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0438 - acc: 0.2169 - val_loss: 2.9202 - val_acc: 0.0468\n",
      "Epoch 907/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0401 - acc: 0.2296 - val_loss: 2.9226 - val_acc: 0.0492\n",
      "Epoch 908/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0471 - acc: 0.2201 - val_loss: 2.9129 - val_acc: 0.0492\n",
      "Epoch 909/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0427 - acc: 0.2262 - val_loss: 2.9006 - val_acc: 0.0468\n",
      "Epoch 910/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0420 - acc: 0.2197 - val_loss: 2.8934 - val_acc: 0.0468\n",
      "Epoch 911/1500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 2.0411 - acc: 0.2286 - val_loss: 2.8900 - val_acc: 0.0468\n",
      "Epoch 912/1500\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0401 - acc: 0.2217 - val_loss: 2.8915 - val_acc: 0.0422\n",
      "Epoch 913/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0456 - acc: 0.2159 - val_loss: 2.9049 - val_acc: 0.0445\n",
      "Epoch 914/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0407 - acc: 0.2268 - val_loss: 2.9243 - val_acc: 0.0445\n",
      "Epoch 915/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0417 - acc: 0.2179 - val_loss: 2.9429 - val_acc: 0.0398\n",
      "Epoch 916/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0457 - acc: 0.2250 - val_loss: 2.9432 - val_acc: 0.0398\n",
      "Epoch 917/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0445 - acc: 0.2266 - val_loss: 2.9317 - val_acc: 0.0398\n",
      "Epoch 918/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0415 - acc: 0.2266 - val_loss: 2.9157 - val_acc: 0.0375\n",
      "Epoch 919/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0430 - acc: 0.2228 - val_loss: 2.9064 - val_acc: 0.0398\n",
      "Epoch 920/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0417 - acc: 0.2195 - val_loss: 2.9130 - val_acc: 0.0375\n",
      "Epoch 921/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0497 - acc: 0.2173 - val_loss: 2.9353 - val_acc: 0.0398\n",
      "Epoch 922/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0421 - acc: 0.2187 - val_loss: 2.9504 - val_acc: 0.0375\n",
      "Epoch 923/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0435 - acc: 0.2286 - val_loss: 2.9516 - val_acc: 0.0375\n",
      "Epoch 924/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0412 - acc: 0.2256 - val_loss: 2.9354 - val_acc: 0.0375\n",
      "Epoch 925/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0420 - acc: 0.2361 - val_loss: 2.9105 - val_acc: 0.0398\n",
      "Epoch 926/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0406 - acc: 0.2262 - val_loss: 2.8938 - val_acc: 0.0375\n",
      "Epoch 927/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0419 - acc: 0.2270 - val_loss: 2.8890 - val_acc: 0.0375\n",
      "Epoch 928/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0439 - acc: 0.2282 - val_loss: 2.8966 - val_acc: 0.0351\n",
      "Epoch 929/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0434 - acc: 0.2240 - val_loss: 2.9044 - val_acc: 0.0398\n",
      "Epoch 930/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0427 - acc: 0.2153 - val_loss: 2.9036 - val_acc: 0.0398\n",
      "Epoch 931/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0455 - acc: 0.2203 - val_loss: 2.9015 - val_acc: 0.0398\n",
      "Epoch 932/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0446 - acc: 0.2163 - val_loss: 2.8911 - val_acc: 0.0398\n",
      "Epoch 933/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0412 - acc: 0.2276 - val_loss: 2.8812 - val_acc: 0.0351\n",
      "Epoch 934/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0423 - acc: 0.2254 - val_loss: 2.8738 - val_acc: 0.0351\n",
      "Epoch 935/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0434 - acc: 0.2248 - val_loss: 2.8743 - val_acc: 0.0398\n",
      "Epoch 936/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0436 - acc: 0.2195 - val_loss: 2.8750 - val_acc: 0.0398\n",
      "Epoch 937/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0494 - acc: 0.2220 - val_loss: 2.8766 - val_acc: 0.0398\n",
      "Epoch 938/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0441 - acc: 0.2173 - val_loss: 2.8777 - val_acc: 0.0398\n",
      "Epoch 939/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0459 - acc: 0.2193 - val_loss: 2.8743 - val_acc: 0.0398\n",
      "Epoch 940/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0477 - acc: 0.2213 - val_loss: 2.8652 - val_acc: 0.0398\n",
      "Epoch 941/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0436 - acc: 0.2256 - val_loss: 2.8567 - val_acc: 0.0422\n",
      "Epoch 942/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0414 - acc: 0.2228 - val_loss: 2.8550 - val_acc: 0.0445\n",
      "Epoch 943/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0431 - acc: 0.2215 - val_loss: 2.8592 - val_acc: 0.0445\n",
      "Epoch 944/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0438 - acc: 0.2232 - val_loss: 2.8652 - val_acc: 0.0445\n",
      "Epoch 945/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0414 - acc: 0.2258 - val_loss: 2.8785 - val_acc: 0.0445\n",
      "Epoch 946/1500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.0445 - acc: 0.2232 - val_loss: 2.8873 - val_acc: 0.0492\n",
      "Epoch 947/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0413 - acc: 0.2244 - val_loss: 2.8886 - val_acc: 0.0515\n",
      "Epoch 948/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0406 - acc: 0.2278 - val_loss: 2.8780 - val_acc: 0.0515\n",
      "Epoch 949/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0443 - acc: 0.2224 - val_loss: 2.8638 - val_acc: 0.0445\n",
      "Epoch 950/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0409 - acc: 0.2256 - val_loss: 2.8541 - val_acc: 0.0445\n",
      "Epoch 951/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0439 - acc: 0.2248 - val_loss: 2.8571 - val_acc: 0.0445\n",
      "Epoch 952/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0437 - acc: 0.2232 - val_loss: 2.8647 - val_acc: 0.0445\n",
      "Epoch 953/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0396 - acc: 0.2272 - val_loss: 2.8782 - val_acc: 0.0445\n",
      "Epoch 954/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0429 - acc: 0.2230 - val_loss: 2.8900 - val_acc: 0.0398\n",
      "Epoch 955/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0419 - acc: 0.2256 - val_loss: 2.8901 - val_acc: 0.0398\n",
      "Epoch 956/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0428 - acc: 0.2296 - val_loss: 2.8848 - val_acc: 0.0398\n",
      "Epoch 957/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0437 - acc: 0.2226 - val_loss: 2.8787 - val_acc: 0.0445\n",
      "Epoch 958/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0428 - acc: 0.2213 - val_loss: 2.8729 - val_acc: 0.0398\n",
      "Epoch 959/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0433 - acc: 0.2270 - val_loss: 2.8710 - val_acc: 0.0398\n",
      "Epoch 960/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0391 - acc: 0.2303 - val_loss: 2.8716 - val_acc: 0.0398\n",
      "Epoch 961/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0403 - acc: 0.2258 - val_loss: 2.8697 - val_acc: 0.0445\n",
      "Epoch 962/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0395 - acc: 0.2276 - val_loss: 2.8701 - val_acc: 0.0445\n",
      "Epoch 963/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0398 - acc: 0.2209 - val_loss: 2.8681 - val_acc: 0.0492\n",
      "Epoch 964/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0427 - acc: 0.2254 - val_loss: 2.8695 - val_acc: 0.0492\n",
      "Epoch 965/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0414 - acc: 0.2256 - val_loss: 2.8763 - val_acc: 0.0445\n",
      "Epoch 966/1500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0439 - acc: 0.2217 - val_loss: 2.8874 - val_acc: 0.0445\n",
      "Epoch 967/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0434 - acc: 0.2209 - val_loss: 2.8972 - val_acc: 0.0422\n",
      "Epoch 968/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0371 - acc: 0.2331 - val_loss: 2.8974 - val_acc: 0.0422\n",
      "Epoch 969/1500\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 2.0411 - acc: 0.2313 - val_loss: 2.8919 - val_acc: 0.0422\n",
      "Epoch 970/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0417 - acc: 0.2230 - val_loss: 2.8859 - val_acc: 0.0375\n",
      "Epoch 971/1500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.0430 - acc: 0.2191 - val_loss: 2.8874 - val_acc: 0.0422\n",
      "Epoch 972/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0460 - acc: 0.2185 - val_loss: 2.8973 - val_acc: 0.0422\n",
      "Epoch 973/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0408 - acc: 0.2288 - val_loss: 2.9070 - val_acc: 0.0422\n",
      "Epoch 974/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0435 - acc: 0.2215 - val_loss: 2.9101 - val_acc: 0.0422\n",
      "Epoch 975/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0432 - acc: 0.2183 - val_loss: 2.9128 - val_acc: 0.0422\n",
      "Epoch 976/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0480 - acc: 0.2195 - val_loss: 2.9163 - val_acc: 0.0445\n",
      "Epoch 977/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0452 - acc: 0.2232 - val_loss: 2.9221 - val_acc: 0.0492\n",
      "Epoch 978/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0419 - acc: 0.2260 - val_loss: 2.9194 - val_acc: 0.0492\n",
      "Epoch 979/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0417 - acc: 0.2211 - val_loss: 2.9156 - val_acc: 0.0422\n",
      "Epoch 980/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0384 - acc: 0.2238 - val_loss: 2.9172 - val_acc: 0.0422\n",
      "Epoch 981/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0416 - acc: 0.2268 - val_loss: 2.9213 - val_acc: 0.0422\n",
      "Epoch 982/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0447 - acc: 0.2177 - val_loss: 2.9256 - val_acc: 0.0422\n",
      "Epoch 983/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0424 - acc: 0.2274 - val_loss: 2.9216 - val_acc: 0.0422\n",
      "Epoch 984/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0376 - acc: 0.2303 - val_loss: 2.9190 - val_acc: 0.0422\n",
      "Epoch 985/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0433 - acc: 0.2248 - val_loss: 2.9232 - val_acc: 0.0375\n",
      "Epoch 986/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0401 - acc: 0.2254 - val_loss: 2.9274 - val_acc: 0.0375\n",
      "Epoch 987/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0426 - acc: 0.2343 - val_loss: 2.9326 - val_acc: 0.0375\n",
      "Epoch 988/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0466 - acc: 0.2252 - val_loss: 2.9375 - val_acc: 0.0375\n",
      "Epoch 989/1500\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 2.0423 - acc: 0.2262 - val_loss: 2.9307 - val_acc: 0.0375\n",
      "Epoch 990/1500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.0440 - acc: 0.2242 - val_loss: 2.9217 - val_acc: 0.0398\n",
      "Epoch 991/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0402 - acc: 0.2222 - val_loss: 2.9135 - val_acc: 0.0445\n",
      "Epoch 992/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0400 - acc: 0.2282 - val_loss: 2.9120 - val_acc: 0.0445\n",
      "Epoch 993/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0411 - acc: 0.2264 - val_loss: 2.9115 - val_acc: 0.0445\n",
      "Epoch 994/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0469 - acc: 0.2108 - val_loss: 2.9139 - val_acc: 0.0445\n",
      "Epoch 995/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0419 - acc: 0.2252 - val_loss: 2.9196 - val_acc: 0.0422\n",
      "Epoch 996/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0428 - acc: 0.2213 - val_loss: 2.9154 - val_acc: 0.0375\n",
      "Epoch 997/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0421 - acc: 0.2234 - val_loss: 2.9063 - val_acc: 0.0328\n",
      "Epoch 998/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0437 - acc: 0.2276 - val_loss: 2.9067 - val_acc: 0.0304\n",
      "Epoch 999/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0415 - acc: 0.2236 - val_loss: 2.9042 - val_acc: 0.0304\n",
      "Epoch 1000/1500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.0418 - acc: 0.2266 - val_loss: 2.8968 - val_acc: 0.0304\n",
      "Epoch 1001/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0430 - acc: 0.2240 - val_loss: 2.8902 - val_acc: 0.0304\n",
      "Epoch 1002/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0424 - acc: 0.2242 - val_loss: 2.8915 - val_acc: 0.0328\n",
      "Epoch 1003/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0415 - acc: 0.2250 - val_loss: 2.9003 - val_acc: 0.0375\n",
      "Epoch 1004/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0381 - acc: 0.2343 - val_loss: 2.9001 - val_acc: 0.0422\n",
      "Epoch 1005/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0417 - acc: 0.2284 - val_loss: 2.8932 - val_acc: 0.0398\n",
      "Epoch 1006/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0380 - acc: 0.2262 - val_loss: 2.8803 - val_acc: 0.0351\n",
      "Epoch 1007/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0442 - acc: 0.2222 - val_loss: 2.8655 - val_acc: 0.0351\n",
      "Epoch 1008/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0428 - acc: 0.2230 - val_loss: 2.8597 - val_acc: 0.0351\n",
      "Epoch 1009/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0392 - acc: 0.2256 - val_loss: 2.8590 - val_acc: 0.0328\n",
      "Epoch 1010/1500\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 2.0459 - acc: 0.2193 - val_loss: 2.8671 - val_acc: 0.0328\n",
      "Epoch 1011/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0411 - acc: 0.2276 - val_loss: 2.8790 - val_acc: 0.0328\n",
      "Epoch 1012/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0375 - acc: 0.2347 - val_loss: 2.8845 - val_acc: 0.0328\n",
      "Epoch 1013/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0424 - acc: 0.2337 - val_loss: 2.8798 - val_acc: 0.0328\n",
      "Epoch 1014/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0438 - acc: 0.2203 - val_loss: 2.8676 - val_acc: 0.0328\n",
      "Epoch 1015/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0415 - acc: 0.2240 - val_loss: 2.8545 - val_acc: 0.0328\n",
      "Epoch 1016/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0427 - acc: 0.2222 - val_loss: 2.8537 - val_acc: 0.0328\n",
      "Epoch 1017/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0450 - acc: 0.2189 - val_loss: 2.8596 - val_acc: 0.0351\n",
      "Epoch 1018/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0403 - acc: 0.2270 - val_loss: 2.8588 - val_acc: 0.0351\n",
      "Epoch 1019/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0430 - acc: 0.2264 - val_loss: 2.8612 - val_acc: 0.0375\n",
      "Epoch 1020/1500\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 2.0425 - acc: 0.2280 - val_loss: 2.8560 - val_acc: 0.0351\n",
      "Epoch 1021/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0418 - acc: 0.2215 - val_loss: 2.8504 - val_acc: 0.0351\n",
      "Epoch 1022/1500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.0410 - acc: 0.2163 - val_loss: 2.8467 - val_acc: 0.0351\n",
      "Epoch 1023/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0430 - acc: 0.2215 - val_loss: 2.8485 - val_acc: 0.0375\n",
      "Epoch 1024/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0381 - acc: 0.2268 - val_loss: 2.8557 - val_acc: 0.0375\n",
      "Epoch 1025/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0377 - acc: 0.2288 - val_loss: 2.8603 - val_acc: 0.0351\n",
      "Epoch 1026/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0439 - acc: 0.2187 - val_loss: 2.8641 - val_acc: 0.0351\n",
      "Epoch 1027/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0437 - acc: 0.2252 - val_loss: 2.8720 - val_acc: 0.0375\n",
      "Epoch 1028/1500\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.0399 - acc: 0.2301 - val_loss: 2.8725 - val_acc: 0.0375\n",
      "Epoch 1029/1500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 2.0394 - acc: 0.2278 - val_loss: 2.8608 - val_acc: 0.0375\n",
      "Epoch 1030/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0411 - acc: 0.2250 - val_loss: 2.8372 - val_acc: 0.0375\n",
      "Epoch 1031/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0447 - acc: 0.2167 - val_loss: 2.8197 - val_acc: 0.0375\n",
      "Epoch 1032/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0426 - acc: 0.2220 - val_loss: 2.8112 - val_acc: 0.0375\n",
      "Epoch 1033/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0444 - acc: 0.2177 - val_loss: 2.8155 - val_acc: 0.0351\n",
      "Epoch 1034/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0380 - acc: 0.2319 - val_loss: 2.8257 - val_acc: 0.0351\n",
      "Epoch 1035/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0441 - acc: 0.2189 - val_loss: 2.8328 - val_acc: 0.0468\n",
      "Epoch 1036/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0456 - acc: 0.2215 - val_loss: 2.8277 - val_acc: 0.0468\n",
      "Epoch 1037/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0385 - acc: 0.2315 - val_loss: 2.8154 - val_acc: 0.0351\n",
      "Epoch 1038/1500\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 2.0432 - acc: 0.2272 - val_loss: 2.8040 - val_acc: 0.0351\n",
      "Epoch 1039/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0384 - acc: 0.2315 - val_loss: 2.7970 - val_acc: 0.0351\n",
      "Epoch 1040/1500\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.0420 - acc: 0.2181 - val_loss: 2.8067 - val_acc: 0.0351\n",
      "Epoch 1041/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0440 - acc: 0.2280 - val_loss: 2.8260 - val_acc: 0.0351\n",
      "Epoch 1042/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0420 - acc: 0.2238 - val_loss: 2.8468 - val_acc: 0.0351\n",
      "Epoch 1043/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0452 - acc: 0.2256 - val_loss: 2.8502 - val_acc: 0.0398\n",
      "Epoch 1044/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0388 - acc: 0.2299 - val_loss: 2.8319 - val_acc: 0.0351\n",
      "Epoch 1045/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0415 - acc: 0.2321 - val_loss: 2.8096 - val_acc: 0.0351\n",
      "Epoch 1046/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0370 - acc: 0.2220 - val_loss: 2.7943 - val_acc: 0.0328\n",
      "Epoch 1047/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0433 - acc: 0.2179 - val_loss: 2.7938 - val_acc: 0.0351\n",
      "Epoch 1048/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0423 - acc: 0.2280 - val_loss: 2.8053 - val_acc: 0.0351\n",
      "Epoch 1049/1500\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 2.0394 - acc: 0.2333 - val_loss: 2.8195 - val_acc: 0.0398\n",
      "Epoch 1050/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0399 - acc: 0.2301 - val_loss: 2.8213 - val_acc: 0.0398\n",
      "Epoch 1051/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0380 - acc: 0.2301 - val_loss: 2.8091 - val_acc: 0.0351\n",
      "Epoch 1052/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0409 - acc: 0.2240 - val_loss: 2.7965 - val_acc: 0.0351\n",
      "Epoch 1053/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0435 - acc: 0.2270 - val_loss: 2.7922 - val_acc: 0.0328\n",
      "Epoch 1054/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0418 - acc: 0.2313 - val_loss: 2.7968 - val_acc: 0.0351\n",
      "Epoch 1055/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0400 - acc: 0.2341 - val_loss: 2.8033 - val_acc: 0.0351\n",
      "Epoch 1056/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0409 - acc: 0.2211 - val_loss: 2.8107 - val_acc: 0.0398\n",
      "Epoch 1057/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0393 - acc: 0.2272 - val_loss: 2.8126 - val_acc: 0.0398\n",
      "Epoch 1058/1500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.0373 - acc: 0.2377 - val_loss: 2.8089 - val_acc: 0.0351\n",
      "Epoch 1059/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0475 - acc: 0.2213 - val_loss: 2.8096 - val_acc: 0.0351\n",
      "Epoch 1060/1500\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.0430 - acc: 0.2242 - val_loss: 2.8093 - val_acc: 0.0351\n",
      "Epoch 1061/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0426 - acc: 0.2256 - val_loss: 2.8130 - val_acc: 0.0351\n",
      "Epoch 1062/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0431 - acc: 0.2163 - val_loss: 2.8190 - val_acc: 0.0351\n",
      "Epoch 1063/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0382 - acc: 0.2256 - val_loss: 2.8218 - val_acc: 0.0351\n",
      "Epoch 1064/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0429 - acc: 0.2244 - val_loss: 2.8199 - val_acc: 0.0351\n",
      "Epoch 1065/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0427 - acc: 0.2282 - val_loss: 2.8229 - val_acc: 0.0351\n",
      "Epoch 1066/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0419 - acc: 0.2207 - val_loss: 2.8236 - val_acc: 0.0351\n",
      "Epoch 1067/1500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 2.0447 - acc: 0.2258 - val_loss: 2.8294 - val_acc: 0.0398\n",
      "Epoch 1068/1500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.0439 - acc: 0.2211 - val_loss: 2.8399 - val_acc: 0.0398\n",
      "Epoch 1069/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0408 - acc: 0.2205 - val_loss: 2.8478 - val_acc: 0.0351\n",
      "Epoch 1070/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0420 - acc: 0.2234 - val_loss: 2.8462 - val_acc: 0.0351\n",
      "Epoch 1071/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0393 - acc: 0.2252 - val_loss: 2.8409 - val_acc: 0.0351\n",
      "Epoch 1072/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0426 - acc: 0.2262 - val_loss: 2.8327 - val_acc: 0.0351\n",
      "Epoch 1073/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0459 - acc: 0.2274 - val_loss: 2.8293 - val_acc: 0.0351\n",
      "Epoch 1074/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0362 - acc: 0.2284 - val_loss: 2.8270 - val_acc: 0.0351\n",
      "Epoch 1075/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0463 - acc: 0.2151 - val_loss: 2.8322 - val_acc: 0.0351\n",
      "Epoch 1076/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0449 - acc: 0.2246 - val_loss: 2.8424 - val_acc: 0.0351\n",
      "Epoch 1077/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0397 - acc: 0.2282 - val_loss: 2.8502 - val_acc: 0.0351\n",
      "Epoch 1078/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0411 - acc: 0.2313 - val_loss: 2.8528 - val_acc: 0.0351\n",
      "Epoch 1079/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0419 - acc: 0.2299 - val_loss: 2.8511 - val_acc: 0.0351\n",
      "Epoch 1080/1500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 2.0433 - acc: 0.2244 - val_loss: 2.8440 - val_acc: 0.0351\n",
      "Epoch 1081/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0408 - acc: 0.2260 - val_loss: 2.8419 - val_acc: 0.0351\n",
      "Epoch 1082/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0380 - acc: 0.2333 - val_loss: 2.8455 - val_acc: 0.0351\n",
      "Epoch 1083/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0387 - acc: 0.2286 - val_loss: 2.8492 - val_acc: 0.0351\n",
      "Epoch 1084/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0411 - acc: 0.2213 - val_loss: 2.8472 - val_acc: 0.0351\n",
      "Epoch 1085/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0395 - acc: 0.2351 - val_loss: 2.8378 - val_acc: 0.0351\n",
      "Epoch 1086/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0396 - acc: 0.2313 - val_loss: 2.8273 - val_acc: 0.0351\n",
      "Epoch 1087/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0461 - acc: 0.2191 - val_loss: 2.8228 - val_acc: 0.0351\n",
      "Epoch 1088/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0405 - acc: 0.2272 - val_loss: 2.8145 - val_acc: 0.0351\n",
      "Epoch 1089/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0427 - acc: 0.2286 - val_loss: 2.8204 - val_acc: 0.0351\n",
      "Epoch 1090/1500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.0398 - acc: 0.2262 - val_loss: 2.8264 - val_acc: 0.0351\n",
      "Epoch 1091/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0415 - acc: 0.2319 - val_loss: 2.8291 - val_acc: 0.0351\n",
      "Epoch 1092/1500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.0386 - acc: 0.2361 - val_loss: 2.8242 - val_acc: 0.0351\n",
      "Epoch 1093/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0394 - acc: 0.2244 - val_loss: 2.8144 - val_acc: 0.0351\n",
      "Epoch 1094/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0407 - acc: 0.2256 - val_loss: 2.8095 - val_acc: 0.0328\n",
      "Epoch 1095/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0412 - acc: 0.2159 - val_loss: 2.8149 - val_acc: 0.0328\n",
      "Epoch 1096/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0413 - acc: 0.2232 - val_loss: 2.8245 - val_acc: 0.0328\n",
      "Epoch 1097/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0407 - acc: 0.2278 - val_loss: 2.8327 - val_acc: 0.0328\n",
      "Epoch 1098/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0391 - acc: 0.2244 - val_loss: 2.8352 - val_acc: 0.0328\n",
      "Epoch 1099/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0405 - acc: 0.2278 - val_loss: 2.8323 - val_acc: 0.0328\n",
      "Epoch 1100/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0403 - acc: 0.2260 - val_loss: 2.8233 - val_acc: 0.0328\n",
      "Epoch 1101/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0412 - acc: 0.2266 - val_loss: 2.8171 - val_acc: 0.0351\n",
      "Epoch 1102/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0420 - acc: 0.2280 - val_loss: 2.8138 - val_acc: 0.0351\n",
      "Epoch 1103/1500\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.0463 - acc: 0.2189 - val_loss: 2.8190 - val_acc: 0.0328\n",
      "Epoch 1104/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0404 - acc: 0.2270 - val_loss: 2.8318 - val_acc: 0.0328\n",
      "Epoch 1105/1500\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.0431 - acc: 0.2228 - val_loss: 2.8492 - val_acc: 0.0351\n",
      "Epoch 1106/1500\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.0432 - acc: 0.2252 - val_loss: 2.8556 - val_acc: 0.0351\n",
      "Epoch 1107/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0472 - acc: 0.2234 - val_loss: 2.8531 - val_acc: 0.0351\n",
      "Epoch 1108/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0424 - acc: 0.2278 - val_loss: 2.8424 - val_acc: 0.0328\n",
      "Epoch 1109/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0397 - acc: 0.2246 - val_loss: 2.8249 - val_acc: 0.0328\n",
      "Epoch 1110/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0395 - acc: 0.2262 - val_loss: 2.8127 - val_acc: 0.0328\n",
      "Epoch 1111/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0395 - acc: 0.2209 - val_loss: 2.8119 - val_acc: 0.0328\n",
      "Epoch 1112/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0391 - acc: 0.2305 - val_loss: 2.8184 - val_acc: 0.0328\n",
      "Epoch 1113/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0420 - acc: 0.2232 - val_loss: 2.8312 - val_acc: 0.0328\n",
      "Epoch 1114/1500\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 2.0424 - acc: 0.2274 - val_loss: 2.8276 - val_acc: 0.0328\n",
      "Epoch 1115/1500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.0394 - acc: 0.2244 - val_loss: 2.8194 - val_acc: 0.0328\n",
      "Epoch 1116/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0418 - acc: 0.2193 - val_loss: 2.8056 - val_acc: 0.0328\n",
      "Epoch 1117/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0438 - acc: 0.2220 - val_loss: 2.7949 - val_acc: 0.0328\n",
      "Epoch 1118/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0415 - acc: 0.2213 - val_loss: 2.7923 - val_acc: 0.0328\n",
      "Epoch 1119/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0373 - acc: 0.2307 - val_loss: 2.7930 - val_acc: 0.0328\n",
      "Epoch 1120/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0387 - acc: 0.2260 - val_loss: 2.7999 - val_acc: 0.0328\n",
      "Epoch 1121/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0416 - acc: 0.2280 - val_loss: 2.8034 - val_acc: 0.0328\n",
      "Epoch 1122/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0367 - acc: 0.2215 - val_loss: 2.8018 - val_acc: 0.0328\n",
      "Epoch 1123/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0363 - acc: 0.2303 - val_loss: 2.7989 - val_acc: 0.0328\n",
      "Epoch 1124/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0410 - acc: 0.2232 - val_loss: 2.7969 - val_acc: 0.0328\n",
      "Epoch 1125/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0418 - acc: 0.2234 - val_loss: 2.7943 - val_acc: 0.0328\n",
      "Epoch 1126/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0388 - acc: 0.2278 - val_loss: 2.7959 - val_acc: 0.0328\n",
      "Epoch 1127/1500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 2.0384 - acc: 0.2282 - val_loss: 2.7969 - val_acc: 0.0328\n",
      "Epoch 1128/1500\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.0411 - acc: 0.2307 - val_loss: 2.7948 - val_acc: 0.0281\n",
      "Epoch 1129/1500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.0393 - acc: 0.2339 - val_loss: 2.7922 - val_acc: 0.0281\n",
      "Epoch 1130/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0391 - acc: 0.2248 - val_loss: 2.7900 - val_acc: 0.0281\n",
      "Epoch 1131/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0433 - acc: 0.2189 - val_loss: 2.7923 - val_acc: 0.0281\n",
      "Epoch 1132/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0424 - acc: 0.2230 - val_loss: 2.8019 - val_acc: 0.0281\n",
      "Epoch 1133/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0406 - acc: 0.2266 - val_loss: 2.8129 - val_acc: 0.0281\n",
      "Epoch 1134/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0398 - acc: 0.2294 - val_loss: 2.8163 - val_acc: 0.0281\n",
      "Epoch 1135/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0415 - acc: 0.2248 - val_loss: 2.8102 - val_acc: 0.0281\n",
      "Epoch 1136/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0370 - acc: 0.2292 - val_loss: 2.7995 - val_acc: 0.0328\n",
      "Epoch 1137/1500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.0381 - acc: 0.2355 - val_loss: 2.7948 - val_acc: 0.0328\n",
      "Epoch 1138/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0408 - acc: 0.2256 - val_loss: 2.7954 - val_acc: 0.0328\n",
      "Epoch 1139/1500\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 2.0404 - acc: 0.2226 - val_loss: 2.8004 - val_acc: 0.0328\n",
      "Epoch 1140/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0376 - acc: 0.2296 - val_loss: 2.8062 - val_acc: 0.0328\n",
      "Epoch 1141/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0386 - acc: 0.2254 - val_loss: 2.8092 - val_acc: 0.0328\n",
      "Epoch 1142/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0420 - acc: 0.2199 - val_loss: 2.8081 - val_acc: 0.0328\n",
      "Epoch 1143/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0414 - acc: 0.2250 - val_loss: 2.8056 - val_acc: 0.0328\n",
      "Epoch 1144/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0362 - acc: 0.2319 - val_loss: 2.7972 - val_acc: 0.0328\n",
      "Epoch 1145/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0412 - acc: 0.2230 - val_loss: 2.7913 - val_acc: 0.0328\n",
      "Epoch 1146/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0427 - acc: 0.2254 - val_loss: 2.7900 - val_acc: 0.0328\n",
      "Epoch 1147/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0387 - acc: 0.2242 - val_loss: 2.7936 - val_acc: 0.0328\n",
      "Epoch 1148/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0418 - acc: 0.2193 - val_loss: 2.7938 - val_acc: 0.0328\n",
      "Epoch 1149/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0416 - acc: 0.2217 - val_loss: 2.7951 - val_acc: 0.0328\n",
      "Epoch 1150/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0396 - acc: 0.2311 - val_loss: 2.7952 - val_acc: 0.0328\n",
      "Epoch 1151/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0378 - acc: 0.2280 - val_loss: 2.7953 - val_acc: 0.0328\n",
      "Epoch 1152/1500\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 2.0411 - acc: 0.2217 - val_loss: 2.7933 - val_acc: 0.0328\n",
      "Epoch 1153/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0439 - acc: 0.2207 - val_loss: 2.7898 - val_acc: 0.0328\n",
      "Epoch 1154/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0376 - acc: 0.2303 - val_loss: 2.7893 - val_acc: 0.0328\n",
      "Epoch 1155/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0417 - acc: 0.2260 - val_loss: 2.7874 - val_acc: 0.0328\n",
      "Epoch 1156/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0390 - acc: 0.2211 - val_loss: 2.7765 - val_acc: 0.0328\n",
      "Epoch 1157/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0396 - acc: 0.2286 - val_loss: 2.7692 - val_acc: 0.0351\n",
      "Epoch 1158/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0404 - acc: 0.2301 - val_loss: 2.7679 - val_acc: 0.0351\n",
      "Epoch 1159/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0408 - acc: 0.2171 - val_loss: 2.7777 - val_acc: 0.0328\n",
      "Epoch 1160/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0374 - acc: 0.2290 - val_loss: 2.7870 - val_acc: 0.0328\n",
      "Epoch 1161/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0431 - acc: 0.2266 - val_loss: 2.7865 - val_acc: 0.0328\n",
      "Epoch 1162/1500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.0418 - acc: 0.2256 - val_loss: 2.7779 - val_acc: 0.0328\n",
      "Epoch 1163/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0404 - acc: 0.2185 - val_loss: 2.7688 - val_acc: 0.0351\n",
      "Epoch 1164/1500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 2.0421 - acc: 0.2282 - val_loss: 2.7610 - val_acc: 0.0351\n",
      "Epoch 1165/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0412 - acc: 0.2278 - val_loss: 2.7616 - val_acc: 0.0328\n",
      "Epoch 1166/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0386 - acc: 0.2313 - val_loss: 2.7625 - val_acc: 0.0328\n",
      "Epoch 1167/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0370 - acc: 0.2319 - val_loss: 2.7640 - val_acc: 0.0328\n",
      "Epoch 1168/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0391 - acc: 0.2258 - val_loss: 2.7684 - val_acc: 0.0328\n",
      "Epoch 1169/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0421 - acc: 0.2217 - val_loss: 2.7718 - val_acc: 0.0328\n",
      "Epoch 1170/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0406 - acc: 0.2256 - val_loss: 2.7733 - val_acc: 0.0328\n",
      "Epoch 1171/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0397 - acc: 0.2272 - val_loss: 2.7724 - val_acc: 0.0328\n",
      "Epoch 1172/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0378 - acc: 0.2217 - val_loss: 2.7681 - val_acc: 0.0328\n",
      "Epoch 1173/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0360 - acc: 0.2264 - val_loss: 2.7626 - val_acc: 0.0328\n",
      "Epoch 1174/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0426 - acc: 0.2252 - val_loss: 2.7644 - val_acc: 0.0328\n",
      "Epoch 1175/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0395 - acc: 0.2290 - val_loss: 2.7749 - val_acc: 0.0328\n",
      "Epoch 1176/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0438 - acc: 0.2191 - val_loss: 2.7856 - val_acc: 0.0328\n",
      "Epoch 1177/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0425 - acc: 0.2311 - val_loss: 2.7844 - val_acc: 0.0328\n",
      "Epoch 1178/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0387 - acc: 0.2238 - val_loss: 2.7776 - val_acc: 0.0328\n",
      "Epoch 1179/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0403 - acc: 0.2181 - val_loss: 2.7680 - val_acc: 0.0328\n",
      "Epoch 1180/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0403 - acc: 0.2258 - val_loss: 2.7630 - val_acc: 0.0328\n",
      "Epoch 1181/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0447 - acc: 0.2220 - val_loss: 2.7697 - val_acc: 0.0328\n",
      "Epoch 1182/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0378 - acc: 0.2311 - val_loss: 2.7779 - val_acc: 0.0328\n",
      "Epoch 1183/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0415 - acc: 0.2228 - val_loss: 2.7850 - val_acc: 0.0328\n",
      "Epoch 1184/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0439 - acc: 0.2157 - val_loss: 2.7916 - val_acc: 0.0328\n",
      "Epoch 1185/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0413 - acc: 0.2248 - val_loss: 2.7937 - val_acc: 0.0328\n",
      "Epoch 1186/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0386 - acc: 0.2248 - val_loss: 2.7897 - val_acc: 0.0328\n",
      "Epoch 1187/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0402 - acc: 0.2296 - val_loss: 2.7840 - val_acc: 0.0328\n",
      "Epoch 1188/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0403 - acc: 0.2286 - val_loss: 2.7832 - val_acc: 0.0328\n",
      "Epoch 1189/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0401 - acc: 0.2224 - val_loss: 2.7858 - val_acc: 0.0328\n",
      "Epoch 1190/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0391 - acc: 0.2262 - val_loss: 2.7932 - val_acc: 0.0328\n",
      "Epoch 1191/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0412 - acc: 0.2264 - val_loss: 2.7989 - val_acc: 0.0304\n",
      "Epoch 1192/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0390 - acc: 0.2224 - val_loss: 2.7934 - val_acc: 0.0304\n",
      "Epoch 1193/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0422 - acc: 0.2248 - val_loss: 2.7819 - val_acc: 0.0351\n",
      "Epoch 1194/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0416 - acc: 0.2179 - val_loss: 2.7691 - val_acc: 0.0328\n",
      "Epoch 1195/1500\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.0439 - acc: 0.2224 - val_loss: 2.7586 - val_acc: 0.0328\n",
      "Epoch 1196/1500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.0425 - acc: 0.2211 - val_loss: 2.7560 - val_acc: 0.0328\n",
      "Epoch 1197/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0409 - acc: 0.2250 - val_loss: 2.7601 - val_acc: 0.0328\n",
      "Epoch 1198/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0345 - acc: 0.2240 - val_loss: 2.7721 - val_acc: 0.0328\n",
      "Epoch 1199/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0422 - acc: 0.2207 - val_loss: 2.7866 - val_acc: 0.0328\n",
      "Epoch 1200/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0397 - acc: 0.2284 - val_loss: 2.7914 - val_acc: 0.0328\n",
      "Epoch 1201/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0380 - acc: 0.2242 - val_loss: 2.7856 - val_acc: 0.0328\n",
      "Epoch 1202/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0381 - acc: 0.2317 - val_loss: 2.7751 - val_acc: 0.0328\n",
      "Epoch 1203/1500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.0412 - acc: 0.2294 - val_loss: 2.7687 - val_acc: 0.0328\n",
      "Epoch 1204/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0369 - acc: 0.2266 - val_loss: 2.7689 - val_acc: 0.0328\n",
      "Epoch 1205/1500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.0419 - acc: 0.2264 - val_loss: 2.7754 - val_acc: 0.0328\n",
      "Epoch 1206/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0399 - acc: 0.2264 - val_loss: 2.7820 - val_acc: 0.0328\n",
      "Epoch 1207/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0447 - acc: 0.2159 - val_loss: 2.7863 - val_acc: 0.0351\n",
      "Epoch 1208/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0365 - acc: 0.2317 - val_loss: 2.7813 - val_acc: 0.0398\n",
      "Epoch 1209/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0389 - acc: 0.2264 - val_loss: 2.7671 - val_acc: 0.0398\n",
      "Epoch 1210/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0375 - acc: 0.2294 - val_loss: 2.7536 - val_acc: 0.0351\n",
      "Epoch 1211/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0390 - acc: 0.2201 - val_loss: 2.7481 - val_acc: 0.0351\n",
      "Epoch 1212/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0356 - acc: 0.2234 - val_loss: 2.7527 - val_acc: 0.0351\n",
      "Epoch 1213/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0378 - acc: 0.2323 - val_loss: 2.7624 - val_acc: 0.0328\n",
      "Epoch 1214/1500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.0376 - acc: 0.2290 - val_loss: 2.7737 - val_acc: 0.0328\n",
      "Epoch 1215/1500\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0426 - acc: 0.2230 - val_loss: 2.7818 - val_acc: 0.0328\n",
      "Epoch 1216/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0478 - acc: 0.2242 - val_loss: 2.7787 - val_acc: 0.0281\n",
      "Epoch 1217/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0427 - acc: 0.2266 - val_loss: 2.7647 - val_acc: 0.0281\n",
      "Epoch 1218/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0389 - acc: 0.2349 - val_loss: 2.7465 - val_acc: 0.0281\n",
      "Epoch 1219/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0398 - acc: 0.2305 - val_loss: 2.7362 - val_acc: 0.0351\n",
      "Epoch 1220/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0391 - acc: 0.2220 - val_loss: 2.7412 - val_acc: 0.0351\n",
      "Epoch 1221/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0420 - acc: 0.2303 - val_loss: 2.7595 - val_acc: 0.0351\n",
      "Epoch 1222/1500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 2.0391 - acc: 0.2248 - val_loss: 2.7890 - val_acc: 0.0304\n",
      "Epoch 1223/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0359 - acc: 0.2280 - val_loss: 2.8117 - val_acc: 0.0351\n",
      "Epoch 1224/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0417 - acc: 0.2272 - val_loss: 2.8181 - val_acc: 0.0398\n",
      "Epoch 1225/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0429 - acc: 0.2280 - val_loss: 2.8064 - val_acc: 0.0445\n",
      "Epoch 1226/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0375 - acc: 0.2311 - val_loss: 2.7835 - val_acc: 0.0398\n",
      "Epoch 1227/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0409 - acc: 0.2250 - val_loss: 2.7644 - val_acc: 0.0328\n",
      "Epoch 1228/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0411 - acc: 0.2236 - val_loss: 2.7584 - val_acc: 0.0445\n",
      "Epoch 1229/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0383 - acc: 0.2276 - val_loss: 2.7655 - val_acc: 0.0445\n",
      "Epoch 1230/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0395 - acc: 0.2262 - val_loss: 2.7787 - val_acc: 0.0445\n",
      "Epoch 1231/1500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 2.0426 - acc: 0.2195 - val_loss: 2.7908 - val_acc: 0.0398\n",
      "Epoch 1232/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0387 - acc: 0.2282 - val_loss: 2.7879 - val_acc: 0.0398\n",
      "Epoch 1233/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0403 - acc: 0.2280 - val_loss: 2.7763 - val_acc: 0.0328\n",
      "Epoch 1234/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0414 - acc: 0.2280 - val_loss: 2.7644 - val_acc: 0.0328\n",
      "Epoch 1235/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0371 - acc: 0.2292 - val_loss: 2.7613 - val_acc: 0.0328\n",
      "Epoch 1236/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0406 - acc: 0.2264 - val_loss: 2.7705 - val_acc: 0.0328\n",
      "Epoch 1237/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0404 - acc: 0.2211 - val_loss: 2.7863 - val_acc: 0.0328\n",
      "Epoch 1238/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0366 - acc: 0.2313 - val_loss: 2.7962 - val_acc: 0.0328\n",
      "Epoch 1239/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0384 - acc: 0.2234 - val_loss: 2.7950 - val_acc: 0.0328\n",
      "Epoch 1240/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0407 - acc: 0.2222 - val_loss: 2.7839 - val_acc: 0.0328\n",
      "Epoch 1241/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0406 - acc: 0.2274 - val_loss: 2.7689 - val_acc: 0.0422\n",
      "Epoch 1242/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0377 - acc: 0.2315 - val_loss: 2.7525 - val_acc: 0.0445\n",
      "Epoch 1243/1500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.0399 - acc: 0.2270 - val_loss: 2.7539 - val_acc: 0.0422\n",
      "Epoch 1244/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0411 - acc: 0.2268 - val_loss: 2.7673 - val_acc: 0.0422\n",
      "Epoch 1245/1500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.0378 - acc: 0.2290 - val_loss: 2.7815 - val_acc: 0.0422\n",
      "Epoch 1246/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0410 - acc: 0.2197 - val_loss: 2.7925 - val_acc: 0.0398\n",
      "Epoch 1247/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0388 - acc: 0.2262 - val_loss: 2.7895 - val_acc: 0.0398\n",
      "Epoch 1248/1500\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 2.0356 - acc: 0.2341 - val_loss: 2.7786 - val_acc: 0.0445\n",
      "Epoch 1249/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0366 - acc: 0.2246 - val_loss: 2.7703 - val_acc: 0.0445\n",
      "Epoch 1250/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0381 - acc: 0.2299 - val_loss: 2.7701 - val_acc: 0.0445\n",
      "Epoch 1251/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0368 - acc: 0.2268 - val_loss: 2.7807 - val_acc: 0.0445\n",
      "Epoch 1252/1500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 2.0381 - acc: 0.2232 - val_loss: 2.7926 - val_acc: 0.0398\n",
      "Epoch 1253/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0371 - acc: 0.2262 - val_loss: 2.8006 - val_acc: 0.0328\n",
      "Epoch 1254/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0377 - acc: 0.2288 - val_loss: 2.7963 - val_acc: 0.0328\n",
      "Epoch 1255/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0400 - acc: 0.2175 - val_loss: 2.7880 - val_acc: 0.0422\n",
      "Epoch 1256/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0407 - acc: 0.2222 - val_loss: 2.7836 - val_acc: 0.0422\n",
      "Epoch 1257/1500\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 2.0389 - acc: 0.2270 - val_loss: 2.7839 - val_acc: 0.0422\n",
      "Epoch 1258/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0422 - acc: 0.2234 - val_loss: 2.7878 - val_acc: 0.0422\n",
      "Epoch 1259/1500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.0396 - acc: 0.2260 - val_loss: 2.7979 - val_acc: 0.0328\n",
      "Epoch 1260/1500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.0380 - acc: 0.2290 - val_loss: 2.8130 - val_acc: 0.0328\n",
      "Epoch 1261/1500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 2.0375 - acc: 0.2317 - val_loss: 2.8188 - val_acc: 0.0328\n",
      "Epoch 1262/1500\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 2.0405 - acc: 0.2228 - val_loss: 2.8164 - val_acc: 0.0328\n",
      "Epoch 1263/1500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.0403 - acc: 0.2286 - val_loss: 2.8109 - val_acc: 0.0328\n",
      "Epoch 1264/1500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.0359 - acc: 0.2321 - val_loss: 2.8042 - val_acc: 0.0398\n",
      "Epoch 1265/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0428 - acc: 0.2228 - val_loss: 2.7980 - val_acc: 0.0375\n",
      "Epoch 1266/1500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.0422 - acc: 0.2276 - val_loss: 2.7937 - val_acc: 0.0375\n",
      "Epoch 1267/1500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 2.0377 - acc: 0.2309 - val_loss: 2.7908 - val_acc: 0.0375\n",
      "Epoch 1268/1500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.0376 - acc: 0.2217 - val_loss: 2.7859 - val_acc: 0.0375\n",
      "Epoch 1269/1500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.0399 - acc: 0.2315 - val_loss: 2.7860 - val_acc: 0.0422\n",
      "Epoch 1270/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0395 - acc: 0.2240 - val_loss: 2.7842 - val_acc: 0.0422\n",
      "Epoch 1271/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0370 - acc: 0.2301 - val_loss: 2.7832 - val_acc: 0.0422\n",
      "Epoch 1272/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0336 - acc: 0.2321 - val_loss: 2.7812 - val_acc: 0.0398\n",
      "Epoch 1273/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0427 - acc: 0.2224 - val_loss: 2.7797 - val_acc: 0.0398\n",
      "Epoch 1274/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0362 - acc: 0.2357 - val_loss: 2.7806 - val_acc: 0.0445\n",
      "Epoch 1275/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0364 - acc: 0.2311 - val_loss: 2.7814 - val_acc: 0.0445\n",
      "Epoch 1276/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0391 - acc: 0.2313 - val_loss: 2.7870 - val_acc: 0.0422\n",
      "Epoch 1277/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0417 - acc: 0.2290 - val_loss: 2.7879 - val_acc: 0.0422\n",
      "Epoch 1278/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0359 - acc: 0.2272 - val_loss: 2.7871 - val_acc: 0.0422\n",
      "Epoch 1279/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0371 - acc: 0.2337 - val_loss: 2.7809 - val_acc: 0.0422\n",
      "Epoch 1280/1500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.0372 - acc: 0.2276 - val_loss: 2.7663 - val_acc: 0.0422\n",
      "Epoch 1281/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0414 - acc: 0.2232 - val_loss: 2.7541 - val_acc: 0.0422\n",
      "Epoch 1282/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0350 - acc: 0.2313 - val_loss: 2.7441 - val_acc: 0.0422\n",
      "Epoch 1283/1500\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.0411 - acc: 0.2207 - val_loss: 2.7411 - val_acc: 0.0422\n",
      "Epoch 1284/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0401 - acc: 0.2252 - val_loss: 2.7424 - val_acc: 0.0351\n",
      "Epoch 1285/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0407 - acc: 0.2305 - val_loss: 2.7478 - val_acc: 0.0351\n",
      "Epoch 1286/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0393 - acc: 0.2230 - val_loss: 2.7533 - val_acc: 0.0351\n",
      "Epoch 1287/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0431 - acc: 0.2254 - val_loss: 2.7554 - val_acc: 0.0351\n",
      "Epoch 1288/1500\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 2.0391 - acc: 0.2296 - val_loss: 2.7484 - val_acc: 0.0351\n",
      "Epoch 1289/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0351 - acc: 0.2268 - val_loss: 2.7417 - val_acc: 0.0351\n",
      "Epoch 1290/1500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0377 - acc: 0.227 - 0s 200ms/step - loss: 2.0377 - acc: 0.2270 - val_loss: 2.7366 - val_acc: 0.0398\n",
      "Epoch 1291/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0386 - acc: 0.2268 - val_loss: 2.7349 - val_acc: 0.0422\n",
      "Epoch 1292/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0385 - acc: 0.2373 - val_loss: 2.7341 - val_acc: 0.0422\n",
      "Epoch 1293/1500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.0390 - acc: 0.2220 - val_loss: 2.7374 - val_acc: 0.0351\n",
      "Epoch 1294/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0392 - acc: 0.2254 - val_loss: 2.7333 - val_acc: 0.0328\n",
      "Epoch 1295/1500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.0432 - acc: 0.2238 - val_loss: 2.7317 - val_acc: 0.0351\n",
      "Epoch 1296/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0402 - acc: 0.2181 - val_loss: 2.7237 - val_acc: 0.0351\n",
      "Epoch 1297/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0347 - acc: 0.2349 - val_loss: 2.7159 - val_acc: 0.0328\n",
      "Epoch 1298/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0390 - acc: 0.2262 - val_loss: 2.7096 - val_acc: 0.0328\n",
      "Epoch 1299/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0405 - acc: 0.2276 - val_loss: 2.7072 - val_acc: 0.0328\n",
      "Epoch 1300/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0385 - acc: 0.2282 - val_loss: 2.7120 - val_acc: 0.0328\n",
      "Epoch 1301/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0397 - acc: 0.2274 - val_loss: 2.7236 - val_acc: 0.0328\n",
      "Epoch 1302/1500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 2.0331 - acc: 0.2321 - val_loss: 2.7375 - val_acc: 0.0304\n",
      "Epoch 1303/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0406 - acc: 0.2236 - val_loss: 2.7493 - val_acc: 0.0304\n",
      "Epoch 1304/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0385 - acc: 0.2262 - val_loss: 2.7556 - val_acc: 0.0304\n",
      "Epoch 1305/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0415 - acc: 0.2232 - val_loss: 2.7523 - val_acc: 0.0304\n",
      "Epoch 1306/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0389 - acc: 0.2252 - val_loss: 2.7464 - val_acc: 0.0304\n",
      "Epoch 1307/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0366 - acc: 0.2355 - val_loss: 2.7449 - val_acc: 0.0258\n",
      "Epoch 1308/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0341 - acc: 0.2345 - val_loss: 2.7438 - val_acc: 0.0258\n",
      "Epoch 1309/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0397 - acc: 0.2240 - val_loss: 2.7503 - val_acc: 0.0281\n",
      "Epoch 1310/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0327 - acc: 0.2367 - val_loss: 2.7556 - val_acc: 0.0281\n",
      "Epoch 1311/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0355 - acc: 0.2319 - val_loss: 2.7559 - val_acc: 0.0281\n",
      "Epoch 1312/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0384 - acc: 0.2266 - val_loss: 2.7521 - val_acc: 0.0281\n",
      "Epoch 1313/1500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.0399 - acc: 0.2284 - val_loss: 2.7480 - val_acc: 0.0281\n",
      "Epoch 1314/1500\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.0385 - acc: 0.2307 - val_loss: 2.7472 - val_acc: 0.0258\n",
      "Epoch 1315/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0359 - acc: 0.2303 - val_loss: 2.7486 - val_acc: 0.0258\n",
      "Epoch 1316/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0382 - acc: 0.2248 - val_loss: 2.7517 - val_acc: 0.0258\n",
      "Epoch 1317/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0423 - acc: 0.2242 - val_loss: 2.7477 - val_acc: 0.0258\n",
      "Epoch 1318/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0387 - acc: 0.2278 - val_loss: 2.7368 - val_acc: 0.0258\n",
      "Epoch 1319/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0369 - acc: 0.2309 - val_loss: 2.7304 - val_acc: 0.0258\n",
      "Epoch 1320/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0397 - acc: 0.2260 - val_loss: 2.7250 - val_acc: 0.0258\n",
      "Epoch 1321/1500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0401 - acc: 0.2246 - val_loss: 2.7219 - val_acc: 0.0258\n",
      "Epoch 1322/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0375 - acc: 0.2299 - val_loss: 2.7233 - val_acc: 0.0258\n",
      "Epoch 1323/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0349 - acc: 0.2305 - val_loss: 2.7263 - val_acc: 0.0258\n",
      "Epoch 1324/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0383 - acc: 0.2319 - val_loss: 2.7319 - val_acc: 0.0258\n",
      "Epoch 1325/1500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.0403 - acc: 0.2264 - val_loss: 2.7354 - val_acc: 0.0258\n",
      "Epoch 1326/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0371 - acc: 0.2343 - val_loss: 2.7277 - val_acc: 0.0258\n",
      "Epoch 1327/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0399 - acc: 0.2266 - val_loss: 2.7153 - val_acc: 0.0258\n",
      "Epoch 1328/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0381 - acc: 0.2197 - val_loss: 2.7088 - val_acc: 0.0281\n",
      "Epoch 1329/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0375 - acc: 0.2254 - val_loss: 2.7066 - val_acc: 0.0258\n",
      "Epoch 1330/1500\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.0372 - acc: 0.2270 - val_loss: 2.7123 - val_acc: 0.0258\n",
      "Epoch 1331/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0392 - acc: 0.2217 - val_loss: 2.7243 - val_acc: 0.0234\n",
      "Epoch 1332/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.0390 - acc: 0.2248 - val_loss: 2.7321 - val_acc: 0.0234\n",
      "Epoch 1333/1500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 2.0399 - acc: 0.2290 - val_loss: 2.7309 - val_acc: 0.0234\n",
      "Epoch 1334/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0338 - acc: 0.2373 - val_loss: 2.7227 - val_acc: 0.0234\n",
      "Epoch 1335/1500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0372 - acc: 0.227 - 0s 203ms/step - loss: 2.0372 - acc: 0.2278 - val_loss: 2.7145 - val_acc: 0.0234\n",
      "Epoch 1336/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0410 - acc: 0.2222 - val_loss: 2.7136 - val_acc: 0.0281\n",
      "Epoch 1337/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0370 - acc: 0.2313 - val_loss: 2.7206 - val_acc: 0.0258\n",
      "Epoch 1338/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0345 - acc: 0.2272 - val_loss: 2.7204 - val_acc: 0.0281\n",
      "Epoch 1339/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0385 - acc: 0.2276 - val_loss: 2.7236 - val_acc: 0.0281\n",
      "Epoch 1340/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0354 - acc: 0.2341 - val_loss: 2.7257 - val_acc: 0.0281\n",
      "Epoch 1341/1500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.0379 - acc: 0.2272 - val_loss: 2.7239 - val_acc: 0.0258\n",
      "Epoch 1342/1500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.0353 - acc: 0.2341 - val_loss: 2.7230 - val_acc: 0.0258\n",
      "Epoch 1343/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0367 - acc: 0.2290 - val_loss: 2.7193 - val_acc: 0.0281\n",
      "Epoch 1344/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0360 - acc: 0.2323 - val_loss: 2.7147 - val_acc: 0.0258\n",
      "Epoch 1345/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0394 - acc: 0.2260 - val_loss: 2.7155 - val_acc: 0.0258\n",
      "Epoch 1346/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0359 - acc: 0.2238 - val_loss: 2.7178 - val_acc: 0.0258\n",
      "Epoch 1347/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0372 - acc: 0.2213 - val_loss: 2.7231 - val_acc: 0.0258\n",
      "Epoch 1348/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0358 - acc: 0.2286 - val_loss: 2.7301 - val_acc: 0.0258\n",
      "Epoch 1349/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0382 - acc: 0.2280 - val_loss: 2.7360 - val_acc: 0.0281\n",
      "Epoch 1350/1500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 2.0377 - acc: 0.2331 - val_loss: 2.7384 - val_acc: 0.0281\n",
      "Epoch 1351/1500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.0373 - acc: 0.2292 - val_loss: 2.7368 - val_acc: 0.0258\n",
      "Epoch 1352/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0339 - acc: 0.2339 - val_loss: 2.7336 - val_acc: 0.0258\n",
      "Epoch 1353/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0351 - acc: 0.2390 - val_loss: 2.7352 - val_acc: 0.0258\n",
      "Epoch 1354/1500\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.0403 - acc: 0.2213 - val_loss: 2.7394 - val_acc: 0.0234\n",
      "Epoch 1355/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0385 - acc: 0.2217 - val_loss: 2.7461 - val_acc: 0.0234\n",
      "Epoch 1356/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0372 - acc: 0.2266 - val_loss: 2.7476 - val_acc: 0.0234\n",
      "Epoch 1357/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0333 - acc: 0.2292 - val_loss: 2.7441 - val_acc: 0.0258\n",
      "Epoch 1358/1500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0351 - acc: 0.2282 - val_loss: 2.7313 - val_acc: 0.0234\n",
      "Epoch 1359/1500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 2.0380 - acc: 0.2211 - val_loss: 2.7218 - val_acc: 0.0234\n",
      "Epoch 1360/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0352 - acc: 0.2276 - val_loss: 2.7228 - val_acc: 0.0234\n",
      "Epoch 1361/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0378 - acc: 0.2236 - val_loss: 2.7339 - val_acc: 0.0211\n",
      "Epoch 1362/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0356 - acc: 0.2380 - val_loss: 2.7451 - val_acc: 0.0234\n",
      "Epoch 1363/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0412 - acc: 0.2248 - val_loss: 2.7552 - val_acc: 0.0258\n",
      "Epoch 1364/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0396 - acc: 0.2305 - val_loss: 2.7513 - val_acc: 0.0258\n",
      "Epoch 1365/1500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 2.0410 - acc: 0.2262 - val_loss: 2.7356 - val_acc: 0.0258\n",
      "Epoch 1366/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0364 - acc: 0.2309 - val_loss: 2.7196 - val_acc: 0.0258\n",
      "Epoch 1367/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0366 - acc: 0.2292 - val_loss: 2.7163 - val_acc: 0.0258\n",
      "Epoch 1368/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0347 - acc: 0.2345 - val_loss: 2.7280 - val_acc: 0.0258\n",
      "Epoch 1369/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0435 - acc: 0.2213 - val_loss: 2.7466 - val_acc: 0.0258\n",
      "Epoch 1370/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0370 - acc: 0.2339 - val_loss: 2.7589 - val_acc: 0.0258\n",
      "Epoch 1371/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0349 - acc: 0.2303 - val_loss: 2.7561 - val_acc: 0.0258\n",
      "Epoch 1372/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0378 - acc: 0.2317 - val_loss: 2.7444 - val_acc: 0.0258\n",
      "Epoch 1373/1500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 2.0371 - acc: 0.2268 - val_loss: 2.7326 - val_acc: 0.0258\n",
      "Epoch 1374/1500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0345 - acc: 0.229 - 0s 193ms/step - loss: 2.0345 - acc: 0.2290 - val_loss: 2.7286 - val_acc: 0.0281\n",
      "Epoch 1375/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0417 - acc: 0.2222 - val_loss: 2.7423 - val_acc: 0.0258\n",
      "Epoch 1376/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0372 - acc: 0.2280 - val_loss: 2.7594 - val_acc: 0.0281\n",
      "Epoch 1377/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0373 - acc: 0.2264 - val_loss: 2.7688 - val_acc: 0.0281\n",
      "Epoch 1378/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0389 - acc: 0.2311 - val_loss: 2.7690 - val_acc: 0.0281\n",
      "Epoch 1379/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0384 - acc: 0.2299 - val_loss: 2.7607 - val_acc: 0.0258\n",
      "Epoch 1380/1500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.0393 - acc: 0.2319 - val_loss: 2.7474 - val_acc: 0.0281\n",
      "Epoch 1381/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0381 - acc: 0.2303 - val_loss: 2.7314 - val_acc: 0.0281\n",
      "Epoch 1382/1500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 2.0347 - acc: 0.2276 - val_loss: 2.7289 - val_acc: 0.0281\n",
      "Epoch 1383/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0365 - acc: 0.2357 - val_loss: 2.7309 - val_acc: 0.0304\n",
      "Epoch 1384/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0396 - acc: 0.2238 - val_loss: 2.7317 - val_acc: 0.0304\n",
      "Epoch 1385/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0409 - acc: 0.2276 - val_loss: 2.7277 - val_acc: 0.0304\n",
      "Epoch 1386/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0348 - acc: 0.2363 - val_loss: 2.7256 - val_acc: 0.0304\n",
      "Epoch 1387/1500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0385 - acc: 0.2268 - val_loss: 2.7284 - val_acc: 0.0304\n",
      "Epoch 1388/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0355 - acc: 0.2305 - val_loss: 2.7375 - val_acc: 0.0258\n",
      "Epoch 1389/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0404 - acc: 0.2238 - val_loss: 2.7490 - val_acc: 0.0258\n",
      "Epoch 1390/1500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.0375 - acc: 0.2290 - val_loss: 2.7604 - val_acc: 0.0258\n",
      "Epoch 1391/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0385 - acc: 0.2250 - val_loss: 2.7686 - val_acc: 0.0258\n",
      "Epoch 1392/1500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.0347 - acc: 0.2351 - val_loss: 2.7698 - val_acc: 0.0258\n",
      "Epoch 1393/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0357 - acc: 0.2329 - val_loss: 2.7627 - val_acc: 0.0258\n",
      "Epoch 1394/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0352 - acc: 0.2296 - val_loss: 2.7507 - val_acc: 0.0258\n",
      "Epoch 1395/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0397 - acc: 0.2187 - val_loss: 2.7431 - val_acc: 0.0281\n",
      "Epoch 1396/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0347 - acc: 0.2369 - val_loss: 2.7378 - val_acc: 0.0281\n",
      "Epoch 1397/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0403 - acc: 0.2240 - val_loss: 2.7365 - val_acc: 0.0281\n",
      "Epoch 1398/1500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 2.0386 - acc: 0.2228 - val_loss: 2.7380 - val_acc: 0.0281\n",
      "Epoch 1399/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0415 - acc: 0.2270 - val_loss: 2.7444 - val_acc: 0.0281\n",
      "Epoch 1400/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0383 - acc: 0.2260 - val_loss: 2.7525 - val_acc: 0.0281\n",
      "Epoch 1401/1500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0395 - acc: 0.2317 - val_loss: 2.7584 - val_acc: 0.0258\n",
      "Epoch 1402/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0359 - acc: 0.2270 - val_loss: 2.7603 - val_acc: 0.0258\n",
      "Epoch 1403/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0378 - acc: 0.2248 - val_loss: 2.7628 - val_acc: 0.0258\n",
      "Epoch 1404/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0367 - acc: 0.2337 - val_loss: 2.7647 - val_acc: 0.0258\n",
      "Epoch 1405/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0392 - acc: 0.2234 - val_loss: 2.7633 - val_acc: 0.0258\n",
      "Epoch 1406/1500\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 2.0336 - acc: 0.2284 - val_loss: 2.7600 - val_acc: 0.0258\n",
      "Epoch 1407/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0376 - acc: 0.2292 - val_loss: 2.7593 - val_acc: 0.0258\n",
      "Epoch 1408/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0395 - acc: 0.2270 - val_loss: 2.7641 - val_acc: 0.0258\n",
      "Epoch 1409/1500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.0389 - acc: 0.2236 - val_loss: 2.7682 - val_acc: 0.0281\n",
      "Epoch 1410/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0376 - acc: 0.2284 - val_loss: 2.7685 - val_acc: 0.0281\n",
      "Epoch 1411/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0355 - acc: 0.2309 - val_loss: 2.7637 - val_acc: 0.0281\n",
      "Epoch 1412/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0382 - acc: 0.2286 - val_loss: 2.7611 - val_acc: 0.0281\n",
      "Epoch 1413/1500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 2.0366 - acc: 0.2299 - val_loss: 2.7641 - val_acc: 0.0281\n",
      "Epoch 1414/1500\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.0358 - acc: 0.2258 - val_loss: 2.7682 - val_acc: 0.0258\n",
      "Epoch 1415/1500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.0387 - acc: 0.2195 - val_loss: 2.7727 - val_acc: 0.0281\n",
      "Epoch 1416/1500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.0383 - acc: 0.2282 - val_loss: 2.7708 - val_acc: 0.0258\n",
      "Epoch 1417/1500\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 2.0368 - acc: 0.2244 - val_loss: 2.7665 - val_acc: 0.0258\n",
      "Epoch 1418/1500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.0382 - acc: 0.2270 - val_loss: 2.7664 - val_acc: 0.0258\n",
      "Epoch 1419/1500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0387 - acc: 0.2205 - val_loss: 2.7685 - val_acc: 0.0258\n",
      "Epoch 1420/1500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 2.0362 - acc: 0.2260 - val_loss: 2.7703 - val_acc: 0.0258\n",
      "Epoch 1421/1500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.0342 - acc: 0.2317 - val_loss: 2.7754 - val_acc: 0.0258\n",
      "Epoch 1422/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0386 - acc: 0.2276 - val_loss: 2.7723 - val_acc: 0.0258\n",
      "Epoch 1423/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0338 - acc: 0.2361 - val_loss: 2.7663 - val_acc: 0.0258\n",
      "Epoch 1424/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0400 - acc: 0.2323 - val_loss: 2.7677 - val_acc: 0.0258\n",
      "Epoch 1425/1500\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0325 - acc: 0.2315 - val_loss: 2.7731 - val_acc: 0.0258\n",
      "Epoch 1426/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0392 - acc: 0.2230 - val_loss: 2.7842 - val_acc: 0.0281\n",
      "Epoch 1427/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0370 - acc: 0.2329 - val_loss: 2.7853 - val_acc: 0.0281\n",
      "Epoch 1428/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0369 - acc: 0.2327 - val_loss: 2.7739 - val_acc: 0.0281\n",
      "Epoch 1429/1500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 2.0325 - acc: 0.2361 - val_loss: 2.7592 - val_acc: 0.0281\n",
      "Epoch 1430/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0407 - acc: 0.2252 - val_loss: 2.7492 - val_acc: 0.0281\n",
      "Epoch 1431/1500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0348 - acc: 0.2311 - val_loss: 2.7480 - val_acc: 0.0281\n",
      "Epoch 1432/1500\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.0383 - acc: 0.2252 - val_loss: 2.7573 - val_acc: 0.0281\n",
      "Epoch 1433/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0354 - acc: 0.2280 - val_loss: 2.7630 - val_acc: 0.0281\n",
      "Epoch 1434/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0373 - acc: 0.2299 - val_loss: 2.7662 - val_acc: 0.0281\n",
      "Epoch 1435/1500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.0365 - acc: 0.2248 - val_loss: 2.7611 - val_acc: 0.0304\n",
      "Epoch 1436/1500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 2.0351 - acc: 0.2317 - val_loss: 2.7573 - val_acc: 0.0304\n",
      "Epoch 1437/1500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0397 - acc: 0.2244 - val_loss: 2.7581 - val_acc: 0.0304\n",
      "Epoch 1438/1500\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.0365 - acc: 0.2327 - val_loss: 2.7623 - val_acc: 0.0304\n",
      "Epoch 1439/1500\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.0333 - acc: 0.2361 - val_loss: 2.7646 - val_acc: 0.0304\n",
      "Epoch 1440/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0350 - acc: 0.2349 - val_loss: 2.7631 - val_acc: 0.0304\n",
      "Epoch 1441/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0354 - acc: 0.2280 - val_loss: 2.7572 - val_acc: 0.0304\n",
      "Epoch 1442/1500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0360 - acc: 0.2294 - val_loss: 2.7485 - val_acc: 0.0304\n",
      "Epoch 1443/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0356 - acc: 0.2313 - val_loss: 2.7408 - val_acc: 0.0304\n",
      "Epoch 1444/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0383 - acc: 0.2242 - val_loss: 2.7392 - val_acc: 0.0304\n",
      "Epoch 1445/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0393 - acc: 0.2258 - val_loss: 2.7403 - val_acc: 0.0304\n",
      "Epoch 1446/1500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0366 - acc: 0.2311 - val_loss: 2.7469 - val_acc: 0.0304\n",
      "Epoch 1447/1500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.0353 - acc: 0.2266 - val_loss: 2.7536 - val_acc: 0.0304\n",
      "Epoch 1448/1500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 2.0344 - acc: 0.2319 - val_loss: 2.7600 - val_acc: 0.0304\n",
      "Epoch 1449/1500\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.0353 - acc: 0.2317 - val_loss: 2.7673 - val_acc: 0.0304\n",
      "Epoch 1450/1500\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 2.0365 - acc: 0.2268 - val_loss: 2.7702 - val_acc: 0.0304\n",
      "Epoch 1451/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0337 - acc: 0.2252 - val_loss: 2.7679 - val_acc: 0.0258\n",
      "Epoch 1452/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0350 - acc: 0.2313 - val_loss: 2.7640 - val_acc: 0.0258\n",
      "Epoch 1453/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0344 - acc: 0.2248 - val_loss: 2.7609 - val_acc: 0.0258\n",
      "Epoch 1454/1500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.0345 - acc: 0.2317 - val_loss: 2.7649 - val_acc: 0.0258\n",
      "Epoch 1455/1500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 2.0323 - acc: 0.2373 - val_loss: 2.7680 - val_acc: 0.0258\n",
      "Epoch 1456/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0359 - acc: 0.2274 - val_loss: 2.7663 - val_acc: 0.0258\n",
      "Epoch 1457/1500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.0344 - acc: 0.2311 - val_loss: 2.7652 - val_acc: 0.0258\n",
      "Epoch 1458/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0383 - acc: 0.2327 - val_loss: 2.7602 - val_acc: 0.0258\n",
      "Epoch 1459/1500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.0357 - acc: 0.2278 - val_loss: 2.7564 - val_acc: 0.0258\n",
      "Epoch 1460/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0321 - acc: 0.2369 - val_loss: 2.7524 - val_acc: 0.0328\n",
      "Epoch 1461/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0387 - acc: 0.2205 - val_loss: 2.7515 - val_acc: 0.0281\n",
      "Epoch 1462/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0331 - acc: 0.2315 - val_loss: 2.7516 - val_acc: 0.0258\n",
      "Epoch 1463/1500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.0312 - acc: 0.2299 - val_loss: 2.7579 - val_acc: 0.0258\n",
      "Epoch 1464/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0390 - acc: 0.2240 - val_loss: 2.7707 - val_acc: 0.0258\n",
      "Epoch 1465/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0358 - acc: 0.2299 - val_loss: 2.7806 - val_acc: 0.0258\n",
      "Epoch 1466/1500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.0382 - acc: 0.2270 - val_loss: 2.7821 - val_acc: 0.0258\n",
      "Epoch 1467/1500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.0348 - acc: 0.2317 - val_loss: 2.7749 - val_acc: 0.0258\n",
      "Epoch 1468/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0369 - acc: 0.2305 - val_loss: 2.7674 - val_acc: 0.0258\n",
      "Epoch 1469/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0345 - acc: 0.2317 - val_loss: 2.7599 - val_acc: 0.0258\n",
      "Epoch 1470/1500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0377 - acc: 0.2260 - val_loss: 2.7620 - val_acc: 0.0258\n",
      "Epoch 1471/1500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.0344 - acc: 0.2313 - val_loss: 2.7697 - val_acc: 0.0281\n",
      "Epoch 1472/1500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0372 - acc: 0.2242 - val_loss: 2.7789 - val_acc: 0.0281\n",
      "Epoch 1473/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0376 - acc: 0.2276 - val_loss: 2.7844 - val_acc: 0.0281\n",
      "Epoch 1474/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0384 - acc: 0.2201 - val_loss: 2.7850 - val_acc: 0.0258\n",
      "Epoch 1475/1500\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 2.0357 - acc: 0.2242 - val_loss: 2.7860 - val_acc: 0.0258\n",
      "Epoch 1476/1500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.0365 - acc: 0.2299 - val_loss: 2.7835 - val_acc: 0.0258\n",
      "Epoch 1477/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0349 - acc: 0.2288 - val_loss: 2.7777 - val_acc: 0.0258\n",
      "Epoch 1478/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0329 - acc: 0.2313 - val_loss: 2.7732 - val_acc: 0.0258\n",
      "Epoch 1479/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0345 - acc: 0.2284 - val_loss: 2.7724 - val_acc: 0.0258\n",
      "Epoch 1480/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0374 - acc: 0.2234 - val_loss: 2.7733 - val_acc: 0.0258\n",
      "Epoch 1481/1500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 2.0375 - acc: 0.2288 - val_loss: 2.7733 - val_acc: 0.0258\n",
      "Epoch 1482/1500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0372 - acc: 0.2309 - val_loss: 2.7739 - val_acc: 0.0258\n",
      "Epoch 1483/1500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.0361 - acc: 0.2228 - val_loss: 2.7703 - val_acc: 0.0258\n",
      "Epoch 1484/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0376 - acc: 0.2276 - val_loss: 2.7686 - val_acc: 0.0258\n",
      "Epoch 1485/1500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.0367 - acc: 0.2260 - val_loss: 2.7720 - val_acc: 0.0258\n",
      "Epoch 1486/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0367 - acc: 0.2282 - val_loss: 2.7753 - val_acc: 0.0258\n",
      "Epoch 1487/1500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 2.0371 - acc: 0.2299 - val_loss: 2.7804 - val_acc: 0.0258\n",
      "Epoch 1488/1500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0338 - acc: 0.2339 - val_loss: 2.7713 - val_acc: 0.0258\n",
      "Epoch 1489/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0374 - acc: 0.2299 - val_loss: 2.7586 - val_acc: 0.0258\n",
      "Epoch 1490/1500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.0390 - acc: 0.2296 - val_loss: 2.7544 - val_acc: 0.0258\n",
      "Epoch 1491/1500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.0396 - acc: 0.2286 - val_loss: 2.7639 - val_acc: 0.0234\n",
      "Epoch 1492/1500\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0369 - acc: 0.2250 - val_loss: 2.7778 - val_acc: 0.0258\n",
      "Epoch 1493/1500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.0339 - acc: 0.2286 - val_loss: 2.7913 - val_acc: 0.0258\n",
      "Epoch 1494/1500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.0384 - acc: 0.2315 - val_loss: 2.7877 - val_acc: 0.0258\n",
      "Epoch 1495/1500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 2.0342 - acc: 0.2361 - val_loss: 2.7739 - val_acc: 0.0304\n",
      "Epoch 1496/1500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2.0369 - acc: 0.2311 - val_loss: 2.7584 - val_acc: 0.0328\n",
      "Epoch 1497/1500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0348 - acc: 0.231 - 0s 207ms/step - loss: 2.0348 - acc: 0.2315 - val_loss: 2.7516 - val_acc: 0.0328\n",
      "Epoch 1498/1500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.0322 - acc: 0.2327 - val_loss: 2.7522 - val_acc: 0.0258\n",
      "Epoch 1499/1500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.0331 - acc: 0.2280 - val_loss: 2.7632 - val_acc: 0.0281\n",
      "Epoch 1500/1500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.0360 - acc: 0.2278 - val_loss: 2.7773 - val_acc: 0.0304\n"
     ]
    }
   ],
   "source": [
    "validation_text = []\n",
    "for i in range(len(valid_set)):\n",
    "    df = pd.read_csv(lab_files_path+valid_set[i])\n",
    "    Text = df['Object'].to_list()\n",
    "\n",
    "    for T in Text:\n",
    "        validation_text.append(T)\n",
    "\n",
    "\n",
    "valid_embeddings = []\n",
    "for t in valid_text:\n",
    "    valid_embeddings.append(Loaded_model.wv[t])\n",
    "    \n",
    "valid_embeddings = np.array(valid_embeddings)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# print(\"Shape of A1 is: \", np.shape(A1))\n",
    "# print(\"Shape of embeddings is: \", np.shape(train_embeddings))\n",
    "# print(\"Shape of train embeddings is: \", np.shape(b1_text))\n",
    "\n",
    "\n",
    "# print(\"Shape of A4 is: \", np.shape(A4))\n",
    "# print(\"Shape of embeddings is: \", np.shape(valid_embeddings))\n",
    "# print(\"Shape of train embeddings is: \", np.shape(valid_text))\n",
    "\n",
    "history = model.fit([train_embeddings, A1],\n",
    "                    b1_encodings,\n",
    "                    epochs=1500,\n",
    "                    batch_size=N,\n",
    "                    # class_weight=W,\n",
    "                    validation_data=([valid_embeddings, A4], valid_encodings),\n",
    "                    # callbacks=[callback]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c77d555b0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "# history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c77e1c430>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\n",
    "    \"./Model/IDS_Batch1_0.1778(validation_accuracy).h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv (GCNConv)             (None, 32)           3232        ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gcn_conv_1 (GCNConv)           (None, 32)           1056        ['gcn_conv[0][0]',               \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 32)           0           ['gcn_conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          4224        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           4128        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,970\n",
      "Trainable params: 12,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"./Model/IDS_Batch1_0.1778(validation_accuracy).h5\",\n",
    "                   custom_objects={\"GCNConv\": GCNConv})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on Batch-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2460, 100)\n",
      "(2460, 2460)\n",
      "(2460,)\n",
      "Validation set shape\n",
      "(427, 100)\n",
      "(427, 427)\n",
      "(427,)\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 2.2672 - acc: 0.1346 - val_loss: 2.6648 - val_acc: 0.0468\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2169 - acc: 0.1325 - val_loss: 2.5453 - val_acc: 0.0609\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1804 - acc: 0.1537 - val_loss: 2.4741 - val_acc: 0.1171\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1635 - acc: 0.2211 - val_loss: 2.4474 - val_acc: 0.1288\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1751 - acc: 0.2236 - val_loss: 2.4348 - val_acc: 0.1405\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1696 - acc: 0.2386 - val_loss: 2.4232 - val_acc: 0.1382\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1684 - acc: 0.2402 - val_loss: 2.4096 - val_acc: 0.1475\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1545 - acc: 0.2305 - val_loss: 2.3980 - val_acc: 0.1522\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1431 - acc: 0.2443 - val_loss: 2.3963 - val_acc: 0.1616\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1447 - acc: 0.2390 - val_loss: 2.4040 - val_acc: 0.1780\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1382 - acc: 0.2581 - val_loss: 2.4154 - val_acc: 0.2061\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1333 - acc: 0.2443 - val_loss: 2.4315 - val_acc: 0.2155\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1256 - acc: 0.2423 - val_loss: 2.4534 - val_acc: 0.2108\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1243 - acc: 0.2431 - val_loss: 2.4786 - val_acc: 0.2155\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1091 - acc: 0.2459 - val_loss: 2.5065 - val_acc: 0.2178\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1159 - acc: 0.2472 - val_loss: 2.5368 - val_acc: 0.2248\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1111 - acc: 0.2533 - val_loss: 2.5687 - val_acc: 0.2295\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1045 - acc: 0.2459 - val_loss: 2.6009 - val_acc: 0.2131\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0977 - acc: 0.2528 - val_loss: 2.6281 - val_acc: 0.2131\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1073 - acc: 0.2549 - val_loss: 2.6496 - val_acc: 0.2131\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.1140 - acc: 0.2439 - val_loss: 2.6640 - val_acc: 0.2108\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1110 - acc: 0.2496 - val_loss: 2.6694 - val_acc: 0.2014\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1106 - acc: 0.2423 - val_loss: 2.6673 - val_acc: 0.2014\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1070 - acc: 0.2488 - val_loss: 2.6611 - val_acc: 0.2084\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.1067 - acc: 0.2492 - val_loss: 2.6528 - val_acc: 0.2084\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.1102 - acc: 0.2496 - val_loss: 2.6424 - val_acc: 0.2061\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1061 - acc: 0.2561 - val_loss: 2.6316 - val_acc: 0.2061\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.1006 - acc: 0.2484 - val_loss: 2.6233 - val_acc: 0.2061\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.1006 - acc: 0.2496 - val_loss: 2.6148 - val_acc: 0.2061\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.1053 - acc: 0.2382 - val_loss: 2.6063 - val_acc: 0.2014\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1037 - acc: 0.2520 - val_loss: 2.5978 - val_acc: 0.1967\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1032 - acc: 0.2480 - val_loss: 2.5883 - val_acc: 0.1967\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.0981 - acc: 0.2455 - val_loss: 2.5786 - val_acc: 0.1967\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1020 - acc: 0.2439 - val_loss: 2.5724 - val_acc: 0.1991\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1060 - acc: 0.2463 - val_loss: 2.5678 - val_acc: 0.1991\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1034 - acc: 0.2370 - val_loss: 2.5647 - val_acc: 0.1991\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1050 - acc: 0.2484 - val_loss: 2.5632 - val_acc: 0.1991\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.1008 - acc: 0.2553 - val_loss: 2.5655 - val_acc: 0.1991\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0978 - acc: 0.2524 - val_loss: 2.5711 - val_acc: 0.1991\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0998 - acc: 0.2557 - val_loss: 2.5761 - val_acc: 0.1967\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0917 - acc: 0.2524 - val_loss: 2.5835 - val_acc: 0.1967\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.1033 - acc: 0.2382 - val_loss: 2.5917 - val_acc: 0.1967\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0983 - acc: 0.2512 - val_loss: 2.5990 - val_acc: 0.1967\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0951 - acc: 0.2504 - val_loss: 2.6049 - val_acc: 0.1967\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0936 - acc: 0.2537 - val_loss: 2.6086 - val_acc: 0.1967\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0928 - acc: 0.2565 - val_loss: 2.6135 - val_acc: 0.1967\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0966 - acc: 0.2528 - val_loss: 2.6189 - val_acc: 0.1967\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0893 - acc: 0.2533 - val_loss: 2.6235 - val_acc: 0.1967\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0961 - acc: 0.2520 - val_loss: 2.6269 - val_acc: 0.1967\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.1000 - acc: 0.2472 - val_loss: 2.6285 - val_acc: 0.1991\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0886 - acc: 0.2549 - val_loss: 2.6284 - val_acc: 0.1991\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0953 - acc: 0.2528 - val_loss: 2.6263 - val_acc: 0.1991\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0953 - acc: 0.2435 - val_loss: 2.6233 - val_acc: 0.1991\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0882 - acc: 0.2545 - val_loss: 2.6213 - val_acc: 0.1920\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.0940 - acc: 0.2431 - val_loss: 2.6189 - val_acc: 0.1944\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0934 - acc: 0.2455 - val_loss: 2.6175 - val_acc: 0.1944\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0972 - acc: 0.2549 - val_loss: 2.6157 - val_acc: 0.1944\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0982 - acc: 0.2451 - val_loss: 2.6096 - val_acc: 0.1944\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.0845 - acc: 0.2533 - val_loss: 2.6035 - val_acc: 0.1944\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.0926 - acc: 0.2553 - val_loss: 2.6018 - val_acc: 0.1920\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0973 - acc: 0.2455 - val_loss: 2.6026 - val_acc: 0.1967\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0896 - acc: 0.2589 - val_loss: 2.6078 - val_acc: 0.1944\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0908 - acc: 0.2516 - val_loss: 2.6153 - val_acc: 0.1944\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0874 - acc: 0.2500 - val_loss: 2.6215 - val_acc: 0.1897\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0892 - acc: 0.2528 - val_loss: 2.6251 - val_acc: 0.1897\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0894 - acc: 0.2528 - val_loss: 2.6281 - val_acc: 0.1897\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0879 - acc: 0.2500 - val_loss: 2.6289 - val_acc: 0.1944\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0950 - acc: 0.2435 - val_loss: 2.6281 - val_acc: 0.1944\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0850 - acc: 0.2537 - val_loss: 2.6262 - val_acc: 0.1897\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0898 - acc: 0.2520 - val_loss: 2.6239 - val_acc: 0.1897\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0959 - acc: 0.2504 - val_loss: 2.6244 - val_acc: 0.1944\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0910 - acc: 0.2496 - val_loss: 2.6232 - val_acc: 0.1967\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0830 - acc: 0.2528 - val_loss: 2.6232 - val_acc: 0.1991\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0879 - acc: 0.2512 - val_loss: 2.6235 - val_acc: 0.1991\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0862 - acc: 0.2492 - val_loss: 2.6249 - val_acc: 0.1991\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0885 - acc: 0.2496 - val_loss: 2.6277 - val_acc: 0.1991\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0884 - acc: 0.2541 - val_loss: 2.6287 - val_acc: 0.1944\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0855 - acc: 0.2585 - val_loss: 2.6267 - val_acc: 0.1897\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0894 - acc: 0.2508 - val_loss: 2.6262 - val_acc: 0.1850\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0870 - acc: 0.2549 - val_loss: 2.6290 - val_acc: 0.1827\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0839 - acc: 0.2541 - val_loss: 2.6349 - val_acc: 0.1827\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0862 - acc: 0.2573 - val_loss: 2.6422 - val_acc: 0.1920\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0890 - acc: 0.2524 - val_loss: 2.6485 - val_acc: 0.1944\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0856 - acc: 0.2528 - val_loss: 2.6509 - val_acc: 0.1944\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0830 - acc: 0.2573 - val_loss: 2.6482 - val_acc: 0.1944\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0874 - acc: 0.2565 - val_loss: 2.6458 - val_acc: 0.1944\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0853 - acc: 0.2472 - val_loss: 2.6423 - val_acc: 0.1897\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.0894 - acc: 0.2553 - val_loss: 2.6386 - val_acc: 0.1874\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0861 - acc: 0.2541 - val_loss: 2.6397 - val_acc: 0.1874\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0898 - acc: 0.2520 - val_loss: 2.6425 - val_acc: 0.1874\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0940 - acc: 0.251 - 0s 88ms/step - loss: 2.0940 - acc: 0.2512 - val_loss: 2.6501 - val_acc: 0.1897\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0861 - acc: 0.2447 - val_loss: 2.6578 - val_acc: 0.1944\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.0868 - acc: 0.2561 - val_loss: 2.6627 - val_acc: 0.1991\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0872 - acc: 0.2524 - val_loss: 2.6620 - val_acc: 0.1991\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0868 - acc: 0.2541 - val_loss: 2.6546 - val_acc: 0.1920\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0855 - acc: 0.2561 - val_loss: 2.6432 - val_acc: 0.1874\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0833 - acc: 0.2516 - val_loss: 2.6334 - val_acc: 0.1803\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0858 - acc: 0.2557 - val_loss: 2.6260 - val_acc: 0.1803\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0864 - acc: 0.2565 - val_loss: 2.6260 - val_acc: 0.1803\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0822 - acc: 0.2467 - val_loss: 2.6313 - val_acc: 0.1827\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0918 - acc: 0.2520 - val_loss: 2.6408 - val_acc: 0.1874\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0906 - acc: 0.2533 - val_loss: 2.6466 - val_acc: 0.1897\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0916 - acc: 0.2443 - val_loss: 2.6496 - val_acc: 0.1920\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0911 - acc: 0.2459 - val_loss: 2.6478 - val_acc: 0.1897\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0893 - acc: 0.2496 - val_loss: 2.6457 - val_acc: 0.1897\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0807 - acc: 0.2520 - val_loss: 2.6434 - val_acc: 0.1897\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0850 - acc: 0.2549 - val_loss: 2.6405 - val_acc: 0.1827\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0731 - acc: 0.2618 - val_loss: 2.6391 - val_acc: 0.1803\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0812 - acc: 0.2622 - val_loss: 2.6399 - val_acc: 0.1803\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.0832 - acc: 0.2537 - val_loss: 2.6438 - val_acc: 0.1803\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0864 - acc: 0.2541 - val_loss: 2.6488 - val_acc: 0.1874\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0825 - acc: 0.2606 - val_loss: 2.6518 - val_acc: 0.1874\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0838 - acc: 0.2504 - val_loss: 2.6503 - val_acc: 0.1874\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0841 - acc: 0.2431 - val_loss: 2.6468 - val_acc: 0.1850\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0856 - acc: 0.2500 - val_loss: 2.6440 - val_acc: 0.1827\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0917 - acc: 0.2512 - val_loss: 2.6416 - val_acc: 0.1803\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0804 - acc: 0.2520 - val_loss: 2.6411 - val_acc: 0.1803\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0812 - acc: 0.2516 - val_loss: 2.6425 - val_acc: 0.1827\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0762 - acc: 0.2602 - val_loss: 2.6403 - val_acc: 0.1827\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0830 - acc: 0.2524 - val_loss: 2.6353 - val_acc: 0.1803\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0856 - acc: 0.2524 - val_loss: 2.6302 - val_acc: 0.1803\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0842 - acc: 0.2565 - val_loss: 2.6295 - val_acc: 0.1827\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0882 - acc: 0.2508 - val_loss: 2.6248 - val_acc: 0.1850\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0787 - acc: 0.2541 - val_loss: 2.6229 - val_acc: 0.1827\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0843 - acc: 0.2484 - val_loss: 2.6246 - val_acc: 0.1827\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0880 - acc: 0.2447 - val_loss: 2.6301 - val_acc: 0.1850\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0803 - acc: 0.2528 - val_loss: 2.6332 - val_acc: 0.1850\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0835 - acc: 0.2569 - val_loss: 2.6315 - val_acc: 0.1850\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0848 - acc: 0.2553 - val_loss: 2.6293 - val_acc: 0.1850\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0831 - acc: 0.2516 - val_loss: 2.6243 - val_acc: 0.1827\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0833 - acc: 0.2451 - val_loss: 2.6160 - val_acc: 0.1920\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0802 - acc: 0.2545 - val_loss: 2.6057 - val_acc: 0.1920\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0821 - acc: 0.2467 - val_loss: 2.5977 - val_acc: 0.1897\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0803 - acc: 0.2659 - val_loss: 2.5948 - val_acc: 0.1897\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0831 - acc: 0.2488 - val_loss: 2.5972 - val_acc: 0.1920\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0855 - acc: 0.2423 - val_loss: 2.6048 - val_acc: 0.1920\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0813 - acc: 0.255 - 0s 77ms/step - loss: 2.0813 - acc: 0.2557 - val_loss: 2.6076 - val_acc: 0.1944\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0820 - acc: 0.2504 - val_loss: 2.6080 - val_acc: 0.1944\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0841 - acc: 0.2476 - val_loss: 2.6044 - val_acc: 0.1920\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0805 - acc: 0.2589 - val_loss: 2.5990 - val_acc: 0.1874\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0792 - acc: 0.2541 - val_loss: 2.5968 - val_acc: 0.1897\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0845 - acc: 0.256 - 0s 81ms/step - loss: 2.0845 - acc: 0.2565 - val_loss: 2.5982 - val_acc: 0.1920\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0770 - acc: 0.2541 - val_loss: 2.6018 - val_acc: 0.1920\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0813 - acc: 0.2598 - val_loss: 2.6061 - val_acc: 0.1944\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0828 - acc: 0.2569 - val_loss: 2.6109 - val_acc: 0.2014\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0803 - acc: 0.2528 - val_loss: 2.6107 - val_acc: 0.2014\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0807 - acc: 0.2520 - val_loss: 2.6099 - val_acc: 0.2014\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0736 - acc: 0.2565 - val_loss: 2.6091 - val_acc: 0.2014\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0787 - acc: 0.2549 - val_loss: 2.6099 - val_acc: 0.2014\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0845 - acc: 0.2553 - val_loss: 2.6125 - val_acc: 0.2037\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0774 - acc: 0.2516 - val_loss: 2.6179 - val_acc: 0.2014\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0738 - acc: 0.2585 - val_loss: 2.6239 - val_acc: 0.2037\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0797 - acc: 0.2541 - val_loss: 2.6265 - val_acc: 0.2037\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0820 - acc: 0.2533 - val_loss: 2.6252 - val_acc: 0.2037\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0842 - acc: 0.2541 - val_loss: 2.6245 - val_acc: 0.2014\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0891 - acc: 0.2463 - val_loss: 2.6254 - val_acc: 0.2014\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0808 - acc: 0.2610 - val_loss: 2.6247 - val_acc: 0.2014\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0818 - acc: 0.2573 - val_loss: 2.6244 - val_acc: 0.2014\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0740 - acc: 0.2606 - val_loss: 2.6236 - val_acc: 0.2014\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0820 - acc: 0.2545 - val_loss: 2.6234 - val_acc: 0.2014\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0816 - acc: 0.2602 - val_loss: 2.6261 - val_acc: 0.2014\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0764 - acc: 0.2569 - val_loss: 2.6288 - val_acc: 0.1991\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0763 - acc: 0.2545 - val_loss: 2.6294 - val_acc: 0.1991\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0849 - acc: 0.2541 - val_loss: 2.6270 - val_acc: 0.2014\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0767 - acc: 0.2533 - val_loss: 2.6232 - val_acc: 0.2014\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0758 - acc: 0.2573 - val_loss: 2.6210 - val_acc: 0.2037\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0802 - acc: 0.2573 - val_loss: 2.6242 - val_acc: 0.2014\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0777 - acc: 0.2537 - val_loss: 2.6313 - val_acc: 0.1874\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0796 - acc: 0.2602 - val_loss: 2.6373 - val_acc: 0.1920\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0773 - acc: 0.2557 - val_loss: 2.6396 - val_acc: 0.1874\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0771 - acc: 0.2569 - val_loss: 2.6354 - val_acc: 0.1874\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0764 - acc: 0.2528 - val_loss: 2.6296 - val_acc: 0.1827\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0763 - acc: 0.2541 - val_loss: 2.6224 - val_acc: 0.1827\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0764 - acc: 0.2524 - val_loss: 2.6182 - val_acc: 0.1850\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0772 - acc: 0.2598 - val_loss: 2.6175 - val_acc: 0.1827\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0760 - acc: 0.2561 - val_loss: 2.6202 - val_acc: 0.1827\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0782 - acc: 0.2545 - val_loss: 2.6227 - val_acc: 0.1780\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0782 - acc: 0.2549 - val_loss: 2.6252 - val_acc: 0.1780\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0770 - acc: 0.2528 - val_loss: 2.6263 - val_acc: 0.1780\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0784 - acc: 0.2569 - val_loss: 2.6293 - val_acc: 0.1780\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0719 - acc: 0.2650 - val_loss: 2.6299 - val_acc: 0.1850\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0773 - acc: 0.2516 - val_loss: 2.6273 - val_acc: 0.1803\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0803 - acc: 0.2549 - val_loss: 2.6246 - val_acc: 0.1803\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0751 - acc: 0.2553 - val_loss: 2.6263 - val_acc: 0.1780\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0805 - acc: 0.2533 - val_loss: 2.6294 - val_acc: 0.1897\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0751 - acc: 0.2569 - val_loss: 2.6325 - val_acc: 0.1850\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0744 - acc: 0.2512 - val_loss: 2.6338 - val_acc: 0.1874\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0722 - acc: 0.2577 - val_loss: 2.6326 - val_acc: 0.1874\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0802 - acc: 0.2476 - val_loss: 2.6296 - val_acc: 0.1827\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0701 - acc: 0.2602 - val_loss: 2.6233 - val_acc: 0.1850\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0813 - acc: 0.2500 - val_loss: 2.6233 - val_acc: 0.1850\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0746 - acc: 0.2545 - val_loss: 2.6237 - val_acc: 0.1850\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0748 - acc: 0.2528 - val_loss: 2.6271 - val_acc: 0.1827\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0794 - acc: 0.2573 - val_loss: 2.6307 - val_acc: 0.1780\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0785 - acc: 0.2504 - val_loss: 2.6305 - val_acc: 0.1827\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0847 - acc: 0.2561 - val_loss: 2.6275 - val_acc: 0.1827\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0737 - acc: 0.2573 - val_loss: 2.6209 - val_acc: 0.1803\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0769 - acc: 0.2476 - val_loss: 2.6182 - val_acc: 0.1686\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0783 - acc: 0.2585 - val_loss: 2.6201 - val_acc: 0.1686\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0808 - acc: 0.254 - 0s 80ms/step - loss: 2.0808 - acc: 0.2541 - val_loss: 2.6231 - val_acc: 0.1803\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0848 - acc: 0.2500 - val_loss: 2.6261 - val_acc: 0.1803\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0808 - acc: 0.2492 - val_loss: 2.6286 - val_acc: 0.1850\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0832 - acc: 0.2524 - val_loss: 2.6323 - val_acc: 0.1850\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0827 - acc: 0.2537 - val_loss: 2.6362 - val_acc: 0.1850\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0750 - acc: 0.2541 - val_loss: 2.6383 - val_acc: 0.1874\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0791 - acc: 0.2561 - val_loss: 2.6407 - val_acc: 0.1780\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0776 - acc: 0.2602 - val_loss: 2.6413 - val_acc: 0.1803\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0735 - acc: 0.2553 - val_loss: 2.6390 - val_acc: 0.1850\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0802 - acc: 0.2533 - val_loss: 2.6344 - val_acc: 0.1897\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0801 - acc: 0.2565 - val_loss: 2.6372 - val_acc: 0.1850\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0741 - acc: 0.2573 - val_loss: 2.6406 - val_acc: 0.1944\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0802 - acc: 0.2537 - val_loss: 2.6403 - val_acc: 0.1944\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0698 - acc: 0.2549 - val_loss: 2.6359 - val_acc: 0.1920\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0758 - acc: 0.2537 - val_loss: 2.6366 - val_acc: 0.1874\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0783 - acc: 0.2638 - val_loss: 2.6435 - val_acc: 0.1827\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0836 - acc: 0.2447 - val_loss: 2.6508 - val_acc: 0.1827\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0785 - acc: 0.2472 - val_loss: 2.6547 - val_acc: 0.1827\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0776 - acc: 0.2557 - val_loss: 2.6547 - val_acc: 0.1827\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0826 - acc: 0.2533 - val_loss: 2.6495 - val_acc: 0.1897\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0784 - acc: 0.2581 - val_loss: 2.6451 - val_acc: 0.1920\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0792 - acc: 0.2528 - val_loss: 2.6453 - val_acc: 0.1920\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0721 - acc: 0.2642 - val_loss: 2.6504 - val_acc: 0.1897\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0804 - acc: 0.2496 - val_loss: 2.6583 - val_acc: 0.1897\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0769 - acc: 0.2557 - val_loss: 2.6696 - val_acc: 0.1874\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0774 - acc: 0.2553 - val_loss: 2.6732 - val_acc: 0.1874\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0741 - acc: 0.2573 - val_loss: 2.6672 - val_acc: 0.1874\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0782 - acc: 0.2533 - val_loss: 2.6588 - val_acc: 0.1850\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0746 - acc: 0.2545 - val_loss: 2.6519 - val_acc: 0.1874\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.0798 - acc: 0.2516 - val_loss: 2.6517 - val_acc: 0.1827\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0756 - acc: 0.2561 - val_loss: 2.6575 - val_acc: 0.1850\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0743 - acc: 0.2557 - val_loss: 2.6644 - val_acc: 0.1803\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0772 - acc: 0.2541 - val_loss: 2.6671 - val_acc: 0.1803\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0724 - acc: 0.2602 - val_loss: 2.6685 - val_acc: 0.1803\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 2.0768 - acc: 0.2561 - val_loss: 2.6675 - val_acc: 0.1780\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0781 - acc: 0.2496 - val_loss: 2.6662 - val_acc: 0.1780\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0739 - acc: 0.2618 - val_loss: 2.6646 - val_acc: 0.1780\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0763 - acc: 0.2500 - val_loss: 2.6664 - val_acc: 0.1780\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0806 - acc: 0.2488 - val_loss: 2.6726 - val_acc: 0.1780\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0715 - acc: 0.2610 - val_loss: 2.6788 - val_acc: 0.1780\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0750 - acc: 0.2573 - val_loss: 2.6804 - val_acc: 0.1780\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0725 - acc: 0.2602 - val_loss: 2.6827 - val_acc: 0.1780\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0790 - acc: 0.2512 - val_loss: 2.6815 - val_acc: 0.1780\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0707 - acc: 0.2622 - val_loss: 2.6798 - val_acc: 0.1780\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0727 - acc: 0.2606 - val_loss: 2.6776 - val_acc: 0.1780\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0800 - acc: 0.2516 - val_loss: 2.6774 - val_acc: 0.1780\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0769 - acc: 0.2533 - val_loss: 2.6806 - val_acc: 0.1710\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0800 - acc: 0.246 - 0s 75ms/step - loss: 2.0800 - acc: 0.2467 - val_loss: 2.6839 - val_acc: 0.1733\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0718 - acc: 0.2654 - val_loss: 2.6820 - val_acc: 0.1733\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0737 - acc: 0.2537 - val_loss: 2.6760 - val_acc: 0.1733\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0675 - acc: 0.2573 - val_loss: 2.6713 - val_acc: 0.1780\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0736 - acc: 0.2561 - val_loss: 2.6683 - val_acc: 0.1780\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0766 - acc: 0.2557 - val_loss: 2.6640 - val_acc: 0.1780\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0794 - acc: 0.2569 - val_loss: 2.6622 - val_acc: 0.1780\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0807 - acc: 0.2516 - val_loss: 2.6630 - val_acc: 0.1803\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0743 - acc: 0.2541 - val_loss: 2.6608 - val_acc: 0.1803\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0768 - acc: 0.2602 - val_loss: 2.6603 - val_acc: 0.1803\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0734 - acc: 0.2593 - val_loss: 2.6579 - val_acc: 0.1850\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0688 - acc: 0.2545 - val_loss: 2.6530 - val_acc: 0.1874\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0730 - acc: 0.2565 - val_loss: 2.6466 - val_acc: 0.1874\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0720 - acc: 0.2565 - val_loss: 2.6427 - val_acc: 0.1850\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0800 - acc: 0.2561 - val_loss: 2.6418 - val_acc: 0.1874\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0794 - acc: 0.2557 - val_loss: 2.6432 - val_acc: 0.1920\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0751 - acc: 0.2581 - val_loss: 2.6452 - val_acc: 0.1920\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0736 - acc: 0.2488 - val_loss: 2.6423 - val_acc: 0.1920\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0766 - acc: 0.2528 - val_loss: 2.6376 - val_acc: 0.1920\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0686 - acc: 0.2516 - val_loss: 2.6320 - val_acc: 0.2061\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0761 - acc: 0.2520 - val_loss: 2.6296 - val_acc: 0.2061\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0686 - acc: 0.2622 - val_loss: 2.6294 - val_acc: 0.2061\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0756 - acc: 0.2565 - val_loss: 2.6283 - val_acc: 0.2061\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0706 - acc: 0.2545 - val_loss: 2.6288 - val_acc: 0.2061\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0705 - acc: 0.2537 - val_loss: 2.6344 - val_acc: 0.2084\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0738 - acc: 0.2589 - val_loss: 2.6401 - val_acc: 0.2108\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0740 - acc: 0.2642 - val_loss: 2.6387 - val_acc: 0.2108\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0786 - acc: 0.2508 - val_loss: 2.6324 - val_acc: 0.2131\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0744 - acc: 0.2557 - val_loss: 2.6257 - val_acc: 0.2155\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0677 - acc: 0.2541 - val_loss: 2.6211 - val_acc: 0.2201\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0734 - acc: 0.2650 - val_loss: 2.6210 - val_acc: 0.2201\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0759 - acc: 0.2553 - val_loss: 2.6251 - val_acc: 0.2178\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0685 - acc: 0.2642 - val_loss: 2.6300 - val_acc: 0.2178\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0724 - acc: 0.2642 - val_loss: 2.6305 - val_acc: 0.2108\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0704 - acc: 0.2557 - val_loss: 2.6276 - val_acc: 0.2108\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0733 - acc: 0.2663 - val_loss: 2.6246 - val_acc: 0.2155\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0699 - acc: 0.2598 - val_loss: 2.6224 - val_acc: 0.2178\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0738 - acc: 0.2561 - val_loss: 2.6235 - val_acc: 0.2178\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0715 - acc: 0.2565 - val_loss: 2.6284 - val_acc: 0.2131\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0707 - acc: 0.2549 - val_loss: 2.6347 - val_acc: 0.2131\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0737 - acc: 0.2537 - val_loss: 2.6371 - val_acc: 0.2108\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0813 - acc: 0.2541 - val_loss: 2.6330 - val_acc: 0.2131\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0743 - acc: 0.2638 - val_loss: 2.6231 - val_acc: 0.2131\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0755 - acc: 0.2557 - val_loss: 2.6175 - val_acc: 0.2178\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0742 - acc: 0.2577 - val_loss: 2.6117 - val_acc: 0.2248\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0692 - acc: 0.254 - 0s 81ms/step - loss: 2.0692 - acc: 0.2549 - val_loss: 2.6108 - val_acc: 0.2248\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.0744 - acc: 0.2516 - val_loss: 2.6128 - val_acc: 0.2225\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0729 - acc: 0.2492 - val_loss: 2.6151 - val_acc: 0.2131\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0741 - acc: 0.2569 - val_loss: 2.6159 - val_acc: 0.2131\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0736 - acc: 0.2565 - val_loss: 2.6128 - val_acc: 0.2225\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0738 - acc: 0.2561 - val_loss: 2.6108 - val_acc: 0.2225\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0728 - acc: 0.2598 - val_loss: 2.6084 - val_acc: 0.2225\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0742 - acc: 0.2606 - val_loss: 2.6101 - val_acc: 0.2201\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0728 - acc: 0.2541 - val_loss: 2.6137 - val_acc: 0.2178\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0732 - acc: 0.2573 - val_loss: 2.6169 - val_acc: 0.2131\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0727 - acc: 0.2589 - val_loss: 2.6168 - val_acc: 0.2131\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0770 - acc: 0.2512 - val_loss: 2.6141 - val_acc: 0.2131\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0718 - acc: 0.2524 - val_loss: 2.6115 - val_acc: 0.2201\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0704 - acc: 0.2638 - val_loss: 2.6117 - val_acc: 0.2225\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0696 - acc: 0.2663 - val_loss: 2.6129 - val_acc: 0.2201\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0683 - acc: 0.2577 - val_loss: 2.6185 - val_acc: 0.2201\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0773 - acc: 0.2549 - val_loss: 2.6236 - val_acc: 0.2201\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0641 - acc: 0.2589 - val_loss: 2.6227 - val_acc: 0.2201\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0746 - acc: 0.2606 - val_loss: 2.6223 - val_acc: 0.2248\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0741 - acc: 0.2573 - val_loss: 2.6175 - val_acc: 0.2248\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0663 - acc: 0.2593 - val_loss: 2.6114 - val_acc: 0.2272\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0741 - acc: 0.2541 - val_loss: 2.6075 - val_acc: 0.2342\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0712 - acc: 0.2512 - val_loss: 2.6049 - val_acc: 0.2295\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0741 - acc: 0.2602 - val_loss: 2.6036 - val_acc: 0.2225\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0690 - acc: 0.2634 - val_loss: 2.6081 - val_acc: 0.2131\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.0720 - acc: 0.262 - 0s 77ms/step - loss: 2.0720 - acc: 0.2622 - val_loss: 2.6100 - val_acc: 0.2131\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0743 - acc: 0.2557 - val_loss: 2.6092 - val_acc: 0.2131\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0673 - acc: 0.2638 - val_loss: 2.6081 - val_acc: 0.2178\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0715 - acc: 0.2573 - val_loss: 2.6063 - val_acc: 0.2248\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0647 - acc: 0.2630 - val_loss: 2.6022 - val_acc: 0.2225\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0684 - acc: 0.2638 - val_loss: 2.5982 - val_acc: 0.2248\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0734 - acc: 0.2593 - val_loss: 2.5948 - val_acc: 0.2248\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0677 - acc: 0.2545 - val_loss: 2.5929 - val_acc: 0.2225\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0721 - acc: 0.2606 - val_loss: 2.5934 - val_acc: 0.2201\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0777 - acc: 0.2549 - val_loss: 2.5953 - val_acc: 0.2131\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0715 - acc: 0.2598 - val_loss: 2.5931 - val_acc: 0.2178\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0723 - acc: 0.2504 - val_loss: 2.5892 - val_acc: 0.2178\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0732 - acc: 0.2638 - val_loss: 2.5847 - val_acc: 0.2178\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0715 - acc: 0.2569 - val_loss: 2.5857 - val_acc: 0.2178\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0690 - acc: 0.2638 - val_loss: 2.5919 - val_acc: 0.2108\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0731 - acc: 0.2512 - val_loss: 2.5969 - val_acc: 0.2084\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0705 - acc: 0.2638 - val_loss: 2.5996 - val_acc: 0.2084\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0709 - acc: 0.2541 - val_loss: 2.6024 - val_acc: 0.2084\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0727 - acc: 0.2549 - val_loss: 2.6068 - val_acc: 0.2131\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0716 - acc: 0.2581 - val_loss: 2.6050 - val_acc: 0.2131\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0741 - acc: 0.2553 - val_loss: 2.5970 - val_acc: 0.2037\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0701 - acc: 0.2545 - val_loss: 2.5916 - val_acc: 0.2037\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0714 - acc: 0.2524 - val_loss: 2.5882 - val_acc: 0.2037\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0695 - acc: 0.2650 - val_loss: 2.5905 - val_acc: 0.2084\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0693 - acc: 0.2549 - val_loss: 2.5962 - val_acc: 0.2084\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0688 - acc: 0.2634 - val_loss: 2.6017 - val_acc: 0.2108\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0764 - acc: 0.2565 - val_loss: 2.6017 - val_acc: 0.2131\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0658 - acc: 0.2541 - val_loss: 2.5997 - val_acc: 0.2108\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0667 - acc: 0.2630 - val_loss: 2.5957 - val_acc: 0.2084\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0650 - acc: 0.2663 - val_loss: 2.5913 - val_acc: 0.2084\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0698 - acc: 0.2606 - val_loss: 2.5918 - val_acc: 0.2131\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0658 - acc: 0.2630 - val_loss: 2.5953 - val_acc: 0.2108\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0702 - acc: 0.2593 - val_loss: 2.6013 - val_acc: 0.2108\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0699 - acc: 0.2565 - val_loss: 2.6119 - val_acc: 0.2131\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0754 - acc: 0.2545 - val_loss: 2.6189 - val_acc: 0.2131\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0704 - acc: 0.2561 - val_loss: 2.6139 - val_acc: 0.2131\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0652 - acc: 0.2610 - val_loss: 2.6019 - val_acc: 0.2131\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0710 - acc: 0.2545 - val_loss: 2.5949 - val_acc: 0.2108\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.0712 - acc: 0.2488 - val_loss: 2.5915 - val_acc: 0.2084\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0676 - acc: 0.2533 - val_loss: 2.5955 - val_acc: 0.2108\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0727 - acc: 0.2524 - val_loss: 2.6039 - val_acc: 0.2131\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0667 - acc: 0.2630 - val_loss: 2.6089 - val_acc: 0.2084\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0719 - acc: 0.2593 - val_loss: 2.6067 - val_acc: 0.2155\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0706 - acc: 0.2569 - val_loss: 2.5932 - val_acc: 0.2155\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0741 - acc: 0.2565 - val_loss: 2.5826 - val_acc: 0.2178\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0761 - acc: 0.2581 - val_loss: 2.5798 - val_acc: 0.2201\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0674 - acc: 0.2565 - val_loss: 2.5815 - val_acc: 0.2178\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0679 - acc: 0.2654 - val_loss: 2.5879 - val_acc: 0.2201\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0709 - acc: 0.2549 - val_loss: 2.5887 - val_acc: 0.2061\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0703 - acc: 0.2541 - val_loss: 2.5827 - val_acc: 0.2201\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0680 - acc: 0.2533 - val_loss: 2.5779 - val_acc: 0.2201\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0704 - acc: 0.2610 - val_loss: 2.5767 - val_acc: 0.2225\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0696 - acc: 0.2565 - val_loss: 2.5772 - val_acc: 0.2225\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0680 - acc: 0.2618 - val_loss: 2.5797 - val_acc: 0.2272\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0678 - acc: 0.2593 - val_loss: 2.5789 - val_acc: 0.2225\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0689 - acc: 0.2581 - val_loss: 2.5793 - val_acc: 0.2225\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0699 - acc: 0.2577 - val_loss: 2.5808 - val_acc: 0.2225\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0701 - acc: 0.2598 - val_loss: 2.5819 - val_acc: 0.2155\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0699 - acc: 0.2610 - val_loss: 2.5804 - val_acc: 0.2155\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0696 - acc: 0.2646 - val_loss: 2.5749 - val_acc: 0.2155\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0704 - acc: 0.2650 - val_loss: 2.5702 - val_acc: 0.2178\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0737 - acc: 0.2553 - val_loss: 2.5727 - val_acc: 0.2155\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0687 - acc: 0.2545 - val_loss: 2.5810 - val_acc: 0.2155\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0740 - acc: 0.2557 - val_loss: 2.5913 - val_acc: 0.2108\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0691 - acc: 0.2638 - val_loss: 2.5938 - val_acc: 0.2131\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0655 - acc: 0.2634 - val_loss: 2.5923 - val_acc: 0.2201\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0723 - acc: 0.2500 - val_loss: 2.5910 - val_acc: 0.2201\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0675 - acc: 0.2593 - val_loss: 2.5937 - val_acc: 0.2155\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.0673 - acc: 0.2618 - val_loss: 2.6008 - val_acc: 0.2178\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0704 - acc: 0.2593 - val_loss: 2.6038 - val_acc: 0.2178\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0676 - acc: 0.2585 - val_loss: 2.6033 - val_acc: 0.2131\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0615 - acc: 0.2561 - val_loss: 2.5982 - val_acc: 0.2225\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0686 - acc: 0.2642 - val_loss: 2.5901 - val_acc: 0.2155\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0695 - acc: 0.2618 - val_loss: 2.5829 - val_acc: 0.2178\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0705 - acc: 0.2602 - val_loss: 2.5805 - val_acc: 0.2201\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0711 - acc: 0.2553 - val_loss: 2.5796 - val_acc: 0.2248\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0673 - acc: 0.2581 - val_loss: 2.5814 - val_acc: 0.2248\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0685 - acc: 0.2581 - val_loss: 2.5876 - val_acc: 0.2201\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0642 - acc: 0.2549 - val_loss: 2.5960 - val_acc: 0.2178\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0693 - acc: 0.2557 - val_loss: 2.5977 - val_acc: 0.2201\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0655 - acc: 0.2614 - val_loss: 2.5984 - val_acc: 0.2248\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0741 - acc: 0.2484 - val_loss: 2.5980 - val_acc: 0.2295\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0707 - acc: 0.2606 - val_loss: 2.5964 - val_acc: 0.2295\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0674 - acc: 0.2610 - val_loss: 2.5946 - val_acc: 0.2319\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0664 - acc: 0.2614 - val_loss: 2.5949 - val_acc: 0.2272\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 2.0639 - acc: 0.2622 - val_loss: 2.5958 - val_acc: 0.2225\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0676 - acc: 0.2593 - val_loss: 2.5973 - val_acc: 0.2178\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0712 - acc: 0.2569 - val_loss: 2.5951 - val_acc: 0.2225\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0657 - acc: 0.2577 - val_loss: 2.5936 - val_acc: 0.2225\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0663 - acc: 0.2557 - val_loss: 2.5956 - val_acc: 0.2248\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0690 - acc: 0.2630 - val_loss: 2.6026 - val_acc: 0.2248\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0685 - acc: 0.2589 - val_loss: 2.6075 - val_acc: 0.2201\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0680 - acc: 0.2602 - val_loss: 2.6106 - val_acc: 0.2201\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0639 - acc: 0.2634 - val_loss: 2.6098 - val_acc: 0.2155\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0695 - acc: 0.2496 - val_loss: 2.6107 - val_acc: 0.2178\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0667 - acc: 0.2626 - val_loss: 2.6131 - val_acc: 0.2178\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0683 - acc: 0.2524 - val_loss: 2.6165 - val_acc: 0.2178\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0681 - acc: 0.2569 - val_loss: 2.6235 - val_acc: 0.2201\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0711 - acc: 0.2581 - val_loss: 2.6314 - val_acc: 0.2084\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0738 - acc: 0.2593 - val_loss: 2.6331 - val_acc: 0.2061\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0654 - acc: 0.2622 - val_loss: 2.6280 - val_acc: 0.2084\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0639 - acc: 0.2630 - val_loss: 2.6193 - val_acc: 0.2155\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0658 - acc: 0.2626 - val_loss: 2.6135 - val_acc: 0.2155\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0699 - acc: 0.2585 - val_loss: 2.6163 - val_acc: 0.2131\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0688 - acc: 0.2533 - val_loss: 2.6240 - val_acc: 0.2108\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0669 - acc: 0.2593 - val_loss: 2.6330 - val_acc: 0.2084\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0757 - acc: 0.2541 - val_loss: 2.6335 - val_acc: 0.2084\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0680 - acc: 0.2618 - val_loss: 2.6256 - val_acc: 0.2155\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0694 - acc: 0.2638 - val_loss: 2.6216 - val_acc: 0.2201\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0682 - acc: 0.2610 - val_loss: 2.6247 - val_acc: 0.2225\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0672 - acc: 0.2541 - val_loss: 2.6369 - val_acc: 0.2131\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0706 - acc: 0.2561 - val_loss: 2.6498 - val_acc: 0.2108\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0688 - acc: 0.2626 - val_loss: 2.6513 - val_acc: 0.2061\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0708 - acc: 0.2602 - val_loss: 2.6408 - val_acc: 0.2131\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0709 - acc: 0.2565 - val_loss: 2.6284 - val_acc: 0.2201\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0716 - acc: 0.2561 - val_loss: 2.6221 - val_acc: 0.2201\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0703 - acc: 0.2573 - val_loss: 2.6258 - val_acc: 0.2178\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0677 - acc: 0.2630 - val_loss: 2.6327 - val_acc: 0.2155\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0662 - acc: 0.2622 - val_loss: 2.6361 - val_acc: 0.2084\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0709 - acc: 0.2589 - val_loss: 2.6302 - val_acc: 0.2131\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0683 - acc: 0.2541 - val_loss: 2.6173 - val_acc: 0.2225\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0603 - acc: 0.2589 - val_loss: 2.6069 - val_acc: 0.2201\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.0643 - acc: 0.2642 - val_loss: 2.6058 - val_acc: 0.2178\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.0638 - acc: 0.2589 - val_loss: 2.6106 - val_acc: 0.2155\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0673 - acc: 0.2650 - val_loss: 2.6165 - val_acc: 0.2201\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0658 - acc: 0.2602 - val_loss: 2.6151 - val_acc: 0.2108\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0703 - acc: 0.2565 - val_loss: 2.6092 - val_acc: 0.2155\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0706 - acc: 0.2602 - val_loss: 2.6081 - val_acc: 0.2155\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0716 - acc: 0.2541 - val_loss: 2.6114 - val_acc: 0.2108\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0667 - acc: 0.2602 - val_loss: 2.6217 - val_acc: 0.2084\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0689 - acc: 0.2577 - val_loss: 2.6307 - val_acc: 0.2014\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0677 - acc: 0.2581 - val_loss: 2.6274 - val_acc: 0.2131\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0656 - acc: 0.2618 - val_loss: 2.6191 - val_acc: 0.2178\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0701 - acc: 0.2545 - val_loss: 2.6124 - val_acc: 0.2201\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.0630 - acc: 0.2614 - val_loss: 2.6055 - val_acc: 0.2178\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0669 - acc: 0.2573 - val_loss: 2.6055 - val_acc: 0.2201\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0621 - acc: 0.2606 - val_loss: 2.6067 - val_acc: 0.2225\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0649 - acc: 0.2614 - val_loss: 2.6057 - val_acc: 0.2108\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0644 - acc: 0.2561 - val_loss: 2.6004 - val_acc: 0.2014\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0702 - acc: 0.2569 - val_loss: 2.5896 - val_acc: 0.2131\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0672 - acc: 0.2598 - val_loss: 2.5808 - val_acc: 0.2155\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0625 - acc: 0.2642 - val_loss: 2.5775 - val_acc: 0.2155\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 2.0668 - acc: 0.2561 - val_loss: 2.5792 - val_acc: 0.2201\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0665 - acc: 0.2614 - val_loss: 2.5832 - val_acc: 0.2225\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 2.0647 - acc: 0.2549 - val_loss: 2.5869 - val_acc: 0.2178\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0658 - acc: 0.2589 - val_loss: 2.5896 - val_acc: 0.2225\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0648 - acc: 0.2663 - val_loss: 2.5886 - val_acc: 0.2225\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0657 - acc: 0.2663 - val_loss: 2.5894 - val_acc: 0.2225\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0650 - acc: 0.2638 - val_loss: 2.5910 - val_acc: 0.2272\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0615 - acc: 0.2654 - val_loss: 2.5914 - val_acc: 0.2272\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0635 - acc: 0.2610 - val_loss: 2.5917 - val_acc: 0.2272\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0663 - acc: 0.2610 - val_loss: 2.5894 - val_acc: 0.2272\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0720 - acc: 0.2508 - val_loss: 2.5810 - val_acc: 0.2272\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0661 - acc: 0.2602 - val_loss: 2.5755 - val_acc: 0.2272\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0693 - acc: 0.2622 - val_loss: 2.5776 - val_acc: 0.2248\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0684 - acc: 0.2524 - val_loss: 2.5810 - val_acc: 0.2272\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.0648 - acc: 0.2606 - val_loss: 2.5814 - val_acc: 0.2319\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0653 - acc: 0.2654 - val_loss: 2.5775 - val_acc: 0.2225\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0678 - acc: 0.2524 - val_loss: 2.5806 - val_acc: 0.2272\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0657 - acc: 0.2638 - val_loss: 2.5852 - val_acc: 0.2248\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0629 - acc: 0.2589 - val_loss: 2.5931 - val_acc: 0.2319\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0656 - acc: 0.2541 - val_loss: 2.5957 - val_acc: 0.2319\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0606 - acc: 0.2687 - val_loss: 2.5932 - val_acc: 0.2295\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0659 - acc: 0.2654 - val_loss: 2.5950 - val_acc: 0.2295\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.0622 - acc: 0.2622 - val_loss: 2.6004 - val_acc: 0.2295\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0657 - acc: 0.2561 - val_loss: 2.6122 - val_acc: 0.2248\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0629 - acc: 0.2618 - val_loss: 2.6142 - val_acc: 0.2225\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 2.0649 - acc: 0.2614 - val_loss: 2.6088 - val_acc: 0.2248\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0649 - acc: 0.2642 - val_loss: 2.6036 - val_acc: 0.2225\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.0565 - acc: 0.2732 - val_loss: 2.6037 - val_acc: 0.2248\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0653 - acc: 0.2634 - val_loss: 2.6090 - val_acc: 0.2248\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.0674 - acc: 0.2565 - val_loss: 2.6159 - val_acc: 0.2225\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0649 - acc: 0.2626 - val_loss: 2.6160 - val_acc: 0.2201\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0637 - acc: 0.2585 - val_loss: 2.6031 - val_acc: 0.2248\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.0621 - acc: 0.2663 - val_loss: 2.5925 - val_acc: 0.2319\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0604 - acc: 0.2614 - val_loss: 2.5970 - val_acc: 0.2248\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.0657 - acc: 0.2642 - val_loss: 2.6031 - val_acc: 0.2248\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0721 - acc: 0.2610 - val_loss: 2.6056 - val_acc: 0.2225\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.0628 - acc: 0.2614 - val_loss: 2.6007 - val_acc: 0.2248\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.0622 - acc: 0.2650 - val_loss: 2.5994 - val_acc: 0.2201\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.0618 - acc: 0.2581 - val_loss: 2.6088 - val_acc: 0.2178\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0691 - acc: 0.2675 - val_loss: 2.6238 - val_acc: 0.2178\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.0661 - acc: 0.2638 - val_loss: 2.6381 - val_acc: 0.2155\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.0601 - acc: 0.2569 - val_loss: 2.6369 - val_acc: 0.2131\n"
     ]
    }
   ],
   "source": [
    "b2_embeddings = []\n",
    "# print(len(b2_text))\n",
    "\n",
    "for t2 in b2_text:\n",
    "    b2_embeddings.append(Loaded_model.wv[t2])\n",
    "\n",
    "b2_embeddings=np.array(b2_embeddings) \n",
    "print(np.shape(b2_embeddings))\n",
    "print(np.shape(A2))\n",
    "print(np.shape(b2_encodings))\n",
    "\n",
    "print(\"Validation set shape\")\n",
    "print(np.shape(valid_embeddings))\n",
    "print(np.shape(A4))\n",
    "print(np.shape(valid_encodings))\n",
    "\n",
    "\n",
    "history = model.fit([b2_embeddings, A2],\n",
    "                    b2_encodings,\n",
    "                    epochs=500,\n",
    "                    batch_size=N,\n",
    "                    # class_weight=W,\n",
    "                    validation_data=([valid_embeddings, A4], valid_encodings),\n",
    "                    # callbacks=[callback]\n",
    "                    )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35146d2ce121e8e653791712ad16cca408ea08bd1c84e92938f653a743d84e6c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Graphs': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
